{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data_preprocess/train_preprocess.csv\", sep=\",\", header=0, na_values=['?', '', 'NA'])\n",
    "# Cargamos csv con los datos de test\n",
    "df_test = pd.read_csv(\"../data_preprocess/test_preprocess.csv\", sep=\",\", header=0, na_values=['?', '', 'NA'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X1</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X7</th>\n",
       "      <th>X9</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>...</th>\n",
       "      <th>X25</th>\n",
       "      <th>X27</th>\n",
       "      <th>X30</th>\n",
       "      <th>X32</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>-0.283105</td>\n",
       "      <td>-0.294141</td>\n",
       "      <td>-0.216731</td>\n",
       "      <td>-0.281493</td>\n",
       "      <td>1.398353</td>\n",
       "      <td>-0.434783</td>\n",
       "      <td>-0.455000</td>\n",
       "      <td>0.455889</td>\n",
       "      <td>-0.411449</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.763188</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.128418</td>\n",
       "      <td>-0.372249</td>\n",
       "      <td>-0.123599</td>\n",
       "      <td>-0.398377</td>\n",
       "      <td>2.864004</td>\n",
       "      <td>-1.493411</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>343</td>\n",
       "      <td>0.544414</td>\n",
       "      <td>0.773519</td>\n",
       "      <td>0.849708</td>\n",
       "      <td>0.479761</td>\n",
       "      <td>0.980651</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1.215000</td>\n",
       "      <td>0.117917</td>\n",
       "      <td>0.075134</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503571</td>\n",
       "      <td>0</td>\n",
       "      <td>1.172363</td>\n",
       "      <td>0.577876</td>\n",
       "      <td>0.547511</td>\n",
       "      <td>0.172548</td>\n",
       "      <td>0.447551</td>\n",
       "      <td>0.286241</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>407</td>\n",
       "      <td>-0.109076</td>\n",
       "      <td>-0.182473</td>\n",
       "      <td>-0.165846</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.310319</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>-0.023889</td>\n",
       "      <td>0.077177</td>\n",
       "      <td>0.132379</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.323889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312988</td>\n",
       "      <td>0.023685</td>\n",
       "      <td>0.606281</td>\n",
       "      <td>-0.260056</td>\n",
       "      <td>-0.246029</td>\n",
       "      <td>-0.581444</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>950</td>\n",
       "      <td>-0.142328</td>\n",
       "      <td>-0.170376</td>\n",
       "      <td>-0.160334</td>\n",
       "      <td>-0.089851</td>\n",
       "      <td>-0.009279</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>-0.587864</td>\n",
       "      <td>-0.100179</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.652845</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380371</td>\n",
       "      <td>-0.150597</td>\n",
       "      <td>-0.084419</td>\n",
       "      <td>0.354622</td>\n",
       "      <td>1.829387</td>\n",
       "      <td>-0.269900</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>848</td>\n",
       "      <td>-0.248911</td>\n",
       "      <td>-0.301795</td>\n",
       "      <td>-0.314106</td>\n",
       "      <td>-0.194442</td>\n",
       "      <td>-0.252107</td>\n",
       "      <td>-0.608696</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>-0.126237</td>\n",
       "      <td>0.354204</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.386547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.637207</td>\n",
       "      <td>0.081308</td>\n",
       "      <td>0.565182</td>\n",
       "      <td>0.422371</td>\n",
       "      <td>-0.551973</td>\n",
       "      <td>-0.319979</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>89</td>\n",
       "      <td>0.538190</td>\n",
       "      <td>0.617877</td>\n",
       "      <td>0.188801</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>-0.171094</td>\n",
       "      <td>1.565217</td>\n",
       "      <td>-0.627222</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.393560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162635</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.921962</td>\n",
       "      <td>-1.023932</td>\n",
       "      <td>-0.772406</td>\n",
       "      <td>-0.556728</td>\n",
       "      <td>-0.077491</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>571</td>\n",
       "      <td>-0.310287</td>\n",
       "      <td>-0.314977</td>\n",
       "      <td>-0.357120</td>\n",
       "      <td>-0.321784</td>\n",
       "      <td>-0.551324</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>-2.173889</td>\n",
       "      <td>0.358342</td>\n",
       "      <td>-1.649374</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.068417</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.835449</td>\n",
       "      <td>-0.948475</td>\n",
       "      <td>-0.761183</td>\n",
       "      <td>-0.549400</td>\n",
       "      <td>1.338374</td>\n",
       "      <td>-0.798629</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>953</td>\n",
       "      <td>3.470347</td>\n",
       "      <td>0.830079</td>\n",
       "      <td>2.029403</td>\n",
       "      <td>7.164578</td>\n",
       "      <td>0.278583</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-0.223889</td>\n",
       "      <td>-2.251327</td>\n",
       "      <td>3.191413</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.041926</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.253418</td>\n",
       "      <td>-0.336309</td>\n",
       "      <td>-0.464607</td>\n",
       "      <td>-0.245236</td>\n",
       "      <td>0.029291</td>\n",
       "      <td>-0.187665</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>274</td>\n",
       "      <td>-0.029073</td>\n",
       "      <td>-0.125599</td>\n",
       "      <td>-0.283810</td>\n",
       "      <td>-0.229721</td>\n",
       "      <td>-0.476467</td>\n",
       "      <td>-0.521739</td>\n",
       "      <td>-2.563889</td>\n",
       "      <td>0.978626</td>\n",
       "      <td>-1.499106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.537434</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.270996</td>\n",
       "      <td>-2.246222</td>\n",
       "      <td>-1.987983</td>\n",
       "      <td>0.368031</td>\n",
       "      <td>0.017309</td>\n",
       "      <td>-1.425936</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>370</td>\n",
       "      <td>-0.293103</td>\n",
       "      <td>-0.348404</td>\n",
       "      <td>-0.313144</td>\n",
       "      <td>-0.246272</td>\n",
       "      <td>0.173186</td>\n",
       "      <td>-0.695652</td>\n",
       "      <td>-1.453889</td>\n",
       "      <td>-0.360350</td>\n",
       "      <td>-0.597496</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514628</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.569824</td>\n",
       "      <td>-0.844425</td>\n",
       "      <td>-0.922852</td>\n",
       "      <td>-0.592449</td>\n",
       "      <td>-0.033191</td>\n",
       "      <td>0.724302</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>906 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID        X1        X4        X5        X7        X9       X13  \\\n",
       "0    102 -0.283105 -0.294141 -0.216731 -0.281493  1.398353 -0.434783   \n",
       "1    343  0.544414  0.773519  0.849708  0.479761  0.980651  0.086957   \n",
       "2    407 -0.109076 -0.182473 -0.165846 -0.000198 -0.310319  0.434783   \n",
       "3    950 -0.142328 -0.170376 -0.160334 -0.089851 -0.009279  0.521739   \n",
       "4    848 -0.248911 -0.301795 -0.314106 -0.194442 -0.252107 -0.608696   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "901   89  0.538190  0.617877  0.188801  0.632552 -0.171094  1.565217   \n",
       "902  571 -0.310287 -0.314977 -0.357120 -0.321784 -0.551324 -0.782609   \n",
       "903  953  3.470347  0.830079  2.029403  7.164578  0.278583  0.739130   \n",
       "904  274 -0.029073 -0.125599 -0.283810 -0.229721 -0.476467 -0.521739   \n",
       "905  370 -0.293103 -0.348404 -0.313144 -0.246272  0.173186 -0.695652   \n",
       "\n",
       "          X14       X15       X16  ...  X25       X27  X30       X32  \\\n",
       "0   -0.455000  0.455889 -0.411449  ...    0 -1.763188    0 -0.128418   \n",
       "1    1.215000  0.117917  0.075134  ...    1  0.503571    0  1.172363   \n",
       "2   -0.023889  0.077177  0.132379  ...    0 -0.323889    0  0.312988   \n",
       "3    0.451667 -0.587864 -0.100179  ...    0 -0.652845    0  0.380371   \n",
       "4    0.019444 -0.126237  0.354204  ...    0 -0.386547    0  0.637207   \n",
       "..        ...       ...       ...  ...  ...       ...  ...       ...   \n",
       "901 -0.627222  0.324200  0.393560  ...    0 -0.162635    0 -0.395996   \n",
       "902 -2.173889  0.358342 -1.649374  ...    0 -1.068417    0 -1.835449   \n",
       "903 -0.223889 -2.251327  3.191413  ...    0 -0.041926   -1 -1.253418   \n",
       "904 -2.563889  0.978626 -1.499106  ...    0 -1.537434    0 -2.270996   \n",
       "905 -1.453889 -0.360350 -0.597496  ...    1  0.514628    0 -1.569824   \n",
       "\n",
       "          X34       X35       X36       X38       X39  RATE  \n",
       "0   -0.372249 -0.123599 -0.398377  2.864004 -1.493411     B  \n",
       "1    0.577876  0.547511  0.172548  0.447551  0.286241     B  \n",
       "2    0.023685  0.606281 -0.260056 -0.246029 -0.581444     B  \n",
       "3   -0.150597 -0.084419  0.354622  1.829387 -0.269900     D  \n",
       "4    0.081308  0.565182  0.422371 -0.551973 -0.319979     C  \n",
       "..        ...       ...       ...       ...       ...   ...  \n",
       "901 -0.921962 -1.023932 -0.772406 -0.556728 -0.077491     B  \n",
       "902 -0.948475 -0.761183 -0.549400  1.338374 -0.798629     C  \n",
       "903 -0.336309 -0.464607 -0.245236  0.029291 -0.187665     D  \n",
       "904 -2.246222 -1.987983  0.368031  0.017309 -1.425936     D  \n",
       "905 -0.844425 -0.922852 -0.592449 -0.033191  0.724302     C  \n",
       "\n",
       "[906 rows x 26 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X7</th>\n",
       "      <th>X9</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X18</th>\n",
       "      <th>...</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X27</th>\n",
       "      <th>X30</th>\n",
       "      <th>X32</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.283105</td>\n",
       "      <td>-0.294141</td>\n",
       "      <td>-0.216731</td>\n",
       "      <td>-0.281493</td>\n",
       "      <td>1.398353</td>\n",
       "      <td>-0.434783</td>\n",
       "      <td>-0.455000</td>\n",
       "      <td>0.455889</td>\n",
       "      <td>-0.411449</td>\n",
       "      <td>-0.437620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.763188</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.128418</td>\n",
       "      <td>-0.372249</td>\n",
       "      <td>-0.123599</td>\n",
       "      <td>-0.398377</td>\n",
       "      <td>2.864004</td>\n",
       "      <td>-1.493411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544414</td>\n",
       "      <td>0.773519</td>\n",
       "      <td>0.849708</td>\n",
       "      <td>0.479761</td>\n",
       "      <td>0.980651</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1.215000</td>\n",
       "      <td>0.117917</td>\n",
       "      <td>0.075134</td>\n",
       "      <td>0.119002</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503571</td>\n",
       "      <td>0</td>\n",
       "      <td>1.172363</td>\n",
       "      <td>0.577876</td>\n",
       "      <td>0.547511</td>\n",
       "      <td>0.172548</td>\n",
       "      <td>0.447551</td>\n",
       "      <td>0.286241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.109076</td>\n",
       "      <td>-0.182473</td>\n",
       "      <td>-0.165846</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.310319</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>-0.023889</td>\n",
       "      <td>0.077177</td>\n",
       "      <td>0.132379</td>\n",
       "      <td>0.142035</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.323889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312988</td>\n",
       "      <td>0.023685</td>\n",
       "      <td>0.606281</td>\n",
       "      <td>-0.260056</td>\n",
       "      <td>-0.246029</td>\n",
       "      <td>-0.581444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.142328</td>\n",
       "      <td>-0.170376</td>\n",
       "      <td>-0.160334</td>\n",
       "      <td>-0.089851</td>\n",
       "      <td>-0.009279</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>-0.587864</td>\n",
       "      <td>-0.100179</td>\n",
       "      <td>-0.095969</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.652845</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380371</td>\n",
       "      <td>-0.150597</td>\n",
       "      <td>-0.084419</td>\n",
       "      <td>0.354622</td>\n",
       "      <td>1.829387</td>\n",
       "      <td>-0.269900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.248911</td>\n",
       "      <td>-0.301795</td>\n",
       "      <td>-0.314106</td>\n",
       "      <td>-0.194442</td>\n",
       "      <td>-0.252107</td>\n",
       "      <td>-0.608696</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>-0.126237</td>\n",
       "      <td>0.354204</td>\n",
       "      <td>0.422265</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.386547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.637207</td>\n",
       "      <td>0.081308</td>\n",
       "      <td>0.565182</td>\n",
       "      <td>0.422371</td>\n",
       "      <td>-0.551973</td>\n",
       "      <td>-0.319979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>0.538190</td>\n",
       "      <td>0.617877</td>\n",
       "      <td>0.188801</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>-0.171094</td>\n",
       "      <td>1.565217</td>\n",
       "      <td>-0.627222</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.393560</td>\n",
       "      <td>0.383877</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162635</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.921962</td>\n",
       "      <td>-1.023932</td>\n",
       "      <td>-0.772406</td>\n",
       "      <td>-0.556728</td>\n",
       "      <td>-0.077491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>-0.310287</td>\n",
       "      <td>-0.314977</td>\n",
       "      <td>-0.357120</td>\n",
       "      <td>-0.321784</td>\n",
       "      <td>-0.551324</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>-2.173889</td>\n",
       "      <td>0.358342</td>\n",
       "      <td>-1.649374</td>\n",
       "      <td>-1.266795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.068417</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.835449</td>\n",
       "      <td>-0.948475</td>\n",
       "      <td>-0.761183</td>\n",
       "      <td>-0.549400</td>\n",
       "      <td>1.338374</td>\n",
       "      <td>-0.798629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>3.470347</td>\n",
       "      <td>0.830079</td>\n",
       "      <td>2.029403</td>\n",
       "      <td>7.164578</td>\n",
       "      <td>0.278583</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-0.223889</td>\n",
       "      <td>-2.251327</td>\n",
       "      <td>3.191413</td>\n",
       "      <td>2.687140</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.041926</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.253418</td>\n",
       "      <td>-0.336309</td>\n",
       "      <td>-0.464607</td>\n",
       "      <td>-0.245236</td>\n",
       "      <td>0.029291</td>\n",
       "      <td>-0.187665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>-0.029073</td>\n",
       "      <td>-0.125599</td>\n",
       "      <td>-0.283810</td>\n",
       "      <td>-0.229721</td>\n",
       "      <td>-0.476467</td>\n",
       "      <td>-0.521739</td>\n",
       "      <td>-2.563889</td>\n",
       "      <td>0.978626</td>\n",
       "      <td>-1.499106</td>\n",
       "      <td>-0.944338</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.537434</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.270996</td>\n",
       "      <td>-2.246222</td>\n",
       "      <td>-1.987983</td>\n",
       "      <td>0.368031</td>\n",
       "      <td>0.017309</td>\n",
       "      <td>-1.425936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>-0.293103</td>\n",
       "      <td>-0.348404</td>\n",
       "      <td>-0.313144</td>\n",
       "      <td>-0.246272</td>\n",
       "      <td>0.173186</td>\n",
       "      <td>-0.695652</td>\n",
       "      <td>-1.453889</td>\n",
       "      <td>-0.360350</td>\n",
       "      <td>-0.597496</td>\n",
       "      <td>-0.568138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514628</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.569824</td>\n",
       "      <td>-0.844425</td>\n",
       "      <td>-0.922852</td>\n",
       "      <td>-0.592449</td>\n",
       "      <td>-0.033191</td>\n",
       "      <td>0.724302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>906 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X4        X5        X7        X9       X13       X14  \\\n",
       "0   -0.283105 -0.294141 -0.216731 -0.281493  1.398353 -0.434783 -0.455000   \n",
       "1    0.544414  0.773519  0.849708  0.479761  0.980651  0.086957  1.215000   \n",
       "2   -0.109076 -0.182473 -0.165846 -0.000198 -0.310319  0.434783 -0.023889   \n",
       "3   -0.142328 -0.170376 -0.160334 -0.089851 -0.009279  0.521739  0.451667   \n",
       "4   -0.248911 -0.301795 -0.314106 -0.194442 -0.252107 -0.608696  0.019444   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "901  0.538190  0.617877  0.188801  0.632552 -0.171094  1.565217 -0.627222   \n",
       "902 -0.310287 -0.314977 -0.357120 -0.321784 -0.551324 -0.782609 -2.173889   \n",
       "903  3.470347  0.830079  2.029403  7.164578  0.278583  0.739130 -0.223889   \n",
       "904 -0.029073 -0.125599 -0.283810 -0.229721 -0.476467 -0.521739 -2.563889   \n",
       "905 -0.293103 -0.348404 -0.313144 -0.246272  0.173186 -0.695652 -1.453889   \n",
       "\n",
       "          X15       X16       X18  ...  X24  X25       X27  X30       X32  \\\n",
       "0    0.455889 -0.411449 -0.437620  ...  0.0    0 -1.763188    0 -0.128418   \n",
       "1    0.117917  0.075134  0.119002  ...  1.0    1  0.503571    0  1.172363   \n",
       "2    0.077177  0.132379  0.142035  ... -1.0    0 -0.323889    0  0.312988   \n",
       "3   -0.587864 -0.100179 -0.095969  ...  2.0    0 -0.652845    0  0.380371   \n",
       "4   -0.126237  0.354204  0.422265  ...  1.0    0 -0.386547    0  0.637207   \n",
       "..        ...       ...       ...  ...  ...  ...       ...  ...       ...   \n",
       "901  0.324200  0.393560  0.383877  ...  2.0    0 -0.162635    0 -0.395996   \n",
       "902  0.358342 -1.649374 -1.266795  ...  0.0    0 -1.068417    0 -1.835449   \n",
       "903 -2.251327  3.191413  2.687140  ... -2.0    0 -0.041926   -1 -1.253418   \n",
       "904  0.978626 -1.499106 -0.944338  ...  1.0    0 -1.537434    0 -2.270996   \n",
       "905 -0.360350 -0.597496 -0.568138  ...  0.0    1  0.514628    0 -1.569824   \n",
       "\n",
       "          X34       X35       X36       X38       X39  \n",
       "0   -0.372249 -0.123599 -0.398377  2.864004 -1.493411  \n",
       "1    0.577876  0.547511  0.172548  0.447551  0.286241  \n",
       "2    0.023685  0.606281 -0.260056 -0.246029 -0.581444  \n",
       "3   -0.150597 -0.084419  0.354622  1.829387 -0.269900  \n",
       "4    0.081308  0.565182  0.422371 -0.551973 -0.319979  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "901 -0.921962 -1.023932 -0.772406 -0.556728 -0.077491  \n",
       "902 -0.948475 -0.761183 -0.549400  1.338374 -0.798629  \n",
       "903 -0.336309 -0.464607 -0.245236  0.029291 -0.187665  \n",
       "904 -2.246222 -1.987983  0.368031  0.017309 -1.425936  \n",
       "905 -0.844425 -0.922852 -0.592449 -0.033191  0.724302  \n",
       "\n",
       "[906 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[:,1:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=SMOTE()\n",
    "x_over, y_over=sm.fit_resample(df_train.iloc[:,1:25],df_train.iloc[:,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RATE\n",
       "B    386\n",
       "D    386\n",
       "C    386\n",
       "A    386\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(max_iter=100000),\n",
       "             param_grid={&#x27;C&#x27;: (0.1, 0.5, 1, 1.5, 2),\n",
       "                         &#x27;intercept_scaling&#x27;: (0.1, 0.25, 0.5, 1.0),\n",
       "                         &#x27;penalty&#x27;: (&#x27;l2&#x27;, None)},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LogisticRegression(max_iter=100000),\n",
       "             param_grid={&#x27;C&#x27;: (0.1, 0.5, 1, 1.5, 2),\n",
       "                         &#x27;intercept_scaling&#x27;: (0.1, 0.25, 0.5, 1.0),\n",
       "                         &#x27;penalty&#x27;: (&#x27;l2&#x27;, None)},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=100000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=100000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=100000),\n",
       "             param_grid={'C': (0.1, 0.5, 1, 1.5, 2),\n",
       "                         'intercept_scaling': (0.1, 0.25, 0.5, 1.0),\n",
       "                         'penalty': ('l2', None)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'intercept_scaling':(0.1,0.25,0.5,1.0),'penalty':('l2',None),'C':(0.1,0.5,1,1.5,2)}\n",
    "lr=LogisticRegression(max_iter=100000,solver='lbfgs',class_weight=None)\n",
    "clf=GridSearchCV(lr,parameters,scoring='accuracy')\n",
    "clf.fit(x_over,y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'intercept_scaling': 0.1, 'penalty': None}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(accuracy_score)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6757921342634718"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2=clf.best_estimator_.predict(df_test.iloc[:,1:40])\n",
    "if(not(np.array_equal(pred,pred2))):\n",
    "    print(\"OJO CUIDADO QUE SON DIFERENTES\")\n",
    "    print(pred2)\n",
    "pred=pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.best_estimator_.predict(df_test.iloc[:,1:40])\n",
    "results={'ID':df_test.iloc[:,0], 'RATE': pred}\n",
    "df_submission=pd.DataFrame(data=results)\n",
    "df_submission.to_csv(\"SubmissionSMOTE.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={'ID':df_test.iloc[:,0], 'RATE': pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission=pd.DataFrame(data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(\"Submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=100000, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=100000, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=100000, solver='saga')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=100000,class_weight='balanced',penalty='l2',solver='saga')\n",
    "lr.fit(df_train.iloc[:,1:39],df_train.iloc[:,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprape_submission(classifier):\n",
    "    pred=classifier.predict(df_test.iloc[:,1:40])\n",
    "    results={'ID':df_test.iloc[:,0], 'RATE': pred}\n",
    "    df_submission=pd.DataFrame(data=results)\n",
    "    df_submission.to_csv(\"Submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4326/621546083.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprape_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4326/3282904965.py\u001b[0m in \u001b[0;36mpreprape_submission\u001b[0;34m(classifier)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RATE'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf_submission\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Submission.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3900\u001b[0m         )\n\u001b[1;32m   3901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3902\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3903\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         )\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Submission.csv'"
     ]
    }
   ],
   "source": [
    "preprape_submission(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08874277, 0.41487151, 0.26709393, 0.22929179],\n",
       "       [0.07550051, 0.40453913, 0.30378234, 0.21617802],\n",
       "       [0.06480887, 0.50562   , 0.25276237, 0.17680877],\n",
       "       ...,\n",
       "       [0.08855152, 0.46616364, 0.21398749, 0.23129735],\n",
       "       [0.08136342, 0.40460633, 0.2595434 , 0.25448685],\n",
       "       [0.09882603, 0.48088424, 0.22366756, 0.19662217]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(df_test.iloc[:,1:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RATE\n",
       "B    361\n",
       "C    224\n",
       "D    199\n",
       "A     68\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[:,40].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    cv=RepeatedStratifiedKFold()\n",
    "    n_scores=cross_val_score(model,df_train.iloc[:,1:40],df_train.iloc[:,40],scoring=\"accuracy\",cv=cv,n_jobs=-1)\n",
    "    print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ('l2','l1',None),'multi_class': ('ovr','multinomial'),'class_weight':('balanced',None)}\n",
    "lr=LogisticRegression(max_iter=100000,solver='lbfgs',penalty='l2',multi_class='ovr',class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=100000, multi_class=&#x27;ovr&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=100000, multi_class=&#x27;ovr&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=100000, multi_class='ovr')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(df_train.iloc[:,1:40],df_train.iloc[:,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'D', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'C', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'C', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'C', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'C',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'D', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'D', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'C', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'C', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'C', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'C', 'B', 'B', 'B', 'D', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'D', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'D', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'C', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=lr.predict(df_test.iloc[:,1:40])\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
