{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones para manejo de datos y dataframes\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import pandas as pd\n",
    "\n",
    "# Importaciones para manejo de archivos y llamadas al OS\n",
    "import os as os\n",
    "import warnings\n",
    "\n",
    "# Importaciones para manejo de gráficos\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "# No mostrar warnings de versiones anteriores\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos csv con los datos de train\n",
    "df_train = pd.read_csv(\"../data_raw/training_data.csv\", sep=\",\", header=0, na_values=['?', '', 'NA'])\n",
    "# Cargamos csv con los datos de test\n",
    "df_test = pd.read_csv(\"../data_raw/test_data.csv\", sep=\",\", header=0, na_values=['?', '', 'NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGÓRICAS: X24, X25, X30, RATE \n",
    "\n",
    "# X24 -> Factor ordenado (VLOW, LOW, MED, HIGH, VHIGH) -> LabelEncoder\n",
    "# X25 -> Binario (YES, NO) -> LabelEncoder NO -> 0, YES -> 1. (Da un poco igual si es 0,1 o 1,2 la verdad)\n",
    "# X30 -> ASKVR, CLPXZ, GXZVX, KUHMP, VTKGN, XNHTQ -> OneHotEncoder\n",
    "\n",
    "# Ninguna presenta nulos, aplicamos las transformaciones y posteriormente imputación de NAs\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "df_train_num = df_train.copy()\n",
    "df_test_num = df_test.copy()\n",
    "\n",
    "# 1. \"OrdinalEncoder\" para X24\n",
    "orden_x24 = ['VLOW', 'LOW', 'MED', 'HIGH', 'VHIGH']\n",
    "\n",
    "ordinal_encoder_x24 = OrdinalEncoder(categories=[orden_x24], dtype=int)\n",
    "\n",
    "df_train_num['X24'] = ordinal_encoder_x24.fit_transform(df_train_num[['X24']])\n",
    "df_test_num['X24'] = ordinal_encoder_x24.transform(df_test_num[['X24']])\n",
    "\n",
    "# 2. \"OrdinalEncoder\" para X25\n",
    "orden_x25 = ['NO', 'YES']\n",
    "\n",
    "ordinal_encoder_x25 = OrdinalEncoder(categories=[orden_x25], dtype=int)\n",
    "\n",
    "df_train_num['X25'] = ordinal_encoder_x25.fit_transform(df_train_num[['X25']])\n",
    "df_test_num['X25'] = ordinal_encoder_x25.transform(df_test_num[['X25']])\n",
    "\n",
    "\n",
    "# Si es VTKGN 1 else 0\n",
    "# Ya que la la clase está muy desbalanceada\n",
    "df_train_encoded = df_train_num.copy()\n",
    "df_test_encoded = df_test_num.copy()\n",
    "\n",
    "df_train_encoded.loc[df_train_num['X30'] == 'VTKGN', 'X30'] = 1\n",
    "df_train_encoded.loc[df_train_num['X30'] != 'VTKGN', 'X30'] = 0\n",
    "\n",
    "df_test_encoded.loc[df_test_num['X30'] == 'VTKGN', 'X30'] = 1\n",
    "df_test_encoded.loc[df_test_num['X30'] != 'VTKGN', 'X30'] = 0\n",
    "\n",
    "# df_train_encoded['X30'].astype(int)\n",
    "# df_test_encoded['X30'].astype(int)\n",
    "\n",
    "# #3. \"OneHotEncoder\" para X30\n",
    "\n",
    "# one_hot_encoder = OneHotEncoder(sparse=False, dtype=np.int32)\n",
    "# col_encoded = one_hot_encoder.fit_transform(df_train_num[[\"X30\"]])\n",
    "# df_train_encoded = pd.concat([df_train_num, pd.DataFrame(col_encoded, columns=one_hot_encoder.get_feature_names_out(['X30']))], axis=1)\n",
    "\n",
    "# one_hot_encoder_test = OneHotEncoder(sparse=False, dtype=np.int32)\n",
    "# col_encoded_test = one_hot_encoder_test.fit_transform(df_train_num[[\"X30\"]]) # ponemos train porque test no tiene todas las distintas categorias\n",
    "# df_test_encoded = pd.concat([df_test_num, pd.DataFrame(col_encoded_test, columns=one_hot_encoder_test.get_feature_names_out(['X30']))], axis=1)\n",
    "\n",
    "\n",
    "# Eliminamos original\n",
    "# df_train_encoded.head()\n",
    "# df_test_encoded.head()\n",
    "\n",
    "df_train_encoded['X30'] = pd.to_numeric(df_train_encoded['X30'])\n",
    "df_test_encoded['X30'] = pd.to_numeric(df_train_encoded['X30']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(method,train,test):\n",
    "    if method==\"Minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    if method==\"Robust\":\n",
    "        scaler = RobustScaler()\n",
    "    if method==\"Standard\":\n",
    "        scaler = StandardScaler()\n",
    "    df_scaled_train = scaler.fit_transform(train.to_numpy())\n",
    "    df_scaled_train = pd.DataFrame(df_scaled_train,index=train.index, columns=\n",
    "    train.columns)\n",
    "    df_scaled_test = scaler.transform(test.to_numpy())\n",
    "    df_scaled_test = pd.DataFrame(df_scaled_test,index=test.index, columns=\n",
    "    test.columns)\n",
    "\n",
    "    return df_scaled_train,df_scaled_test\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_imputation(method,n_neigh,train,test):\n",
    "    if method==\"knn\":\n",
    "        Knn_imp_train = KNNImputer(n_neighbors=n_neigh).fit(train)\n",
    "        imp_train = pd.DataFrame(Knn_imp_train.transform(train), columns=train.columns)\n",
    "        Knn_imp_test = KNNImputer(n_neighbors=8).fit(test)\n",
    "        imp_test = pd.DataFrame(Knn_imp_test.transform(test), columns=test.columns)\n",
    "    else:\n",
    "        if method==\"mean\":\n",
    "            Mean_imp_train = SimpleImputer(strategy=\"mean\")\n",
    "        if method==\"median\":\n",
    "            Mean_imp_train = SimpleImputer(strategy=\"median\")\n",
    "        if method==\"most_frequent\":\n",
    "            Mean_imp_train = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "        Mean_imp_train.fit(train,train_RATE)\n",
    "        imp_train = pd.DataFrame(Mean_imp_train.transform(train), columns=train.columns)\n",
    "        imp_test = pd.DataFrame(Mean_imp_train.transform(test), columns=test.columns)\n",
    "    \n",
    "    return imp_train,imp_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(train,test):\n",
    "\n",
    "    min_features_to_select = 1  # Minimum number of features to consider\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    cv = StratifiedKFold(5)\n",
    "\n",
    "    rfecv = RFECV(\n",
    "        estimator=clf,\n",
    "        step=1,\n",
    "        cv=cv,\n",
    "        scoring=\"accuracy\",\n",
    "        min_features_to_select=min_features_to_select,\n",
    "        n_jobs=2,\n",
    "    )\n",
    "    rfecv.fit(train,train_RATE )\n",
    "    \n",
    "    final_columns=rfecv.get_feature_names_out()\n",
    "    res_train= train.loc[:,final_columns]\n",
    "    res_test= test.loc[:,final_columns]\n",
    "    return res_train,res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalanced_management(method,train_X,train_Y):\n",
    "    if method==\"SMOTE\":\n",
    "        sm=SMOTE()\n",
    "    if method==\"Tomeklinks\":\n",
    "        sm=TomekLinks()\n",
    "    if method==\"SMOTETomek\":\n",
    "        sm=SMOTETomek()\n",
    "    \n",
    "    x_over, y_over=sm.fit_resample(train_X,train_Y)\n",
    "    return x_over,y_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Cargamos csv con los datos de train\n",
    "    df_train = pd.read_csv(\"../data_raw/training_data.csv\", sep=\",\", header=0, na_values=['?', '', 'NA'])\n",
    "    # Cargamos csv con los datos de test\n",
    "    df_test = pd.read_csv(\"../data_raw/test_data.csv\", sep=\",\", header=0, na_values=['?', '', 'NA'])\n",
    " \n",
    "\n",
    "    df_train_num = df_train.copy()\n",
    "    df_test_num = df_test.copy()\n",
    "\n",
    "    orden_x24 = ['VLOW', 'LOW', 'MED', 'HIGH', 'VHIGH']\n",
    "\n",
    "    ordinal_encoder_x24 = OrdinalEncoder(categories=[orden_x24], dtype=int)\n",
    "\n",
    "    df_train_num['X24'] = ordinal_encoder_x24.fit_transform(df_train_num[['X24']])\n",
    "    df_test_num['X24'] = ordinal_encoder_x24.transform(df_test_num[['X24']])\n",
    "\n",
    "    orden_x25 = ['NO', 'YES']\n",
    "\n",
    "    ordinal_encoder_x25 = OrdinalEncoder(categories=[orden_x25], dtype=int)\n",
    "\n",
    "    df_train_num['X25'] = ordinal_encoder_x25.fit_transform(df_train_num[['X25']])\n",
    "    df_test_num['X25'] = ordinal_encoder_x25.transform(df_test_num[['X25']])\n",
    "\n",
    "\n",
    "    df_train_encoded = df_train_num.copy()\n",
    "    df_test_encoded = df_test_num.copy()\n",
    "\n",
    "    df_train_encoded.loc[df_train_num['X30'] == 'VTKGN', 'X30'] = 1\n",
    "    df_train_encoded.loc[df_train_num['X30'] != 'VTKGN', 'X30'] = 0\n",
    "\n",
    "    df_test_encoded.loc[df_test_num['X30'] == 'VTKGN', 'X30'] = 1\n",
    "    df_test_encoded.loc[df_test_num['X30'] != 'VTKGN', 'X30'] = 0\n",
    "\n",
    "    df_train_encoded['X30'] = pd.to_numeric(df_train_encoded['X30'])\n",
    "    df_test_encoded['X30'] = pd.to_numeric(df_train_encoded['X30']) \n",
    "\n",
    "    \n",
    "    train_ID = df_train_encoded['ID'].copy()\n",
    "    train_RATE = df_train_encoded ['RATE'].copy()\n",
    "\n",
    "    df_train_encoded = df_train_encoded .drop(['ID','RATE'], axis=1, inplace=False)\n",
    "    test_ID = df_test_encoded['ID'].copy()\n",
    "    df_test_encoded = df_test_encoded.drop('ID', axis=1, inplace=False)\n",
    "\n",
    "    \n",
    "    train=df_train_encoded\n",
    "    test=df_test_encoded\n",
    "\n",
    "\n",
    "\n",
    "    scaling=trial.suggest_categorical(\"scaling\",['Minmax','Robust','Standard'])\n",
    "    train,test=scale_data(method=scaling,train=train,test=test)\n",
    "    imputation=trial.suggest_categorical(\"imputation\",[\"knn\",\"mean\",\"median\",\"most_frequent\"])\n",
    "    if imputation==\"knn\":\n",
    "        n_neigh=trial.suggest_int(\"neighbors\",3,15,step=1,log=False)\n",
    "    else:\n",
    "        n_neigh=None\n",
    "    train,test=value_imputation(method=imputation,n_neigh=n_neigh,train=train,test=test)\n",
    "    fselct=trial.suggest_categorical(\"fselect\",[True,False])\n",
    "    if(fselct):\n",
    "        train,test=feature_selection(train=train,test=test)\n",
    "\n",
    "\n",
    "    x_train,x_val,y_train,y_val = train_test_split(train,train_RATE,shuffle=True)\n",
    "\n",
    "    \n",
    "    imbalanced=trial.suggest_categorical(\"imbalanced\",[\"SMOTE\",\"Tomeklinks\",\"SMOTETomek\"])\n",
    "    if(imbalanced!=None):\n",
    "        x_over,y_over=imbalanced_management(method=imbalanced,train_X=x_train,train_Y=y_train)\n",
    "    else:\n",
    "        x_over,y_over=x_train,y_train\n",
    "\n",
    "\n",
    "    solver=trial.suggest_categorical(\"solver\",['lbfgs','newton-cg','sag','saga'])\n",
    "    if solver!='liblinear':\n",
    "        multiclass=trial.suggest_categorical(\"multi_class\",['ovr','multinomial'])\n",
    "    else:\n",
    "        multiclass='ovr'\n",
    "    multiclass_weights=trial.suggest_categorical(\"class_weight\",['balanced',\"None\"])\n",
    "    if multiclass_weights==\"None\":\n",
    "        multiclass_weights=None\n",
    "    fit_intercept=trial.suggest_categorical(\"fit_intercept\",[True,False])\n",
    "    if solver==\"lbfgs\" or solver==\"newton-cg\" or solver==\"sag\":\n",
    "        penalty=trial.suggest_categorical(\"penalty\",['l2',None])\n",
    "    if solver==\"saga\":\n",
    "        penalty=\"elasticnet\"\n",
    "        l1_ratio=trial.suggest_float(\"l1_ratio\",0.01,0.99,step=0.01)\n",
    "    else:\n",
    "        l1_ratio=None\n",
    "    if penalty!=None:\n",
    "        C_reg=trial.suggest_float(\"C\",0.01,2,step=None,log=True)\n",
    "    else:\n",
    "        C_reg=1.0\n",
    "        \n",
    "\n",
    "\n",
    "    lr=LogisticRegression(penalty=penalty,solver=solver,multi_class=multiclass,class_weight=multiclass_weights,fit_intercept=fit_intercept,C=C_reg,l1_ratio=l1_ratio,max_iter=100000)\n",
    "    lr.fit(x_over,y_over)\n",
    "    y_pred=lr.predict(x_val)\n",
    "    score_a=accuracy_score(y_val,y_pred)\n",
    "    score_b=f1_score(y_pred=y_pred,y_true=y_val,average='weighted')\n",
    "    return score_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-11 20:52:28,384] A new study created in memory with name: no-name-25d2ac37-8f3e-48d0-a6a9-b3732b650eec\n",
      "[I 2024-01-11 20:52:31,314] Trial 0 finished with value: 0.5622887592228428 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 0 with value: 0.5622887592228428.\n",
      "[I 2024-01-11 20:52:36,617] Trial 1 finished with value: 0.6213997472125059 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 1 with value: 0.6213997472125059.\n",
      "[I 2024-01-11 20:52:36,695] Trial 2 finished with value: 0.550012504892885 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': False, 'penalty': 'l2', 'C': 0.10618308768539782}. Best is trial 1 with value: 0.6213997472125059.\n",
      "[I 2024-01-11 20:52:57,080] Trial 3 finished with value: 0.5260142236042729 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': False, 'l1_ratio': 0.23, 'C': 0.2903861307755986}. Best is trial 1 with value: 0.6213997472125059.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 20:53:11,470] Trial 4 finished with value: 0.5802286901988479 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.2246868310170773}. Best is trial 1 with value: 0.6213997472125059.\n",
      "[I 2024-01-11 20:53:20,381] Trial 5 finished with value: 0.635791363595025 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.93, 'C': 1.7369052666159426}. Best is trial 5 with value: 0.635791363595025.\n",
      "[I 2024-01-11 20:53:24,138] Trial 6 finished with value: 0.6169477447010486 and parameters: {'scaling': 'Minmax', 'imputation': 'median', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 5 with value: 0.635791363595025.\n",
      "[I 2024-01-11 20:53:27,603] Trial 7 finished with value: 0.6003027866921204 and parameters: {'scaling': 'Minmax', 'imputation': 'knn', 'neighbors': 4, 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 5 with value: 0.635791363595025.\n",
      "[I 2024-01-11 20:53:28,792] Trial 8 finished with value: 0.5847973112070356 and parameters: {'scaling': 'Minmax', 'imputation': 'knn', 'neighbors': 15, 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 5 with value: 0.635791363595025.\n",
      "[I 2024-01-11 20:53:29,532] Trial 9 finished with value: 0.5807710495532492 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': False, 'imbalanced': 'SMOTETomek', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.07883115540414642}. Best is trial 5 with value: 0.635791363595025.\n",
      "[I 2024-01-11 20:53:36,984] Trial 10 finished with value: 0.6347231492605941 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.99, 'C': 1.2717467392905777}. Best is trial 5 with value: 0.635791363595025.\n",
      "[I 2024-01-11 20:53:47,463] Trial 11 finished with value: 0.5954860401892822 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.99, 'C': 1.828632778816482}. Best is trial 5 with value: 0.635791363595025.\n",
      "[I 2024-01-11 20:53:55,545] Trial 12 finished with value: 0.6553679628274169 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.99, 'C': 1.783292576372738}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:53:58,994] Trial 13 finished with value: 0.47397870811625475 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.7100000000000001, 'C': 0.011324924272233413}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:54:04,714] Trial 14 finished with value: 0.5664042754112517 and parameters: {'scaling': 'Standard', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.67, 'C': 0.7607219154605026}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:54:07,887] Trial 15 finished with value: 0.5605274197247682 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'newton-cg', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.6091564404809305}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:54:13,825] Trial 16 finished with value: 0.5883554815815731 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.79, 'C': 1.877407527768913}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:54:18,788] Trial 17 finished with value: 0.588259114416785 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.36000000000000004, 'C': 0.4662589325819542}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:54:22,380] Trial 18 finished with value: 0.5625538635321293 and parameters: {'scaling': 'Standard', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'l1_ratio': 0.88, 'C': 0.037456584584876974}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:54:25,984] Trial 19 finished with value: 0.5626565114324196 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 11, 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'newton-cg', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.027400705170042}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:54:41,339] Trial 20 finished with value: 0.6552082571343801 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.53, 'C': 0.3884999460122073}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:54:57,048] Trial 21 finished with value: 0.5495920645282774 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.03, 'C': 0.39212495877293047}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:55:12,874] Trial 22 finished with value: 0.5064714942814751 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.55, 'C': 0.9420903227033305}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:55:27,930] Trial 23 finished with value: 0.49440051215632935 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.5, 'C': 0.1746020883289964}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:55:43,617] Trial 24 finished with value: 0.5917713015186119 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.85, 'C': 1.9575701099092542}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:55:49,750] Trial 25 finished with value: 0.5794799417564382 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.6, 'C': 0.6084215816855925}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:56:01,909] Trial 26 finished with value: 0.4820326680573902 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': False, 'l1_ratio': 0.39, 'C': 0.04826828050280406}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:56:05,638] Trial 27 finished with value: 0.6079256942108509 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 3, 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'newton-cg', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.1755401631279914}. Best is trial 12 with value: 0.6553679628274169.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 20:56:25,601] Trial 28 finished with value: 0.5353353955103338 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:56:29,385] Trial 29 finished with value: 0.6112007813182364 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:56:33,906] Trial 30 finished with value: 0.6003419920016511 and parameters: {'scaling': 'Minmax', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.89, 'C': 0.32696183848950405}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:56:43,486] Trial 31 finished with value: 0.5967529935203032 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.98, 'C': 1.2055369925888864}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:56:53,051] Trial 32 finished with value: 0.6197389288040017 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.97, 'C': 1.3453047082911005}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:56:59,031] Trial 33 finished with value: 0.5998757904279217 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.76, 'C': 0.7372091247561389}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:03,422] Trial 34 finished with value: 0.5297373307387264 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'l1_ratio': 0.88, 'C': 1.226465757190191}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:07,418] Trial 35 finished with value: 0.5315208858596773 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.504639577387135}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:12,781] Trial 36 finished with value: 0.5558275403938476 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': False, 'l1_ratio': 0.93, 'C': 1.584173623756235}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:12,967] Trial 37 finished with value: 0.6077979446312787 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': False, 'imbalanced': 'SMOTETomek', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.12750719293305554}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:21,161] Trial 38 finished with value: 0.5348927054085996 and parameters: {'scaling': 'Standard', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:21,570] Trial 39 finished with value: 0.5393951541417106 and parameters: {'scaling': 'Minmax', 'imputation': 'knn', 'neighbors': 8, 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': False, 'penalty': 'l2', 'C': 0.9058364815798108}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:38,505] Trial 40 finished with value: 0.598442003990635 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.81, 'C': 0.26810380717303006}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:43,101] Trial 41 finished with value: 0.630623523837202 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:49,747] Trial 42 finished with value: 0.5991831495267171 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:54,473] Trial 43 finished with value: 0.5999561786908244 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:57:59,321] Trial 44 finished with value: 0.6020975895330967 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:58:04,595] Trial 45 finished with value: 0.610888906394011 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:58:05,551] Trial 46 finished with value: 0.6278788229913579 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:58:05,765] Trial 47 finished with value: 0.5390271550280217 and parameters: {'scaling': 'Minmax', 'imputation': 'median', 'fselect': False, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'l1_ratio': 0.22, 'C': 0.19248295653024564}. Best is trial 12 with value: 0.6553679628274169.\n",
      "[I 2024-01-11 20:58:11,366] Trial 48 finished with value: 0.6875098120670794 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.99, 'C': 1.4841139554291727}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:58:17,673] Trial 49 finished with value: 0.6366029486367448 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 15, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.99, 'C': 1.4796815089947022}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:58:23,269] Trial 50 finished with value: 0.60394521985205 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 15, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.91, 'C': 1.5039690918651933}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:58:28,999] Trial 51 finished with value: 0.5568579630405546 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 11, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.99, 'C': 1.4717391466670255}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:58:34,691] Trial 52 finished with value: 0.6262153180307597 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 8, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.99, 'C': 1.9746230863728529}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:58:39,724] Trial 53 finished with value: 0.6011439909545333 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 12, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.92, 'C': 0.7498442544405985}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:58:44,748] Trial 54 finished with value: 0.5871404225429055 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.85, 'C': 0.9236559860730977}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:58:49,958] Trial 55 finished with value: 0.5363549101859185 and parameters: {'scaling': 'Standard', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.92, 'C': 1.3165893772241022}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:58:57,006] Trial 56 finished with value: 0.6018925709515758 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': True, 'l1_ratio': 0.9400000000000001, 'C': 1.6116477144221755}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:59:00,710] Trial 57 finished with value: 0.6010164587494153 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 6, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.81, 'C': 0.08894467822381458}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:59:11,055] Trial 58 finished with value: 0.605620929229399 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'newton-cg', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.013118099754710403}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:59:17,523] Trial 59 finished with value: 0.5786758434055833 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.99, 'C': 1.9761481949136561}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:59:22,431] Trial 60 finished with value: 0.5514435894833672 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.16, 'C': 0.5456121666554993}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:59:26,979] Trial 61 finished with value: 0.5084887281721203 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.73, 'C': 1.031678769498893}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:59:50,463] Trial 62 finished with value: 0.6176593099038054 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.63, 'C': 0.7604663162009887}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 20:59:54,463] Trial 63 finished with value: 0.5804377977333656 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:00:04,679] Trial 64 finished with value: 0.6395034520915387 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:00:11,528] Trial 65 finished with value: 0.6226196630968589 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.38, 'C': 1.586923682631581}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:00:15,394] Trial 66 finished with value: 0.5802775705221624 and parameters: {'scaling': 'Standard', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'newton-cg', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:00:23,255] Trial 67 finished with value: 0.6281735382562917 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.85, 'C': 1.0390399856865402}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:00:28,093] Trial 68 finished with value: 0.5898317478436476 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 13, 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': True, 'l1_ratio': 0.47000000000000003, 'C': 0.4202482395891645}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:00:49,851] Trial 69 finished with value: 0.5515819232094015 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.68, 'C': 0.8300966462180558}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:00:58,971] Trial 70 finished with value: 0.5776225564908959 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:01:06,260] Trial 71 finished with value: 0.5646313644400491 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:01:09,393] Trial 72 finished with value: 0.6122144942269812 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:01:16,530] Trial 73 finished with value: 0.5325217085630091 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:01:28,098] Trial 74 finished with value: 0.680520762583613 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:01:42,345] Trial 75 finished with value: 0.5865978491084531 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:01:57,475] Trial 76 finished with value: 0.5595981937621756 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.9400000000000001, 'C': 1.113739850864402}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:02:09,254] Trial 77 finished with value: 0.6012629805779948 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:02:23,327] Trial 78 finished with value: 0.6395169221943448 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.31, 'C': 0.6341055539400323}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:02:35,666] Trial 79 finished with value: 0.6409385943482429 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:02:47,809] Trial 80 finished with value: 0.6029103882768883 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:02:59,617] Trial 81 finished with value: 0.6622710943098643 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:03:11,211] Trial 82 finished with value: 0.5891753235882864 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:03:23,266] Trial 83 finished with value: 0.6320423169369489 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:03:35,150] Trial 84 finished with value: 0.6731922128876413 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:03:47,105] Trial 85 finished with value: 0.5805599281239504 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:03:58,781] Trial 86 finished with value: 0.6405326903793503 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:04:11,556] Trial 87 finished with value: 0.5930735115637027 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:04:24,505] Trial 88 finished with value: 0.6337513277514173 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:04:36,672] Trial 89 finished with value: 0.6436596967872127 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:04:48,537] Trial 90 finished with value: 0.6079078145005534 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:05:00,484] Trial 91 finished with value: 0.686896783741163 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:05:12,344] Trial 92 finished with value: 0.6074650925648594 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:05:24,372] Trial 93 finished with value: 0.5779765352836967 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:05:36,022] Trial 94 finished with value: 0.6172866403708932 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 48 with value: 0.6875098120670794.\n",
      "[I 2024-01-11 21:05:48,298] Trial 95 finished with value: 0.6903509436549083 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:06:00,580] Trial 96 finished with value: 0.6218228241137023 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:06:12,944] Trial 97 finished with value: 0.6192074993027633 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:06:25,200] Trial 98 finished with value: 0.6633723752530096 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:06:37,217] Trial 99 finished with value: 0.6105705320204476 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:06:49,891] Trial 100 finished with value: 0.6275635948431448 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:07:02,012] Trial 101 finished with value: 0.6131205469161864 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:07:14,017] Trial 102 finished with value: 0.5978610246195367 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:07:26,130] Trial 103 finished with value: 0.6463076008670722 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:07:38,827] Trial 104 finished with value: 0.6260678252088133 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:07:48,137] Trial 105 finished with value: 0.532830643138314 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.045368299696822885}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:07:59,602] Trial 106 finished with value: 0.6018474447389458 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:08:11,130] Trial 107 finished with value: 0.5966226946742027 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:08:22,847] Trial 108 finished with value: 0.6219456731038371 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:08:34,729] Trial 109 finished with value: 0.6003134293364922 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.34079057281477804}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:08:44,973] Trial 110 finished with value: 0.6089894688449439 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:08:56,699] Trial 111 finished with value: 0.590931049392478 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:09:08,486] Trial 112 finished with value: 0.5819200513838958 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:09:20,341] Trial 113 finished with value: 0.641598950661254 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:09:32,494] Trial 114 finished with value: 0.6511587914671868 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:09:44,292] Trial 115 finished with value: 0.612399313664133 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:09:55,519] Trial 116 finished with value: 0.6078717194329945 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:10:05,303] Trial 117 finished with value: 0.5663343020171213 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:10:18,033] Trial 118 finished with value: 0.626607683495794 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:10:30,452] Trial 119 finished with value: 0.6005953581259451 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:10:41,398] Trial 120 finished with value: 0.5717025334616098 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.0192491311933048}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:10:54,364] Trial 121 finished with value: 0.6212188570190399 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:11:06,639] Trial 122 finished with value: 0.6093281168171036 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:11:19,056] Trial 123 finished with value: 0.6190728374769899 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:11:30,833] Trial 124 finished with value: 0.6158551286535934 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:11:42,324] Trial 125 finished with value: 0.6006002524667027 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:11:53,572] Trial 126 finished with value: 0.5969303777947761 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:12:04,606] Trial 127 finished with value: 0.600439956516733 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': False, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:12:16,896] Trial 128 finished with value: 0.6166786371391723 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:12:28,871] Trial 129 finished with value: 0.5697795837904465 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:12:29,280] Trial 130 finished with value: 0.5851600356717097 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:12:41,126] Trial 131 finished with value: 0.6160336390172757 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:12:52,548] Trial 132 finished with value: 0.6354924261485413 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:13:04,057] Trial 133 finished with value: 0.6323713563054423 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:13:15,666] Trial 134 finished with value: 0.6648101615744203 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:13:27,036] Trial 135 finished with value: 0.6013529171045544 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:13:38,566] Trial 136 finished with value: 0.6068461207842485 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:13:52,513] Trial 137 finished with value: 0.662281396542609 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:14:04,981] Trial 138 finished with value: 0.6290319084036764 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:14:09,634] Trial 139 finished with value: 0.5267026682018422 and parameters: {'scaling': 'Minmax', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.05, 'C': 0.2402990307934013}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:14:22,180] Trial 140 finished with value: 0.5877349460916544 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.12867002483264892}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:14:34,597] Trial 141 finished with value: 0.574813990594255 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:14:46,429] Trial 142 finished with value: 0.6049590998790341 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:14:59,332] Trial 143 finished with value: 0.5943554710076238 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:15:11,792] Trial 144 finished with value: 0.6493738056115198 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:15:24,040] Trial 145 finished with value: 0.6168290099920292 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:15:36,619] Trial 146 finished with value: 0.6441970670117063 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'l1_ratio': 0.6, 'C': 0.06297429129817056}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:15:48,936] Trial 147 finished with value: 0.5930072817743056 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.44, 'C': 0.06222209346339323}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:16:01,742] Trial 148 finished with value: 0.5282152116944006 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': False, 'l1_ratio': 0.54, 'C': 0.16557063200385377}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:16:13,219] Trial 149 finished with value: 0.5110681365429397 and parameters: {'scaling': 'Robust', 'imputation': 'knn', 'neighbors': 6, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.5800000000000001, 'C': 0.03391074424806197}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:16:17,537] Trial 150 finished with value: 0.6046767749206023 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'l1_ratio': 0.67, 'C': 0.1051086233532356}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:16:29,810] Trial 151 finished with value: 0.5385479687954247 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'l1_ratio': 0.31, 'C': 0.0294250142352108}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:16:41,246] Trial 152 finished with value: 0.5903973116529945 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:16:52,993] Trial 153 finished with value: 0.5928694066671663 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:17:06,156] Trial 154 finished with value: 0.5584525617508741 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'l1_ratio': 0.76, 'C': 0.06221676196847342}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:17:18,369] Trial 155 finished with value: 0.6000683949042788 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:17:30,153] Trial 156 finished with value: 0.6175720415879574 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:17:40,615] Trial 157 finished with value: 0.6313172554053077 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:17:52,531] Trial 158 finished with value: 0.6242538746253372 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:18:12,859] Trial 159 finished with value: 0.5741086622915952 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'saga', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.63, 'C': 0.21399204461995291}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:18:19,600] Trial 160 finished with value: 0.5922868478861987 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:18:31,286] Trial 161 finished with value: 0.6204242308545953 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:18:42,606] Trial 162 finished with value: 0.634746518353961 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:18:53,995] Trial 163 finished with value: 0.6115581394302375 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:19:05,425] Trial 164 finished with value: 0.6523509635711462 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:19:17,251] Trial 165 finished with value: 0.5908093781932192 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:19:28,820] Trial 166 finished with value: 0.6081408831828881 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.06714535364451525}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:19:42,636] Trial 167 finished with value: 0.634839333398219 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:19:46,199] Trial 168 finished with value: 0.5087787551137013 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.53, 'C': 0.02502572806352125}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:19:55,900] Trial 169 finished with value: 0.653946593550158 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:20:05,695] Trial 170 finished with value: 0.6153940747957469 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:20:15,757] Trial 171 finished with value: 0.6486115537009128 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:20:25,753] Trial 172 finished with value: 0.6592408318427175 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:20:35,728] Trial 173 finished with value: 0.6419459452738621 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:20:45,988] Trial 174 finished with value: 0.6154129905701761 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:20:56,132] Trial 175 finished with value: 0.5918550985729384 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:21:06,395] Trial 176 finished with value: 0.6236560299117313 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:21:19,271] Trial 177 finished with value: 0.6017775093553125 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': False, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:21:29,252] Trial 178 finished with value: 0.6187261810767002 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:21:32,726] Trial 179 finished with value: 0.6093605572256637 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:21:35,805] Trial 180 finished with value: 0.6409178841755572 and parameters: {'scaling': 'Robust', 'imputation': 'knn', 'neighbors': 5, 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:21:45,526] Trial 181 finished with value: 0.6497684243089972 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:21:55,312] Trial 182 finished with value: 0.5718637753140449 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:22:05,408] Trial 183 finished with value: 0.5914844943027364 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:22:15,265] Trial 184 finished with value: 0.630942551771328 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:22:25,547] Trial 185 finished with value: 0.6267995952334902 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:22:36,164] Trial 186 finished with value: 0.5956937721892186 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:22:46,400] Trial 187 finished with value: 0.6509931136378375 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:22:58,352] Trial 188 finished with value: 0.6065676794021174 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:23:02,357] Trial 189 finished with value: 0.6449017694571638 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:23:13,580] Trial 190 finished with value: 0.6280747028210307 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:23:24,271] Trial 191 finished with value: 0.6596714773166324 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:23:34,322] Trial 192 finished with value: 0.6598041659630779 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:23:44,307] Trial 193 finished with value: 0.606766917293233 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:23:53,869] Trial 194 finished with value: 0.631168540910164 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:24:03,496] Trial 195 finished with value: 0.6463869165779613 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:24:13,739] Trial 196 finished with value: 0.6237232838128705 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:24:24,786] Trial 197 finished with value: 0.6416021665806352 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:24:29,373] Trial 198 finished with value: 0.6327188101048677 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:24:38,448] Trial 199 finished with value: 0.5852556694701533 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.3001546244762341}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:24:47,404] Trial 200 finished with value: 0.6663965180165198 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:24:56,650] Trial 201 finished with value: 0.6520808879483814 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:25:05,959] Trial 202 finished with value: 0.5968732170859062 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:25:15,303] Trial 203 finished with value: 0.5952004111336362 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:25:24,843] Trial 204 finished with value: 0.6173091430361853 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:25:34,081] Trial 205 finished with value: 0.559827984057059 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:25:44,938] Trial 206 finished with value: 0.5967280420362221 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:25:48,343] Trial 207 finished with value: 0.6435545297490868 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:25:57,652] Trial 208 finished with value: 0.5872333268354776 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:26:07,276] Trial 209 finished with value: 0.6141364485450016 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'newton-cg', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:26:16,844] Trial 210 finished with value: 0.6239285515219889 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:26:26,657] Trial 211 finished with value: 0.6629110697707299 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:26:37,512] Trial 212 finished with value: 0.6222498023268949 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:26:47,626] Trial 213 finished with value: 0.6699697976551986 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:26:57,513] Trial 214 finished with value: 0.6269059413195363 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:26:58,109] Trial 215 finished with value: 0.6358455224839247 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:27:08,048] Trial 216 finished with value: 0.6307861607078699 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:27:18,429] Trial 217 finished with value: 0.60774833042607 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:27:28,243] Trial 218 finished with value: 0.6722169665585258 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:27:31,945] Trial 219 finished with value: 0.6431588760550957 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:27:41,308] Trial 220 finished with value: 0.6349620083612503 and parameters: {'scaling': 'Robust', 'imputation': 'knn', 'neighbors': 9, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:27:50,815] Trial 221 finished with value: 0.6289854131263823 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:28:01,124] Trial 222 finished with value: 0.6796457340495029 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:28:10,942] Trial 223 finished with value: 0.6309058003588334 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:28:20,119] Trial 224 finished with value: 0.6280040319661745 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:28:29,298] Trial 225 finished with value: 0.6854001407350379 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:28:38,510] Trial 226 finished with value: 0.5859621935119429 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:28:47,228] Trial 227 finished with value: 0.6839120817434573 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.6453782658499367}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:28:56,802] Trial 228 finished with value: 0.5613440777729196 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:29:05,107] Trial 229 finished with value: 0.6553057818116726 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.3935189089064422}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:29:13,915] Trial 230 finished with value: 0.6539624282393868 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.3648317590233063}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:29:22,559] Trial 231 finished with value: 0.6285720455853168 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.4036697273779097}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:29:31,525] Trial 232 finished with value: 0.5602580282756495 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.47462525944251477}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:29:40,473] Trial 233 finished with value: 0.6373062085294814 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.6026674577260749}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:29:49,117] Trial 234 finished with value: 0.6338174986572853 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.3423489182089069}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:29:57,782] Trial 235 finished with value: 0.6014901401701845 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.5343170726796905}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:30:07,334] Trial 236 finished with value: 0.6575115857081717 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.6643750401759809}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:30:11,056] Trial 237 finished with value: 0.5658488697760891 and parameters: {'scaling': 'Standard', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.6720882840688573}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:30:15,681] Trial 238 finished with value: 0.5885898559129966 and parameters: {'scaling': 'Minmax', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.27372153200757193}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:30:27,077] Trial 239 finished with value: 0.5853418660688129 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.4399405372463478}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:30:38,088] Trial 240 finished with value: 0.575126437633451 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.35640742690497335}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:30:49,291] Trial 241 finished with value: 0.5833363178244833 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.8933226259208804}. Best is trial 95 with value: 0.6903509436549083.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:31:00,287] Trial 242 finished with value: 0.5915432142095098 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.23718935223516543}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:31:10,043] Trial 243 finished with value: 0.6571892682556305 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.719179536657548}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:31:20,106] Trial 244 finished with value: 0.6090779812968545 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.3636722335584524}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:31:29,996] Trial 245 finished with value: 0.6597180878403073 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.178003531437717}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:31:40,512] Trial 246 finished with value: 0.6232059305073655 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.6373189971948954}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:31:49,676] Trial 247 finished with value: 0.6289723983192236 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': 'l2', 'C': 1.1862033152580946}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:31:58,792] Trial 248 finished with value: 0.6091035120478991 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.8295292654041062}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:08,201] Trial 249 finished with value: 0.5551533469510165 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.8412251409236634}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:08,538] Trial 250 finished with value: 0.6423092454952799 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.3425505088957888}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:18,594] Trial 251 finished with value: 0.6159010016158771 and parameters: {'scaling': 'Robust', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.9982184971849475}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:22,037] Trial 252 finished with value: 0.6575060797017434 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.7228843473374879}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:25,435] Trial 253 finished with value: 0.651835535976505 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.6911489187766269}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:28,817] Trial 254 finished with value: 0.6424895164154553 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.1029435316180056}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:32,162] Trial 255 finished with value: 0.6710214408040103 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.7236208617285247}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:35,502] Trial 256 finished with value: 0.6598239115419394 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.6943509062640627}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:38,731] Trial 257 finished with value: 0.6161288082437498 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.6774895503490352}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:41,963] Trial 258 finished with value: 0.6863542967088545 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.4483647158909412}. Best is trial 95 with value: 0.6903509436549083.\n",
      "[I 2024-01-11 21:32:45,286] Trial 259 finished with value: 0.6959828950714468 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.8230657001528943}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:32:48,649] Trial 260 finished with value: 0.6498147136398937 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.4108418062139518}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:32:52,113] Trial 261 finished with value: 0.5972977042826848 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.2353746891547484}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:32:55,489] Trial 262 finished with value: 0.6076968515648631 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.8214533516630073}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:32:58,841] Trial 263 finished with value: 0.6321803034087488 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.9879212500009198}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:02,385] Trial 264 finished with value: 0.613885769933796 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:05,971] Trial 265 finished with value: 0.594793560894085 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.9999357585124189}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:09,499] Trial 266 finished with value: 0.6415115419943483 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:12,972] Trial 267 finished with value: 0.6802722428775837 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:16,428] Trial 268 finished with value: 0.6159792399096317 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:19,905] Trial 269 finished with value: 0.5991089570964367 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:23,353] Trial 270 finished with value: 0.6455872427479512 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:23,549] Trial 271 finished with value: 0.6500934404199765 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:27,329] Trial 272 finished with value: 0.6285696682172454 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:32,818] Trial 273 finished with value: 0.6299249671297812 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:36,554] Trial 274 finished with value: 0.652057450250847 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 13, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:42,419] Trial 275 finished with value: 0.679143489368372 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:48,463] Trial 276 finished with value: 0.6422466224167436 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:54,039] Trial 277 finished with value: 0.6363897500355705 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:33:59,250] Trial 278 finished with value: 0.6265225372898766 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:34:04,740] Trial 279 finished with value: 0.611095420847417 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:34:09,948] Trial 280 finished with value: 0.6256905941573649 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:34:13,346] Trial 281 finished with value: 0.6950071882002873 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:34:16,749] Trial 282 finished with value: 0.6554910586443295 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:34:20,052] Trial 283 finished with value: 0.6378471146127819 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:34:23,555] Trial 284 finished with value: 0.6551389883792085 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 259 with value: 0.6959828950714468.\n",
      "[I 2024-01-11 21:34:26,935] Trial 285 finished with value: 0.7199687133999356 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:34:30,345] Trial 286 finished with value: 0.5937029536349386 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:34:36,842] Trial 287 finished with value: 0.6806506954150815 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:34:42,557] Trial 288 finished with value: 0.620175276862339 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:34:48,239] Trial 289 finished with value: 0.7138749510022692 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:34:53,257] Trial 290 finished with value: 0.6393520378855321 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:34:56,032] Trial 291 finished with value: 0.6165844598750901 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:01,592] Trial 292 finished with value: 0.624265249881953 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:06,948] Trial 293 finished with value: 0.6165933476427815 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:13,581] Trial 294 finished with value: 0.6073292619328224 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:19,316] Trial 295 finished with value: 0.6402575508743876 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 7, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:25,313] Trial 296 finished with value: 0.6490823435944816 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:30,543] Trial 297 finished with value: 0.7120063044917161 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:36,144] Trial 298 finished with value: 0.6551527925560012 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:41,942] Trial 299 finished with value: 0.6243082653561652 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:47,538] Trial 300 finished with value: 0.6387989099516623 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:53,364] Trial 301 finished with value: 0.6582007306678197 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:35:58,874] Trial 302 finished with value: 0.6349743403424316 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:04,665] Trial 303 finished with value: 0.6413807075949938 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:10,481] Trial 304 finished with value: 0.622789206195902 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:13,704] Trial 305 finished with value: 0.656145118503106 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:19,199] Trial 306 finished with value: 0.6382948492535667 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:22,659] Trial 307 finished with value: 0.6113239154959809 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:27,767] Trial 308 finished with value: 0.6515533784256251 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:31,217] Trial 309 finished with value: 0.6257379028447883 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:34,688] Trial 310 finished with value: 0.6523438920355219 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:40,253] Trial 311 finished with value: 0.6393950519032637 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:41,027] Trial 312 finished with value: 0.644772964781231 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:46,836] Trial 313 finished with value: 0.6240833193918256 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:50,570] Trial 314 finished with value: 0.6113599638361817 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:56,070] Trial 315 finished with value: 0.6396202510681991 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 3, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:36:59,523] Trial 316 finished with value: 0.641255498335757 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:37:02,992] Trial 317 finished with value: 0.6423646638777395 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:37:08,819] Trial 318 finished with value: 0.6092013735554974 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:37:12,232] Trial 319 finished with value: 0.6265602841005208 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:37:17,477] Trial 320 finished with value: 0.7183503056664058 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:37:23,016] Trial 321 finished with value: 0.6350940331812115 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 285 with value: 0.7199687133999356.\n",
      "[I 2024-01-11 21:37:26,652] Trial 322 finished with value: 0.7353619446374938 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:37:29,968] Trial 323 finished with value: 0.6476489639947428 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:37:35,516] Trial 324 finished with value: 0.5929677754606494 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:37:39,419] Trial 325 finished with value: 0.6057642431889085 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:37:44,859] Trial 326 finished with value: 0.6273692813459258 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:37:48,331] Trial 327 finished with value: 0.670811562351655 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:37:51,760] Trial 328 finished with value: 0.5712109200723493 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:37:55,003] Trial 329 finished with value: 0.5994633942471649 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:37:58,267] Trial 330 finished with value: 0.595711550945848 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:01,651] Trial 331 finished with value: 0.5830865239244656 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:01,874] Trial 332 finished with value: 0.5787112749612288 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:05,229] Trial 333 finished with value: 0.6421988511818045 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:08,485] Trial 334 finished with value: 0.6410053703239874 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:11,815] Trial 335 finished with value: 0.5961247218407861 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:15,161] Trial 336 finished with value: 0.6533164147434845 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:18,334] Trial 337 finished with value: 0.6007402879074011 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.5830642554046859}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:21,681] Trial 338 finished with value: 0.622405277594285 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:25,008] Trial 339 finished with value: 0.6205220138058323 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:28,716] Trial 340 finished with value: 0.5778176939568678 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.22, 'C': 0.5283990193411735}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:34,220] Trial 341 finished with value: 0.6936332328221648 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:39,584] Trial 342 finished with value: 0.6255506607929515 and parameters: {'scaling': 'Minmax', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:44,991] Trial 343 finished with value: 0.6752032290308924 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:49,421] Trial 344 finished with value: 0.5270877882928842 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.15379650995002928}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:54,709] Trial 345 finished with value: 0.6056029475096562 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:38:59,638] Trial 346 finished with value: 0.638566846981539 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:05,437] Trial 347 finished with value: 0.6383293245141529 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:11,664] Trial 348 finished with value: 0.5987177185949275 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:16,150] Trial 349 finished with value: 0.5764752047890411 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.495247715144811}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:21,549] Trial 350 finished with value: 0.6527009027170197 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:26,894] Trial 351 finished with value: 0.5433302848116335 and parameters: {'scaling': 'Minmax', 'imputation': 'knn', 'neighbors': 11, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:28,036] Trial 352 finished with value: 0.6445722221607906 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:32,610] Trial 353 finished with value: 0.6134596893537132 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.0774719887101218}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:36,740] Trial 354 finished with value: 0.6330556304753914 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.060000000000000005, 'C': 0.7627699591166037}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:40,278] Trial 355 finished with value: 0.654994081846089 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:43,832] Trial 356 finished with value: 0.6516351283637244 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:49,167] Trial 357 finished with value: 0.6084721290082042 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:54,797] Trial 358 finished with value: 0.6153714897725061 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:39:58,326] Trial 359 finished with value: 0.6469693820043652 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.9048279607779586}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:04,263] Trial 360 finished with value: 0.6362086053523524 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:07,648] Trial 361 finished with value: 0.6139004299261862 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:13,125] Trial 362 finished with value: 0.610258200443618 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:16,561] Trial 363 finished with value: 0.6290393144053117 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:20,924] Trial 364 finished with value: 0.49397088330852207 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.30078095370751773}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:24,732] Trial 365 finished with value: 0.6792870811997871 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:29,324] Trial 366 finished with value: 0.6138386389966418 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.15000000000000002, 'C': 0.46886881970400496}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:32,585] Trial 367 finished with value: 0.6227319526727092 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:39,249] Trial 368 finished with value: 0.618636151232257 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:42,628] Trial 369 finished with value: 0.5745582090563945 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:46,328] Trial 370 finished with value: 0.6284621987360927 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:46,510] Trial 371 finished with value: 0.594824819494423 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.01178477962596282}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:49,843] Trial 372 finished with value: 0.6744303790448631 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:55,848] Trial 373 finished with value: 0.6339558740401284 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 10, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:40:59,347] Trial 374 finished with value: 0.5804558607584004 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:02,645] Trial 375 finished with value: 0.6249831150165345 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:06,367] Trial 376 finished with value: 0.6594419041951373 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.2787577686142764}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:09,919] Trial 377 finished with value: 0.6035929897170778 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:17,092] Trial 378 finished with value: 0.6263476625166458 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:21,934] Trial 379 finished with value: 0.5962165669944804 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.43, 'C': 1.808438796932145}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:25,347] Trial 380 finished with value: 0.6152251780517326 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:28,682] Trial 381 finished with value: 0.626251303971471 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:32,341] Trial 382 finished with value: 0.617043290339281 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.8006730763654017}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:35,679] Trial 383 finished with value: 0.6077331645091903 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:42,795] Trial 384 finished with value: 0.6140497626145517 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:46,399] Trial 385 finished with value: 0.6412612167255562 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:49,840] Trial 386 finished with value: 0.6286387577646247 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:41:53,410] Trial 387 finished with value: 0.6986174258783743 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.9300681440457385}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:00,781] Trial 388 finished with value: 0.6456745586554898 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:05,659] Trial 389 finished with value: 0.6576746664852392 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:10,034] Trial 390 finished with value: 0.5436376512900701 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.18106933201131195}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:15,444] Trial 391 finished with value: 0.6384913282895031 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:17,791] Trial 392 finished with value: 0.6646566392204695 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:24,668] Trial 393 finished with value: 0.6608364275942936 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:30,464] Trial 394 finished with value: 0.6868358996101314 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:36,085] Trial 395 finished with value: 0.6688503836456989 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:39,844] Trial 396 finished with value: 0.6588267460658643 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.6178972603416718}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:45,033] Trial 397 finished with value: 0.6641788080005977 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:50,537] Trial 398 finished with value: 0.6440917127389135 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 13, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:42:55,686] Trial 399 finished with value: 0.6547096993274744 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:00,857] Trial 400 finished with value: 0.5755591144060684 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:04,205] Trial 401 finished with value: 0.577872151331451 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.015539596170315006}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:09,627] Trial 402 finished with value: 0.6563504698095205 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:14,086] Trial 403 finished with value: 0.44121923857395895 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.09999999999999999, 'C': 0.09583360401966129}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:19,664] Trial 404 finished with value: 0.64272040429714 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:25,387] Trial 405 finished with value: 0.6244297946033953 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:30,227] Trial 406 finished with value: 0.6090851792656714 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:33,490] Trial 407 finished with value: 0.6421545763389047 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.20678504196791822}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:38,393] Trial 408 finished with value: 0.6036525479732322 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:45,669] Trial 409 finished with value: 0.6199939735180104 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:48,860] Trial 410 finished with value: 0.5638651227933513 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTETomek', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:53,136] Trial 411 finished with value: 0.6395167853290825 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.29000000000000004, 'C': 0.9563184923849238}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:43:58,389] Trial 412 finished with value: 0.6211380043663981 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:01,748] Trial 413 finished with value: 0.5608125974310052 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.4961807973417757}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:05,029] Trial 414 finished with value: 0.6678085130728303 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:10,267] Trial 415 finished with value: 0.6610473459179317 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:15,412] Trial 416 finished with value: 0.6471607687466718 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:19,274] Trial 417 finished with value: 0.635855957502407 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.4339406009618156}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:23,098] Trial 418 finished with value: 0.6205701567194183 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 9, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.7100000000000001, 'C': 0.5506713476709565}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:26,313] Trial 419 finished with value: 0.6185007603220894 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:32,083] Trial 420 finished with value: 0.6966663576071822 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:35,383] Trial 421 finished with value: 0.5960744430515053 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:40,852] Trial 422 finished with value: 0.6375296069569197 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:44,178] Trial 423 finished with value: 0.6738130417478038 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:47,969] Trial 424 finished with value: 0.6784592099356913 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.44492607597227524}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:51,660] Trial 425 finished with value: 0.6525080258611331 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.9055015013289549}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:55,183] Trial 426 finished with value: 0.6306654519993854 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.1929043349137365}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:44:58,629] Trial 427 finished with value: 0.597106622657741 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.43827269708226124}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:02,236] Trial 428 finished with value: 0.6145165518788868 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': 'l2', 'C': 0.6788351905495846}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:05,666] Trial 429 finished with value: 0.5132425673874131 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.1272812960713813}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:05,820] Trial 430 finished with value: 0.6003800598616703 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.31750399365128684}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:09,148] Trial 431 finished with value: 0.6257493858013078 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.2689769641622312}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:12,724] Trial 432 finished with value: 0.5891692342230617 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.0591753314323176}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:16,479] Trial 433 finished with value: 0.590947627001198 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.8478693046870868}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:19,771] Trial 434 finished with value: 0.6418792797633192 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.3845488402217039}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:25,111] Trial 435 finished with value: 0.6444137923107206 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:29,751] Trial 436 finished with value: 0.6067774630078681 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.79, 'C': 0.7509601298100668}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:35,141] Trial 437 finished with value: 0.6550915172681042 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:40,820] Trial 438 finished with value: 0.6595577136249928 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:47,938] Trial 439 finished with value: 0.6552382006696693 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:51,419] Trial 440 finished with value: 0.6234365654591608 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.6215121076085947}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:45:54,911] Trial 441 finished with value: 0.6479823222496903 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 5, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:02,126] Trial 442 finished with value: 0.6093394399490043 and parameters: {'scaling': 'Minmax', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:05,631] Trial 443 finished with value: 0.6666495015082602 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:09,258] Trial 444 finished with value: 0.5999344082113828 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.3350182917895257}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:12,698] Trial 445 finished with value: 0.6370049884701239 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:18,039] Trial 446 finished with value: 0.6722100024302667 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:21,399] Trial 447 finished with value: 0.48406166409608753 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': False, 'l1_ratio': 0.27, 'C': 0.04766700949035843}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:24,826] Trial 448 finished with value: 0.6926528985059798 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:28,175] Trial 449 finished with value: 0.668297989976636 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:28,440] Trial 450 finished with value: 0.6343545032158394 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.5725354696077117}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:32,116] Trial 451 finished with value: 0.6057708536077212 and parameters: {'scaling': 'Standard', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:40,593] Trial 452 finished with value: 0.5322489917191708 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:44,342] Trial 453 finished with value: 0.6417618979511917 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:51,543] Trial 454 finished with value: 0.5875136293136701 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:46:54,815] Trial 455 finished with value: 0.6705417184201028 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.9701725694632284}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:01,403] Trial 456 finished with value: 0.6632464019185459 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:04,953] Trial 457 finished with value: 0.6621414003404033 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:09,813] Trial 458 finished with value: 0.6377566436300949 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.34, 'C': 1.5495534797012969}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:15,026] Trial 459 finished with value: 0.6255912090821406 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:18,448] Trial 460 finished with value: 0.6474587929135385 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.1213329881423577}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:24,216] Trial 461 finished with value: 0.6593127822723804 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:28,490] Trial 462 finished with value: 0.6621653286772259 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:34,592] Trial 463 finished with value: 0.5804300523778678 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:38,053] Trial 464 finished with value: 0.6505069339973844 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.9906985834357982}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:43,004] Trial 465 finished with value: 0.6365581464645065 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:46,685] Trial 466 finished with value: 0.6093448659888012 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 14, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:51,573] Trial 467 finished with value: 0.6201484288598649 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:54,991] Trial 468 finished with value: 0.6573915246968929 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.5071943923797217}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:47:57,132] Trial 469 finished with value: 0.5691515532925223 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:00,672] Trial 470 finished with value: 0.6712888517227635 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:04,033] Trial 471 finished with value: 0.519797328025266 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'l1_ratio': 0.48000000000000004, 'C': 0.07784079134770013}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:09,936] Trial 472 finished with value: 0.6408740947518543 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:13,757] Trial 473 finished with value: 0.6335714849833791 and parameters: {'scaling': 'Standard', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.7939067918194778}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:22,449] Trial 474 finished with value: 0.6137602518582262 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:25,817] Trial 475 finished with value: 0.637738488684191 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:31,192] Trial 476 finished with value: 0.6322888033167003 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:34,575] Trial 477 finished with value: 0.5830730378751349 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:38,094] Trial 478 finished with value: 0.6421601507845105 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.7089339626920103}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:41,449] Trial 479 finished with value: 0.6076626025577659 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:47,446] Trial 480 finished with value: 0.6681252700016768 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:50,801] Trial 481 finished with value: 0.6583412030776454 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:54,108] Trial 482 finished with value: 0.6471907044756229 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 0.24689596466738678}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:48:57,383] Trial 483 finished with value: 0.5969259095031765 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:49:10,260] Trial 484 finished with value: 0.5899064720650624 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.88, 'C': 0.4292103726482024}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:49:17,096] Trial 485 finished with value: 0.6541241772298925 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:49:20,511] Trial 486 finished with value: 0.6670144713837333 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': False, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:49:23,947] Trial 487 finished with value: 0.6164997869037083 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.2920997353550765}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:49:32,985] Trial 488 finished with value: 0.6282800761633565 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:49:35,431] Trial 489 finished with value: 0.6463896872897072 and parameters: {'scaling': 'Standard', 'imputation': 'median', 'fselect': False, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:49:39,511] Trial 490 finished with value: 0.5027164110580339 and parameters: {'scaling': 'Standard', 'imputation': 'knn', 'neighbors': 7, 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:49:50,938] Trial 491 finished with value: 0.6413771714026757 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.4937264921865427}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:49:54,446] Trial 492 finished with value: 0.6096854522416435 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:49:59,560] Trial 493 finished with value: 0.6393787790268236 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:50:03,167] Trial 494 finished with value: 0.6402769787668875 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:50:14,897] Trial 495 finished with value: 0.6421030272339484 and parameters: {'scaling': 'Robust', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2', 'C': 1.0677976140834657}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:50:19,248] Trial 496 finished with value: 0.5575945036240844 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'SMOTE', 'solver': 'lbfgs', 'multi_class': 'ovr', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:50:23,636] Trial 497 finished with value: 0.6191070538732387 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'saga', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'l1_ratio': 0.75, 'C': 0.6422950833982871}. Best is trial 322 with value: 0.7353619446374938.\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-11 21:50:38,840] Trial 498 finished with value: 0.5879270478338338 and parameters: {'scaling': 'Robust', 'imputation': 'most_frequent', 'fselect': True, 'imbalanced': 'SMOTETomek', 'solver': 'sag', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n",
      "[I 2024-01-11 21:50:42,475] Trial 499 finished with value: 0.6487615925378449 and parameters: {'scaling': 'Standard', 'imputation': 'mean', 'fselect': True, 'imbalanced': 'Tomeklinks', 'solver': 'lbfgs', 'multi_class': 'multinomial', 'class_weight': 'None', 'fit_intercept': True, 'penalty': None}. Best is trial 322 with value: 0.7353619446374938.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "study=optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective,n_trials=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaling': 'Standard',\n",
       " 'imputation': 'mean',\n",
       " 'fselect': True,\n",
       " 'imbalanced': 'Tomeklinks',\n",
       " 'solver': 'lbfgs',\n",
       " 'multi_class': 'multinomial',\n",
       " 'class_weight': 'None',\n",
       " 'fit_intercept': True,\n",
       " 'penalty': None}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data_raw/training_data.csv\", sep=\",\", header=0, na_values=['?', '', 'NA'])\n",
    "# Cargamos csv con los datos de test\n",
    "df_test = pd.read_csv(\"../data_raw/test_data.csv\", sep=\",\", header=0, na_values=['?', '', 'NA'])\n",
    "\n",
    "df_train_num = df_train.copy()\n",
    "df_test_num = df_test.copy()\n",
    "\n",
    "# 1. \"OrdinalEncoder\" para X24\n",
    "orden_x24 = ['VLOW', 'LOW', 'MED', 'HIGH', 'VHIGH']\n",
    "\n",
    "ordinal_encoder_x24 = OrdinalEncoder(categories=[orden_x24], dtype=int)\n",
    "\n",
    "df_train_num['X24'] = ordinal_encoder_x24.fit_transform(df_train_num[['X24']])\n",
    "df_test_num['X24'] = ordinal_encoder_x24.transform(df_test_num[['X24']])\n",
    "\n",
    "# 2. \"OrdinalEncoder\" para X25\n",
    "orden_x25 = ['NO', 'YES']\n",
    "\n",
    "ordinal_encoder_x25 = OrdinalEncoder(categories=[orden_x25], dtype=int)\n",
    "\n",
    "df_train_num['X25'] = ordinal_encoder_x25.fit_transform(df_train_num[['X25']])\n",
    "df_test_num['X25'] = ordinal_encoder_x25.transform(df_test_num[['X25']])\n",
    "\n",
    "\n",
    "# Si es VTKGN 1 else 0\n",
    "# Ya que la la clase está muy desbalanceada\n",
    "df_train_encoded = df_train_num.copy()\n",
    "df_test_encoded = df_test_num.copy()\n",
    "\n",
    "df_train_encoded.loc[df_train_num['X30'] == 'VTKGN', 'X30'] = 1\n",
    "df_train_encoded.loc[df_train_num['X30'] != 'VTKGN', 'X30'] = 0\n",
    "\n",
    "df_test_encoded.loc[df_test_num['X30'] == 'VTKGN', 'X30'] = 1\n",
    "df_test_encoded.loc[df_test_num['X30'] != 'VTKGN', 'X30'] = 0\n",
    "\n",
    "# df_train_encoded['X30'].astype(int)\n",
    "# df_test_encoded['X30'].astype(int)\n",
    "\n",
    "# #3. \"OneHotEncoder\" para X30\n",
    "\n",
    "# one_hot_encoder = OneHotEncoder(sparse=False, dtype=np.int32)\n",
    "# col_encoded = one_hot_encoder.fit_transform(df_train_num[[\"X30\"]])\n",
    "# df_train_encoded = pd.concat([df_train_num, pd.DataFrame(col_encoded, columns=one_hot_encoder.get_feature_names_out(['X30']))], axis=1)\n",
    "\n",
    "# one_hot_encoder_test = OneHotEncoder(sparse=False, dtype=np.int32)\n",
    "# col_encoded_test = one_hot_encoder_test.fit_transform(df_train_num[[\"X30\"]]) # ponemos train porque test no tiene todas las distintas categorias\n",
    "# df_test_encoded = pd.concat([df_test_num, pd.DataFrame(col_encoded_test, columns=one_hot_encoder_test.get_feature_names_out(['X30']))], axis=1)\n",
    "\n",
    "\n",
    "# Eliminamos original\n",
    "# df_train_encoded.head()\n",
    "# df_test_encoded.head()\n",
    "\n",
    "df_train_encoded['X30'] = pd.to_numeric(df_train_encoded['X30'])\n",
    "df_test_encoded['X30'] = pd.to_numeric(df_train_encoded['X30']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_ID = df_train_encoded['ID'].copy()\n",
    "    train_RATE = df_train_encoded ['RATE'].copy()\n",
    "\n",
    "    df_train_encoded = df_train_encoded .drop(['ID','RATE'], axis=1, inplace=False)\n",
    "    test_ID = df_test_encoded['ID'].copy()\n",
    "    df_test_encoded = df_test_encoded.drop('ID', axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_train_encoded\n",
    "test=df_test_encoded\n",
    "\n",
    "train,test=scale_data(method=\"Standard\",train=train,test=test)\n",
    "train,test=value_imputation(method=\"mean\",n_neigh=None,train=train,test=test)\n",
    "train,test=feature_selection(train=train,test=test)\n",
    "x_train,x_val,y_train,y_val = train_test_split(train,train_RATE,shuffle=True)\n",
    "x_over,y_over=imbalanced_management(method=\"Tomeklinks\",train_X=x_train,train_Y=y_train)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, penalty=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, penalty=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty=None)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(penalty=None,solver=\"lbfgs\",multi_class=\"multinomial\",class_weight=None,fit_intercept=True)\n",
    "lr.fit(x_over,y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13 111  56  47]\n"
     ]
    }
   ],
   "source": [
    "pred=lr.predict(x_val)\n",
    "unique,count = np.unique(pred,return_counts=True)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16 100  58  53]\n"
     ]
    }
   ],
   "source": [
    "unique,count = np.unique(y_val,return_counts=True)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=lr.predict(test)\n",
    "results={'ID':test_ID, 'RATE': pred}\n",
    "df_submission=pd.DataFrame(data=results)\n",
    "df_submission.to_csv(\"SubmissionOPTUNA5.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
