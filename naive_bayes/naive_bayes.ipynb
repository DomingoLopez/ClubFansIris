{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universidad de Granada | ETSIIT | Escuela Internacional de Posgrado\n",
    "---\n",
    "# **Proyecto Final**: Naïve Bayes\n",
    "---\n",
    "**Asignatura:** Minería de Datos: Preprocesamiento y Clasificación\n",
    "\n",
    "**Autor:** Lugli, Valentino Glauco · YB0819879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías y Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "import pickle\n",
    "import optuna\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, KBinsDiscretizer, Normalizer, QuantileTransformer, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit = pd.read_csv(\"../data_preprocess/train_preprocess.csv\").drop(columns=[\"ID\"])\n",
    "\n",
    "df_credit_x = df_credit.drop(columns=[\"RATE\"])\n",
    "df_credit_y = df_credit[\"RATE\"]\n",
    "\n",
    "df_test = pd.read_csv(\"../data_preprocess/test_preprocess.csv\")\n",
    "X_test     = df_test.drop(columns=[\"ID\"])\n",
    "X_test_ids = df_test[\"ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_fits(results, x_train, y_train, x_val, y_val, show_cf = True):\n",
    "\n",
    "    for model in results:\n",
    "\n",
    "        y_pred_train = results[model][\"model\"].fit(x_train, y_train).predict(x_train)\n",
    "        y_pred_val   = results[model][\"model\"].predict(x_val)\n",
    "        results[model][\"train_stats\"] = classification_report(y_train, y_pred_train, output_dict=True, zero_division=0)\n",
    "        results[model][\"val_stats\"]  = classification_report(y_val, y_pred_val, output_dict=True, zero_division=0)\n",
    "        results[model][\"val_conf\"]  = confusion_matrix(y_val, y_pred_val)\n",
    "        results[model][\"val_pred\"]  = y_pred_val\n",
    "        results[model][\"train_pred\"]  = y_pred_train   \n",
    "\n",
    "    # print(tabulate(body, headers=header, floatfmt=\".4f\"))\n",
    "    naive_bayes_stats(results, show_cf=show_cf)\n",
    "\n",
    "    return results\n",
    "\n",
    "def naive_bayes_stats(results, show_cf = True):\n",
    "    \n",
    "    header = [\"Variant\", \"F1 Score\", \"Train Acc\", \"Test Acc\", \"Parameters\"]\n",
    "    body = []\n",
    "    matrices = []\n",
    "\n",
    "    for m in results:\n",
    "        body.append([m, results[m][\"val_stats\"][\"macro avg\"][\"f1-score\"], results[m][\"train_stats\"][\"accuracy\"] * 100, results[m][\"val_stats\"][\"accuracy\"] * 100, results[m][\"params\"]])\n",
    "        matrices.append(results[m][\"val_conf\"])\n",
    "    print(tabulate(body, headers=header, floatfmt=\".4f\"))\n",
    "\n",
    "    if(show_cf):\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=len(matrices), figsize=(18, 4))\n",
    "\n",
    "        tick_labels = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "        if(len(matrices) > 1):\n",
    "            axes = axes.flatten()\n",
    "        else:\n",
    "            curr_ax = axes\n",
    "\n",
    "        for i, model in enumerate(results):\n",
    "            if(len(matrices) > 1):\n",
    "                curr_ax = axes[i]\n",
    "\n",
    "            sns.heatmap(matrices[i], ax=curr_ax, annot=True, xticklabels=tick_labels, yticklabels=tick_labels)\n",
    "            curr_ax.title.set_text(model)\n",
    "            curr_ax.set_xlabel(\"Predicted\") \n",
    "            curr_ax.set_ylabel(\"Real\") \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def to_kaggle(pred, id, path=\".\", fname=\"kaggle_out\"):\n",
    "    kaggle_dict = {\"ID\" : id, \"RATE\" : pred}\n",
    "    pd.DataFrame(data=kaggle_dict).to_csv(\"{}/{}.csv\".format(path, fname), index=False)\n",
    "\n",
    "def get_kaggle_pred(model, data, id, path=\".\", fname=\"kaggle_out\"):\n",
    "    model_pred = model.predict(data)\n",
    "    to_kaggle(model_pred, id, path=path, fname=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_scaler(scaler, X_train_in, X_val_in, X_test_in):\n",
    "    scaler.fit(X_train_in)\n",
    "\n",
    "    X_train_out = pd.DataFrame(scaler.transform(X_train_in), columns=X_train_in.columns)\n",
    "    X_val_out   = pd.DataFrame(scaler.transform(X_val_in), columns=X_train_in.columns)\n",
    "    X_test_out  = pd.DataFrame(scaler.transform(X_test_in), columns=X_train_in.columns)\n",
    "\n",
    "    return X_train_out, X_val_out, X_test_out\n",
    "\n",
    "\n",
    "def set_PCA(X_train_in, X_val_in, X_test_in, ratio):\n",
    "    explained_variance_ratio = 0\n",
    "    i = 0\n",
    "    while(explained_variance_ratio < ratio):\n",
    "        i += 1\n",
    "        pca = PCA(n_components=i)\n",
    "        pca.fit(X_train_in)\n",
    "        explained_variance_ratio = np.sum(pca.explained_variance_ratio_)\n",
    "\n",
    "    X_train_out = pd.DataFrame(pca.transform(X_train_in))\n",
    "    X_val_out   = pd.DataFrame(pca.transform(X_val_in))\n",
    "    X_test_out  = pd.DataFrame(pca.transform(X_test_in))\n",
    "\n",
    "    return X_train_out, X_val_out, X_test_out\n",
    "\n",
    "def discretize(X_train_in, X_val_in, X_test_in, bins, enconder, strat):\n",
    "    discretizer = KBinsDiscretizer(n_bins=bins, encode=enconder, strategy=strat)\n",
    "\n",
    "    X_train_out = pd.DataFrame(discretizer.fit_transform(X_train_in), columns=discretizer.get_feature_names_out())\n",
    "    X_val_out   = pd.DataFrame(discretizer.transform(X_val_in), columns=discretizer.get_feature_names_out())\n",
    "    X_test_out  = pd.DataFrame(discretizer.transform(X_test_in), columns=discretizer.get_feature_names_out())\n",
    "\n",
    "    return X_train_out, X_val_out, X_test_out\n",
    " \n",
    "def feature_perc(X_train_in, y_train_in, X_val_in, X_test_in, percent):\n",
    "    fs = SelectPercentile(score_func=f_classif, percentile=percent)\n",
    "\n",
    "    X_train_out = pd.DataFrame(fs.fit_transform(X_train_in, y_train_in))\n",
    "    X_val_out   = pd.DataFrame(fs.transform(X_val_in))\n",
    "    X_test_out  = pd.DataFrame(fs.transform(X_test_in))\n",
    "\n",
    "    return X_train_out, X_val_out, X_test_out\n",
    "\n",
    "def feature_top(X_train_in, y_train_in, X_val_in, X_test_in, k):\n",
    "    fs = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "    X_train_out = pd.DataFrame(fs.fit_transform(X_train_in, y_train_in))\n",
    "    X_val_out   = pd.DataFrame(fs.transform(X_val_in))\n",
    "    X_test_out  = pd.DataFrame(fs.transform(X_test_in))\n",
    "\n",
    "    return X_train_out, X_val_out, X_test_out\n",
    "\n",
    "def get_lof(X_train_in, y_train_in, neigh):\n",
    "    lof = LocalOutlierFactor(n_neighbors=neigh)\n",
    "    yhat = lof.fit_predict(X_train_in)\n",
    "\n",
    "    mask = yhat != -1\n",
    "    X_train_out, y_train_out = X_train_in[mask], y_train_in[mask]  \n",
    "\n",
    "    return X_train_out, y_train_out\n",
    "\n",
    "def down_sample(X_train_in, y_train_in, neigh):\n",
    "    X_train_out, y_train_out = NearMiss(version=2, n_neighbors=neigh).fit_resample(X_train_in, y_train_in)\n",
    "\n",
    "    return X_train_out, y_train_out\n",
    "\n",
    "def up_sample(X_train_in, y_train_in, neigh):\n",
    "    sm = SMOTE(random_state=16, k_neighbors=neigh)\n",
    "    X_train_out, y_train_out = sm.fit_resample(X_train_in, y_train_in)\n",
    "\n",
    "    return X_train_out, y_train_out\n",
    "\n",
    "def get_collinear_features(x, threshold):\n",
    "    '''\n",
    "    Objective:\n",
    "        Remove collinear features in a dataframe with a correlation coefficient\n",
    "        greater than the threshold. Removing collinear features can help a model \n",
    "        to generalize and improves the interpretability of the model.\n",
    "\n",
    "    Inputs: \n",
    "        x: features dataframe\n",
    "        threshold: features with correlations greater than this value are removed\n",
    "\n",
    "    Output: \n",
    "        dataframe that contains only the non-highly-collinear features\n",
    "    '''\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                # print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    # print('Correlated Columns are: {}'.format(sorted(drops)))\n",
    "    return drops\n",
    "\n",
    "def delete_corr(X_train_in, X_val_in, X_test_in, corr_val):\n",
    "    collinear_cols = get_collinear_features(X_train_in, corr_val)\n",
    "    X_train_out = X_train_in.drop(columns=collinear_cols)\n",
    "    X_val_out   = X_val_in.drop(columns=collinear_cols)\n",
    "    X_test_out  = X_test_in.drop(columns=collinear_cols)\n",
    "\n",
    "    return X_train_out, X_val_out, X_test_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCRETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    # \"gaussian\" : {\"model\" : GaussianNB()},\n",
    "    # \"multinom\" : {\"model\" : MultinomialNB(force_alpha=True)},\n",
    "    # \"complement\" : {\"model\" : ComplementNB(force_alpha=True)},\n",
    "    # \"bernoulli\" : {\"model\" : BernoulliNB(force_alpha=True)},\n",
    "    \"categorical_1\" : {\"model\" : CategoricalNB(force_alpha=True)},\n",
    "    # \"categorical_2\" : {\"model\" : CategoricalNB(force_alpha=True, fit_prior=False)},\n",
    "    # \"categorical_4\" : {\"model\" : CategoricalNB(force_alpha=True, alpha=0.75)}\n",
    "}\n",
    "out = naive_bayes_fits(results, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test = discretize(X_train, X_val, X_test, 30, enconder=\"onehot-dense\", strat=\"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/valentino/Irithyll1/repos/ClubFansIris/naive_bayes/naive_bayes.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/valentino/Irithyll1/repos/ClubFansIris/naive_bayes/naive_bayes.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_kaggle_pred(out[\u001b[39m\"\u001b[39m\u001b[39mcategorical_1\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], X_test, X_test_ids, fname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnb_categorical__raw\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "get_kaggle_pred(out[\"categorical_1\"][\"model\"], X_test, X_test_ids, fname=\"nb_categorical__raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CategoricalNB(force_alpha=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalNB</label><div class=\"sk-toggleable__content\"><pre>CategoricalNB(force_alpha=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CategoricalNB(force_alpha=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"categorical_1\"][\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# open a file, where you ant to store the data\n",
    "file = open('best_categorical.pkl', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(out[\"categorical_1\"][\"model\"], file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(out[\"categorical_1\"][\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuningParams:\n",
    "    def __init__(self, X_data, y_data, X_test) -> None:\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(X_data, \n",
    "                                                            y_data, stratify=y_data, \n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=16)\n",
    "        self.X_test = X_test.drop(columns=[\"ID\"])\n",
    "        self.X_test_ids = X_test[\"ID\"]\n",
    "        self.trial = {}\n",
    "\n",
    "        self.scalers = {\"std\" : StandardScaler(), \n",
    "                        \"norm\" : Normalizer(), \n",
    "                        \"quan\" : QuantileTransformer(n_quantiles=600), \n",
    "                        \"power\" : PowerTransformer()}\n",
    "\n",
    "    def objective_function(self, trial):\n",
    "        X_train = self.X_train\n",
    "        y_train = self.y_train\n",
    "        X_val   = self.X_val\n",
    "        y_val   = self.y_val\n",
    "        X_test  = self.X_test\n",
    "\n",
    "        # Standarization\n",
    "        scaler = trial.suggest_categorical(\"scaler\", [\"std\", \"norm\", \"quan\", \"power\"])\n",
    "        X_train, X_val, X_test = set_scaler(self.scalers[scaler], X_train, X_val, X_test)\n",
    "\n",
    "        # LOF\n",
    "        do_LOF = trial.suggest_categorical(\"lof\", [True, False])\n",
    "\n",
    "        if(do_LOF):\n",
    "            neigs = trial.suggest_int(\"lof_neighs\", 10, 30)\n",
    "            X_train, y_train = get_lof(X_train, y_train, neigs)\n",
    "\n",
    "        # Feature Selection\n",
    "        do_feat_sel = trial.suggest_categorical(\"feature_selection\", [True, False])\n",
    "\n",
    "        if(do_feat_sel):\n",
    "            sel_type = trial.suggest_categorical(\"feat_sel_type\", [\"top\", \"perc\"])\n",
    "\n",
    "            if(sel_type == \"top\"):\n",
    "                best_k = trial.suggest_int(\"top_k\", 5, 25)\n",
    "                X_train, X_val, X_test = feature_top(X_train, y_train, X_val, X_test, best_k)\n",
    "            else:\n",
    "                perc = trial.suggest_int(\"perc\", 5, 25)\n",
    "                X_train, X_val, X_test = feature_perc(X_train, y_train, X_val, X_test, perc)\n",
    "\n",
    "        # Correlated Columns\n",
    "        delete_correlated = trial.suggest_categorical(\"delete_correlated\", [True, False])\n",
    "        if(delete_correlated):\n",
    "            corr_val = trial.suggest_float(\"corr_value\", 0.5, 0.8)\n",
    "            X_train, X_val, X_test = delete_corr(X_train, X_val, X_test, corr_val)\n",
    "        \n",
    "        # PCA\n",
    "        do_PCA = trial.suggest_categorical(\"pca\", [True, False])\n",
    "\n",
    "        if(do_PCA):\n",
    "            ratio = trial.suggest_float(\"pca_ratio\", 0.5, 0.95)\n",
    "            X_train, X_val, X_test = set_PCA(X_train, X_val, X_test, ratio)\n",
    "\n",
    "        # Under/Oversampling\n",
    "        do_resampling = trial.suggest_categorical(\"resample\", [True, False])\n",
    "\n",
    "        if(do_resampling):\n",
    "            kind = trial.suggest_categorical(\"kind\", [\"up\", \"down\"])\n",
    "            if(kind == \"up\"):\n",
    "                neigs = trial.suggest_int(\"up_neighs\", 2, 10)\n",
    "                X_train, y_train = up_sample(X_train, y_train, neigs)\n",
    "            else:\n",
    "                neigs = trial.suggest_int(\"down_neighs\", 2, 10)\n",
    "                X_train, y_train = down_sample(X_train, y_train, neigs)\n",
    "\n",
    "\n",
    "        try:\n",
    "            # Fitting and testing...\n",
    "            nb_type = trial.suggest_categorical(\"nb_type\", [\"gauss\", \"categorical\", \"complement\", \"bernoulli\"])\n",
    "            if(nb_type == \"gauss\"):\n",
    "                var_smoothing = trial.suggest_float(\"gauss_var_smoothing\", 1e-10, 1e-3)\n",
    "                model = GaussianNB(var_smoothing=var_smoothing)\n",
    "            else:\n",
    "                discr_bins = trial.suggest_int(\"discr_bins\", 10, 75)\n",
    "                discr_encoder = trial.suggest_categorical(\"discr_encoder\", [\"onehot-dense\", \"ordinal\"])\n",
    "                discr_strat = trial.suggest_categorical(\"discr_strat\", [\"uniform\", \"quantile\", \"kmeans\"])\n",
    "\n",
    "                X_train, X_val, X_test = discretize(X_train, X_val, X_test, discr_bins, discr_encoder, discr_strat)\n",
    "\n",
    "                alpha = trial.suggest_float(\"discrete_alpha\", 0, 1)\n",
    "                if(nb_type == \"categorical\"):\n",
    "                    model = CategoricalNB(force_alpha=True, alpha=alpha)\n",
    "                elif(nb_type == \"complement\"):\n",
    "                    model = ComplementNB(force_alpha=True, alpha=alpha)\n",
    "                else:\n",
    "                    model = BernoulliNB(force_alpha=True, alpha=alpha)\n",
    "\n",
    "            y_train_pred = model.fit(X_train, y_train).predict(X_train)\n",
    "            y_val_pred   = model.predict(X_val)\n",
    "            y_test_pred  = model.predict(X_test)\n",
    "\n",
    "        except Exception:\n",
    "            return -1\n",
    "\n",
    "        self.trial[trial.number] = {}\n",
    "        self.trial[trial.number][\"train_stats\"] = classification_report(y_train, y_train_pred, output_dict=True, zero_division=0)\n",
    "        self.trial[trial.number][\"val_stats\"]   = classification_report(y_val, y_val_pred, output_dict=True, zero_division=0)\n",
    "        self.trial[trial.number][\"val_conf\"]    = confusion_matrix(y_val, y_val_pred)\n",
    "        self.trial[trial.number][\"train_pred\"]  = y_train_pred\n",
    "        self.trial[trial.number][\"val_pred\"]    = y_val_pred\n",
    "        self.trial[trial.number][\"test_pred\"]   = y_test_pred\n",
    "        self.trial[trial.number][\"model\"]       = model\n",
    "        \n",
    "        act_acc = self.trial[trial.number][\"val_stats\"][\"accuracy\"]\n",
    "        act_f1  = self.trial[trial.number][\"val_stats\"][\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "        fitness = np.mean([act_acc, act_f1])\n",
    "\n",
    "        self.trial[trial.number][\"fitness\"] = fitness\n",
    "\n",
    "        return fitness\n",
    "\n",
    "    def get_trial_test(self, num_trial):\n",
    "        return self.trial[num_trial]\n",
    "    \n",
    "    def get_k_best_trials(self, study, k=5, save_kaggle=False, show_cf=True, path=\".\"):\n",
    "        trials = study.best_trials[:k]\n",
    "        results = {}\n",
    "        for t in trials:\n",
    "            act_name = \"{}__{}\".format(study.study_name, t.number)\n",
    "            act_result = self.get_trial_test(t.number)\n",
    "            act_result[\"params\"] = t.params\n",
    "\n",
    "            results[act_name] = act_result\n",
    "            if(save_kaggle):\n",
    "                self.trial_to_kaggle(act_result, path = path, fname = act_name)\n",
    "\n",
    "        naive_bayes_stats(results, show_cf=show_cf)\n",
    "        return results\n",
    "    \n",
    "    def trial_to_kaggle(self, trial, path=\".\", fname = \"kaggle_out\"):\n",
    "        to_kaggle(trial[\"test_pred\"], self.X_test_ids, path=path, fname = fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNTuning = TuningParams(df_credit_x, df_credit_y, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-10 12:29:52,009] A new study created in RDB with name: tuning__20240110-122951\n",
      "[I 2024-01-10 12:29:52,495] Trial 0 finished with value: 0.306305261745747 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.5765268490726685, 'pca': True, 'pca_ratio': 0.8320661383483157, 'resample': True, 'kind': 'down', 'down_neighs': 5, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.000955117132269733}. Best is trial 0 with value: 0.306305261745747.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:29:52,837] Trial 1 finished with value: 0.40017570832418187 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 19, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 5, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.7317252743855953, 'resample': True, 'kind': 'down', 'down_neighs': 9, 'nb_type': 'complement', 'discr_bins': 40, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.6858559653263356}. Best is trial 1 with value: 0.40017570832418187.\n",
      "[I 2024-01-10 12:29:53,313] Trial 2 finished with value: 0.31999474648158854 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.7562573950580951, 'resample': True, 'kind': 'down', 'down_neighs': 7, 'nb_type': 'complement', 'discr_bins': 37, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.20315616534001868}. Best is trial 1 with value: 0.40017570832418187.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:29:53,709] Trial 3 finished with value: -1.0 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 7, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.18319293395002867}. Best is trial 1 with value: 0.40017570832418187.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:29:54,034] Trial 4 finished with value: 0.5003186356127532 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 6, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.746289518123952, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 14, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.24550763815051235}. Best is trial 4 with value: 0.5003186356127532.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:29:54,347] Trial 5 finished with value: 0.2720488234506926 and parameters: {'scaler': 'std', 'lof': True, 'lof_neighs': 12, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 9, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.8214624215813465, 'resample': True, 'kind': 'down', 'down_neighs': 7, 'nb_type': 'complement', 'discr_bins': 35, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.609492140988289}. Best is trial 4 with value: 0.5003186356127532.\n",
      "[I 2024-01-10 12:29:54,582] Trial 6 finished with value: 0.48273176224001324 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 11, 'delete_correlated': True, 'corr_value': 0.722859589432576, 'pca': True, 'pca_ratio': 0.7769269123850352, 'resample': False, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0005599476773881394}. Best is trial 4 with value: 0.5003186356127532.\n",
      "[I 2024-01-10 12:29:54,934] Trial 7 finished with value: 0.5559327852963274 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 6, 'delete_correlated': True, 'corr_value': 0.6489366908684436, 'pca': True, 'pca_ratio': 0.9286287984703291, 'resample': False, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.00031286603616306746}. Best is trial 7 with value: 0.5559327852963274.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:29:55,282] Trial 8 finished with value: 0.556467882533774 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 25, 'delete_correlated': True, 'corr_value': 0.5750865976111529, 'pca': False, 'resample': False, 'nb_type': 'bernoulli', 'discr_bins': 53, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.871380353354052}. Best is trial 8 with value: 0.556467882533774.\n",
      "[I 2024-01-10 12:29:55,572] Trial 9 finished with value: 0.4721930372393651 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 12, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.5104381185572152, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 32, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.3822198212760659}. Best is trial 8 with value: 0.556467882533774.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 8 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 9 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 13 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:29:56,008] Trial 10 finished with value: 0.4884540824332537 and parameters: {'scaler': 'norm', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.518585468738525, 'pca': False, 'resample': False, 'nb_type': 'bernoulli', 'discr_bins': 73, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.992471595546828}. Best is trial 8 with value: 0.556467882533774.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (63). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:29:56,420] Trial 11 finished with value: 0.36370211029474586 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 25, 'delete_correlated': True, 'corr_value': 0.6469381075327074, 'pca': False, 'resample': False, 'nb_type': 'bernoulli', 'discr_bins': 63, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.9867013858763124}. Best is trial 8 with value: 0.556467882533774.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:29:56,870] Trial 12 finished with value: 0.5186198285942532 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 22, 'delete_correlated': True, 'corr_value': 0.6285061295799905, 'pca': False, 'resample': False, 'nb_type': 'bernoulli', 'discr_bins': 52, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.8129939361134889}. Best is trial 8 with value: 0.556467882533774.\n",
      "[I 2024-01-10 12:29:57,133] Trial 13 finished with value: 0.4200369513801078 and parameters: {'scaler': 'norm', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 18, 'delete_correlated': True, 'corr_value': 0.7333607911736626, 'pca': False, 'resample': False, 'nb_type': 'gauss', 'gauss_var_smoothing': 3.848563510495208e-05}. Best is trial 8 with value: 0.556467882533774.\n",
      "[I 2024-01-10 12:29:57,529] Trial 14 finished with value: 0.4905642227245238 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.5711806541387945, 'pca': False, 'resample': False, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.00020891610668465852}. Best is trial 8 with value: 0.556467882533774.\n",
      "[I 2024-01-10 12:29:57,916] Trial 15 finished with value: 0.3112278626671618 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 6, 'delete_correlated': True, 'corr_value': 0.6815947886625637, 'pca': False, 'resample': False, 'nb_type': 'bernoulli', 'discr_bins': 55, 'discr_encoder': 'ordinal', 'discr_strat': 'quantile', 'discrete_alpha': 0.7981509961536771}. Best is trial 8 with value: 0.556467882533774.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:29:58,296] Trial 16 finished with value: 0.5105811811241032 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 17, 'delete_correlated': True, 'corr_value': 0.5929509217431312, 'pca': True, 'pca_ratio': 0.9285339746056336, 'resample': False, 'nb_type': 'bernoulli', 'discr_bins': 12, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.5246165188761924}. Best is trial 8 with value: 0.556467882533774.\n",
      "[I 2024-01-10 12:29:58,529] Trial 17 finished with value: 0.4289106178908811 and parameters: {'scaler': 'norm', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 6, 'delete_correlated': True, 'corr_value': 0.7968346650953517, 'pca': False, 'resample': False, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0004436543076758008}. Best is trial 8 with value: 0.556467882533774.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 8 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:29:59,137] Trial 18 finished with value: 0.5307167931275074 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 10, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.5576613914307466, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'bernoulli', 'discr_bins': 72, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.3700490150990375}. Best is trial 8 with value: 0.556467882533774.\n",
      "[I 2024-01-10 12:29:59,425] Trial 19 finished with value: 0.47416817000150335 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 24, 'delete_correlated': True, 'corr_value': 0.5024006411371693, 'pca': True, 'pca_ratio': 0.6253761712020874, 'resample': False, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.00046739643621685514}. Best is trial 8 with value: 0.556467882533774.\n",
      "[I 2024-01-10 12:29:59,667] Trial 20 finished with value: 0.516022003064686 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 21, 'delete_correlated': True, 'corr_value': 0.6231698453865419, 'pca': False, 'resample': False, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0007664787600515125}. Best is trial 8 with value: 0.556467882533774.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 8 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:00,308] Trial 21 finished with value: 0.5400789835164834 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 10, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.5452489691473633, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'bernoulli', 'discr_bins': 75, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.03695607547824009}. Best is trial 8 with value: 0.556467882533774.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 8 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:00,917] Trial 22 finished with value: 0.5437560948536558 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 17, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.5325643947307092, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'bernoulli', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.010254395538883854}. Best is trial 8 with value: 0.556467882533774.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 13 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 17 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:01,492] Trial 23 finished with value: 0.5744879709676409 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 18, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.6786566136747477, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'bernoulli', 'discr_bins': 50, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.04033063143214671}. Best is trial 23 with value: 0.5744879709676409.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 19 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:02,077] Trial 24 finished with value: 0.5800153599355727 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 23, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.6919908398568528, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'bernoulli', 'discr_bins': 48, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.8322267600308009}. Best is trial 24 with value: 0.5800153599355727.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 19 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:02,632] Trial 25 finished with value: 0.5687611929163869 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 23, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.6987756156490328, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'bernoulli', 'discr_bins': 49, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.8469352110463865}. Best is trial 24 with value: 0.5800153599355727.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 19 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:03,204] Trial 26 finished with value: 0.5812728937728938 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.6957807669295126, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'bernoulli', 'discr_bins': 45, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.7011854744132198}. Best is trial 26 with value: 0.5812728937728938.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 20 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:03,784] Trial 27 finished with value: 0.5334235063455012 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 23, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.7639678840056732, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'bernoulli', 'discr_bins': 45, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.6665779648634665}. Best is trial 26 with value: 0.5812728937728938.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 13 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 18 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:04,348] Trial 28 finished with value: 0.5804463612368025 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 23, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.6809095550170609, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'bernoulli', 'discr_bins': 25, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.7356415436828105}. Best is trial 26 with value: 0.5812728937728938.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 19 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:04,989] Trial 29 finished with value: 0.5885672383682181 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 23, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.7126030522659113, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'bernoulli', 'discr_bins': 27, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.7416876685522762}. Best is trial 29 with value: 0.5885672383682181.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:05,563] Trial 30 finished with value: 0.5753423464312075 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.7329096908604756, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'bernoulli', 'discr_bins': 23, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.7069002938470071}. Best is trial 29 with value: 0.5885672383682181.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 19 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:06,145] Trial 31 finished with value: 0.590354740124908 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 23, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.7004435038535741, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'bernoulli', 'discr_bins': 24, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.7653953549541533}. Best is trial 31 with value: 0.590354740124908.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 19 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:06,744] Trial 32 finished with value: 0.5910151483247486 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 22, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.7161825821772194, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'bernoulli', 'discr_bins': 26, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.5614695568966489}. Best is trial 32 with value: 0.5910151483247486.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:07,199] Trial 33 finished with value: 0.5215970461580131 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 21, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.7136899280011096, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 6, 'nb_type': 'complement', 'discr_bins': 24, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.5859330343810172}. Best is trial 32 with value: 0.5910151483247486.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:07,699] Trial 34 finished with value: 0.5873247803394863 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'bernoulli', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.4749379495630081}. Best is trial 32 with value: 0.5910151483247486.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:08,261] Trial 35 finished with value: 0.6045347133890777 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.4339595986560397}. Best is trial 35 with value: 0.6045347133890777.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (23) found smaller than n_clusters (29). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:08,691] Trial 36 finished with value: 0.5669635493758742 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'categorical', 'discr_bins': 29, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.4883301919550317}. Best is trial 35 with value: 0.6045347133890777.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 16 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 28 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 37 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 38 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:09,138] Trial 37 finished with value: 0.5077625327804668 and parameters: {'scaler': 'norm', 'lof': True, 'lof_neighs': 21, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.39033902943021004}. Best is trial 35 with value: 0.6045347133890777.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (28). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:09,714] Trial 38 finished with value: 0.5855094939481993 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 21, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 7, 'nb_type': 'categorical', 'discr_bins': 28, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.6012697701554505}. Best is trial 35 with value: 0.6045347133890777.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (8) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:10,278] Trial 39 finished with value: 0.31791276439019256 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 16, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 6, 'nb_type': 'complement', 'discr_bins': 18, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.5369573075581068}. Best is trial 35 with value: 0.6045347133890777.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:10,868] Trial 40 finished with value: 0.4599447433875593 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.592968469945196, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'categorical', 'discr_bins': 38, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.31288345446196597}. Best is trial 35 with value: 0.6045347133890777.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:11,565] Trial 41 finished with value: 0.6070147331818265 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 19, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.4566136400421227}. Best is trial 41 with value: 0.6070147331818265.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:12,167] Trial 42 finished with value: 0.5911675489618881 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 14, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.4435975515049473}. Best is trial 41 with value: 0.6070147331818265.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:12,639] Trial 43 finished with value: 0.5902551167662695 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 10, 'discr_encoder': 'ordinal', 'discr_strat': 'quantile', 'discrete_alpha': 0.43826223996925506}. Best is trial 41 with value: 0.6070147331818265.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:13,122] Trial 44 finished with value: -1.0 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2701651655950174}. Best is trial 41 with value: 0.6070147331818265.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (14) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:13,724] Trial 45 finished with value: 0.5928614623337664 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 21, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.42140210493735547}. Best is trial 41 with value: 0.6070147331818265.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:30:14,179] Trial 46 finished with value: 0.5839467397024358 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 15, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.4304088274418122}. Best is trial 41 with value: 0.6070147331818265.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:14,631] Trial 47 finished with value: 0.37307702381959806 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.6426226216177904, 'resample': True, 'kind': 'down', 'down_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.20070215625720605}. Best is trial 41 with value: 0.6070147331818265.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (32). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (32). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:15,419] Trial 48 finished with value: 0.6187476073730316 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 32, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.3301031691589599}. Best is trial 48 with value: 0.6187476073730316.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (33). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (33). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (33). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:16,057] Trial 49 finished with value: 0.4848333772208699 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.31537170199191056}. Best is trial 48 with value: 0.6187476073730316.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:16,453] Trial 50 finished with value: 0.3600226275531153 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.5184763387716942, 'resample': True, 'kind': 'down', 'down_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 31, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.31901389439248234}. Best is trial 48 with value: 0.6187476073730316.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (14) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:17,110] Trial 51 finished with value: 0.5928614623337664 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 21, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.5537158116892347}. Best is trial 48 with value: 0.6187476073730316.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:17,709] Trial 52 finished with value: 0.6243119441019802 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.42716021323893705}. Best is trial 52 with value: 0.6243119441019802.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (14) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:18,321] Trial 53 finished with value: 0.5987286111907094 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 21, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.13693765721169338}. Best is trial 52 with value: 0.6243119441019802.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:18,933] Trial 54 finished with value: 0.6243119441019802 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.3682303896336508}. Best is trial 52 with value: 0.6243119441019802.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:19,497] Trial 55 finished with value: 0.6255403425723025 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.15085991942748583}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (11). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:19,962] Trial 56 finished with value: 0.4530084498834499 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 11, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.35613946639461647}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:30:20,484] Trial 57 finished with value: 0.6108849401821784 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2365709104842733}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:30:21,041] Trial 58 finished with value: 0.6108849401821784 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1399651497905925}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:21,648] Trial 59 finished with value: 0.534291184733789 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.8712897137127738, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1458101376784129}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:22,140] Trial 60 finished with value: 0.5261733673523445 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'complement', 'discr_bins': 12, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2524600875971061}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:22,704] Trial 61 finished with value: 0.6255403425723025 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.14821241299422433}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:30:23,255] Trial 62 finished with value: 0.5980358768582571 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 13, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.0851429990042343}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:23,795] Trial 63 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.16268150571978188}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:24,336] Trial 64 finished with value: 0.6175526911452858 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.17244032375224985}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 18 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:24,813] Trial 65 finished with value: 0.6017876534442799 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 25, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 13, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.0994433082279289}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:25,219] Trial 66 finished with value: 0.6033832835828761 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 10, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.18107496931445843}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (14) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (24). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:25,803] Trial 67 finished with value: 0.6047861008086778 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 19, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 24, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.08225258800431745}. Best is trial 55 with value: 0.6255403425723025.\n",
      "[I 2024-01-10 12:30:26,057] Trial 68 finished with value: 0.5907805755418115 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0009677377038845069}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (35). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:26,754] Trial 69 finished with value: 0.5873128966577634 and parameters: {'scaler': 'std', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 35, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.22148558993028816}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 8 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 13 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:27,102] Trial 70 finished with value: -1.0 and parameters: {'scaler': 'norm', 'lof': True, 'lof_neighs': 15, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 16, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 40, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans'}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:27,768] Trial 71 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2855890226645556}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:28,426] Trial 72 finished with value: 0.6021081706396012 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 22, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.28325749338414274}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:29,025] Trial 73 finished with value: 0.6128260837546424 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1777843812229845}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:29,549] Trial 74 finished with value: 0.6104604146317161 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.3675500367756655}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:30,054] Trial 75 finished with value: 0.5814454956021222 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 14, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.3395602732729536}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (26). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:30,499] Trial 76 finished with value: 0.5446928980157846 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'complement', 'discr_bins': 26, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.3974465078385279}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:31,091] Trial 77 finished with value: 0.5780425960671594 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 30, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.27692932220323635}. Best is trial 55 with value: 0.6255403425723025.\n",
      "[I 2024-01-10 12:30:31,543] Trial 78 finished with value: 0.5932476718470814 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.6874382832784425, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'gauss', 'gauss_var_smoothing': 3.4397692153382816e-06}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:32,093] Trial 79 finished with value: 0.5906416264015826 and parameters: {'scaler': 'std', 'lof': True, 'lof_neighs': 12, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 23, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.0593173535403779}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 9 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:32,527] Trial 80 finished with value: 0.6092846323370169 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 14, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 12, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.12188169501115328}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:33,069] Trial 81 finished with value: 0.6105169996791422 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 19, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.17391666419546908}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:33,602] Trial 82 finished with value: 0.6163524748383729 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.20673614083602004}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:34,137] Trial 83 finished with value: 0.6243119441019802 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.21842435206635025}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 16 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 28 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 37 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 38 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:34,505] Trial 84 finished with value: -1.0 and parameters: {'scaler': 'norm', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans'}. Best is trial 55 with value: 0.6255403425723025.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (66). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (66). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:35,522] Trial 85 finished with value: 0.6322280190535658 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 66, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.25357548576375466}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (70). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (70). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:36,649] Trial 86 finished with value: 0.6163934662909756 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 70, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.24227946364890923}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (58). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (14) found smaller than n_clusters (58). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:37,493] Trial 87 finished with value: 0.6025829652075498 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.29635092501165017}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (64) found smaller than n_clusters (69). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (69). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (69). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (69). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:37,984] Trial 88 finished with value: 0.5804626098980938 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'complement', 'discr_bins': 69, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.25567584127320725}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:38,869] Trial 89 finished with value: 0.6119553115612405 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 22, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 66, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3423358391248316}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (51). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (51). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:39,650] Trial 90 finished with value: 0.6150458370777971 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 51, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.4034553570551427}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (13) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:30:40,184] Trial 91 finished with value: 0.6032284794475342 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 19, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.16068186825538502}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:40,741] Trial 92 finished with value: 0.6191148248036793 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.21074379999387816}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (44). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (44). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:41,504] Trial 93 finished with value: 0.6049796565663439 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 44, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.22341330495312944}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:42,080] Trial 94 finished with value: 0.5917893835323326 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 22, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.507663427265401}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:42,684] Trial 95 finished with value: 0.6191148248036793 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.20702489998327966}. Best is trial 85 with value: 0.6322280190535658.\n",
      "[I 2024-01-10 12:30:43,012] Trial 96 finished with value: 0.512046407812913 and parameters: {'scaler': 'std', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.5670228783460721, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0006755295268728816}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:43,563] Trial 97 finished with value: 0.4374427655677655 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1023695867010405}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 16 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 26 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 28 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 37 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 38 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:43,927] Trial 98 finished with value: -1.0 and parameters: {'scaler': 'norm', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 14, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans'}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:44,484] Trial 99 finished with value: 0.5764677487247862 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'categorical', 'discr_bins': 12, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.20475829202877477}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:45,001] Trial 100 finished with value: 0.5825466462450827 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 18, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2073602755269151}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (14) found smaller than n_clusters (25). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:45,686] Trial 101 finished with value: 0.6027930402930403 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 25, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.30724331019240436}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:30:46,274] Trial 102 finished with value: 0.6081485677162334 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.33324536264790483}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:46,887] Trial 103 finished with value: 0.6087761575260416 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.26084100577319547}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:47,547] Trial 104 finished with value: 0.605516774926596 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 22, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.14970336509010634}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:48,099] Trial 105 finished with value: 0.5872416834085157 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 14, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.28457965675273}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:48,838] Trial 106 finished with value: 0.6202120377740932 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 27, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2308583724928117}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (23) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:49,570] Trial 107 finished with value: 0.5837388463403512 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 22, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'categorical', 'discr_bins': 27, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.229538307753526}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:50,045] Trial 108 finished with value: 0.5609197117183715 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 23, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'complement', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.18607092446530443}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:50,821] Trial 109 finished with value: 0.5788730876387982 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 48, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.8972094946060888}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:51,269] Trial 110 finished with value: 0.3440208023008534 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.6791686942065284, 'resample': True, 'kind': 'down', 'down_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 10, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.12498548676499671}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (32). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (32). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:52,018] Trial 111 finished with value: 0.6083000333000333 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 32, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.36285625364380575}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (35). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (35). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:52,775] Trial 112 finished with value: 0.6089302854008736 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 35, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2364230226106417}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:53,371] Trial 113 finished with value: 0.6060567031835922 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 6, 'nb_type': 'categorical', 'discr_bins': 19, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.19862579237580585}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (13) found smaller than n_clusters (40). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:54,088] Trial 114 finished with value: 0.5685312405054086 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 7, 'nb_type': 'categorical', 'discr_bins': 40, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1635758878410153}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:30:54,616] Trial 115 finished with value: 0.596123730956798 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2644853214366933}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (51) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:55,423] Trial 116 finished with value: 0.5742417216782008 and parameters: {'scaler': 'std', 'lof': True, 'lof_neighs': 20, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 55, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.11692126402522032}. Best is trial 85 with value: 0.6322280190535658.\n",
      "[I 2024-01-10 12:30:55,824] Trial 117 finished with value: 0.5906734585448508 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0008060061918245757}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 8 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:56,329] Trial 118 finished with value: 0.5970331462940952 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 11, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 23, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.29553661181306745}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 16 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 17 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 18 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 22 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 25 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 28 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 31 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 37 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 38 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:56,797] Trial 119 finished with value: -1.0 and parameters: {'scaler': 'norm', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 29, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans'}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:57,457] Trial 120 finished with value: 0.5896558451852447 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 21, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.4673961444278538}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:58,042] Trial 121 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.18834345472535277}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:58,592] Trial 122 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.21599958549204323}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:59,112] Trial 123 finished with value: 0.6171913611623072 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 13, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.22078095306639284}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:30:59,660] Trial 124 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.14589349833635237}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:00,292] Trial 125 finished with value: 0.6163524748383729 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2005924760252446}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:00,860] Trial 126 finished with value: 0.6128260837546424 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.18885989247681242}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (75). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (75). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:01,892] Trial 127 finished with value: 0.5729614229614229 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 23, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 75, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.05987206904449516}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:02,412] Trial 128 finished with value: 0.6001741679373258 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.24756716086183683}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:31:03,018] Trial 129 finished with value: 0.5944095412974468 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 13, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2205897829611924}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:03,877] Trial 130 finished with value: 0.32696183923914957 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.8786659177730052, 'resample': True, 'kind': 'down', 'down_neighs': 6, 'nb_type': 'complement', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.1617514910455396}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:04,594] Trial 131 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1433663979417186}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:05,214] Trial 132 finished with value: 0.621450907603772 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.10660588393589877}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:05,783] Trial 133 finished with value: 0.6151180459107288 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 11, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.09143432900901433}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:06,387] Trial 134 finished with value: 0.6067898733659604 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 19, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.013617657473026956}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:31:06,930] Trial 135 finished with value: 0.5974674644855368 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.11866742787780027}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:07,544] Trial 136 finished with value: 0.6128260837546424 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.17004339208761238}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (14). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:08,691] Trial 137 finished with value: 0.5868528593399727 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 14, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.07165543286857075}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 16 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:09,387] Trial 138 finished with value: 0.6024050883667912 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.7883044082338857, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2636337701467288}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (20) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:09,860] Trial 139 finished with value: 0.5675231384471707 and parameters: {'scaler': 'std', 'lof': True, 'lof_neighs': 24, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 20, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 21, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.18114706690018828}. Best is trial 85 with value: 0.6322280190535658.\n",
      "[I 2024-01-10 12:31:10,190] Trial 140 finished with value: 0.6011030926495149 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.00019922551691166801}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:10,833] Trial 141 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.14703457960753202}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (12). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:11,384] Trial 142 finished with value: 0.6088351793384112 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 12, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.10442566419792813}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:12,003] Trial 143 finished with value: 0.6105169996791422 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 19, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2152661036139968}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (63). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (63). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:12,945] Trial 144 finished with value: 0.6050514254136197 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 63, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1912698995793877}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:13,575] Trial 145 finished with value: 0.620098374408341 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.12988804087874026}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 16 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 28 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 37 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 38 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:13,973] Trial 146 finished with value: -1.0 and parameters: {'scaler': 'norm', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 14, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans'}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:14,576] Trial 147 finished with value: 0.6087761575260416 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.23689673723967697}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:15,140] Trial 148 finished with value: 0.5985086701242701 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 22, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.4115230967532084}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:15,595] Trial 149 finished with value: 0.5938314897558472 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 17, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'bernoulli', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.13248861322760627}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:16,106] Trial 150 finished with value: 0.6188365762358854 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 22, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.032122952171849406}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:16,654] Trial 151 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.3822102098980379}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:17,190] Trial 152 finished with value: 0.594527735038684 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.15224647163595761}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:17,733] Trial 153 finished with value: 0.6184065363172799 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 13, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.12966662093014222}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:18,277] Trial 154 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.17670525544086135}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (13) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:31:18,971] Trial 155 finished with value: 0.5961353952267905 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 19, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.28121714162905037}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:19,459] Trial 156 finished with value: 0.46822409739737036 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.24087047785231722}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:20,073] Trial 157 finished with value: 0.5655426367881173 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.8001211100953917, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 12, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1053721576014166}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:20,630] Trial 158 finished with value: 0.6242021925985621 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 24, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.20077459701838407}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:21,066] Trial 159 finished with value: 0.5293359079603323 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'complement', 'discr_bins': 24, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.19983428389287383}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:21,650] Trial 160 finished with value: 0.6169507934594142 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.7615956488761338, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'categorical', 'discr_bins': 25, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.21573176434411817}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:22,232] Trial 161 finished with value: 0.613909038989143 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 21, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.16199053516480869}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:22,744] Trial 162 finished with value: 0.5867100125526263 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.1904510542941624}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:23,289] Trial 163 finished with value: 0.6087761575260416 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2528091673864691}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:23,850] Trial 164 finished with value: 0.5832721529619518 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.636884489501775}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:24,421] Trial 165 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.14460498856635107}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (23). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:25,064] Trial 166 finished with value: 0.6071900602428523 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 23, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.22662834220672273}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 8 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:25,571] Trial 167 finished with value: 0.6197357734793221 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 11, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 11, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1694163450435306}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (16) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:25,997] Trial 168 finished with value: 0.5345117298431905 and parameters: {'scaler': 'std', 'lof': True, 'lof_neighs': 25, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 11, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 19, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1747692842964694}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:26,408] Trial 169 finished with value: 0.5775709878513617 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 10, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 14, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.3120146738725338}. Best is trial 85 with value: 0.6322280190535658.\n",
      "[I 2024-01-10 12:31:26,746] Trial 170 finished with value: 0.6060277991005258 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 10, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 14, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0006205028975055703}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (8) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 14 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:27,265] Trial 171 finished with value: 0.5833648214663458 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 14, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 21, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.15771511738571753}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:27,694] Trial 172 finished with value: 0.5578399840236282 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 19, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 8, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 7, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.12515170441474993}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:31:28,242] Trial 173 finished with value: 0.596123730956798 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 14, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2074607445916644}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:28,896] Trial 174 finished with value: 0.6128260837546424 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.19491953408634974}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (21). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:29,614] Trial 175 finished with value: 0.5956717796807076 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 21, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.26767011392225876}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 16 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 28 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 37 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 38 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:30,033] Trial 176 finished with value: -1.0 and parameters: {'scaler': 'norm', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans'}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:30,629] Trial 177 finished with value: 0.6143610998704255 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 13, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.07922372047455611}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 9 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:31,052] Trial 178 finished with value: 0.6039509701210819 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 13, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.16797201744998178}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:31,568] Trial 179 finished with value: 0.5968341517132345 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.23213152827780575}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:31,979] Trial 180 finished with value: 0.35892087720205645 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.561168109184339, 'resample': True, 'kind': 'down', 'down_neighs': 6, 'nb_type': 'categorical', 'discr_bins': 19, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.11882933366010592}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:32,573] Trial 181 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1472047879140698}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (20) found smaller than n_clusters (38). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (38). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:33,357] Trial 182 finished with value: 0.5946262809125495 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 18, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 38, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1483626909297315}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:34,005] Trial 183 finished with value: 0.5931088322654587 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 14, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.18161646116476082}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:34,559] Trial 184 finished with value: 0.624125268690637 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'bernoulli', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.13671971525552318}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:34,985] Trial 185 finished with value: 0.43130077955222923 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'bernoulli', 'discr_bins': 17, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.10153204887805696}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:35,632] Trial 186 finished with value: 0.6128260837546424 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.19813796985286553}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:31:36,193] Trial 187 finished with value: 0.6015575273822309 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.491626549012408}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (22). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:36,687] Trial 188 finished with value: 0.605516774926596 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 22, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.12764981745732445}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:37,123] Trial 189 finished with value: 0.6133491002374349 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'bernoulli', 'discr_bins': 11, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2175359709340735}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (15). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:31:37,681] Trial 190 finished with value: 0.596123730956798 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.24902392480661922}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:38,296] Trial 191 finished with value: 0.6188486320871702 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1390581450977375}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:38,857] Trial 192 finished with value: 0.6175526911452858 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.16254969119649582}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (19). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:39,510] Trial 193 finished with value: 0.6105169996791422 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 19, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.17652583342910808}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 8 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (13). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:40,165] Trial 194 finished with value: 0.5839001823211782 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.6129789599879719, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 13, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.4550979537959644}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:40,865] Trial 195 finished with value: 0.6032152893959515 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 20, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.09380320338226003}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2024-01-10 12:31:41,502] Trial 196 finished with value: 0.6108849401821784 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 16, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.14212179156410001}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (73). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (73). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:42,148] Trial 197 finished with value: 0.5379954789868807 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 23, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'complement', 'discr_bins': 73, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.21009414540589727}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (11) found smaller than n_clusters (27). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:42,881] Trial 198 finished with value: 0.5783191286012763 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 2, 'nb_type': 'categorical', 'discr_bins': 27, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.11279176559682111}. Best is trial 85 with value: 0.6322280190535658.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (37) found smaller than n_clusters (42). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (42). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:43,630] Trial 199 finished with value: 0.6338700290018748 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 6, 'nb_type': 'categorical', 'discr_bins': 42, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.06013090427769875}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:44,197] Trial 200 finished with value: 0.6107689716032382 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 6, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.06442015288519269}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (31) found smaller than n_clusters (43). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (18) found smaller than n_clusters (43). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:44,930] Trial 201 finished with value: 0.5964330839677192 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 5, 'nb_type': 'categorical', 'discr_bins': 43, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.04026769902457154}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (41) found smaller than n_clusters (57). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (18) found smaller than n_clusters (57). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:45,807] Trial 202 finished with value: 0.6106951125099945 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.18749814207777826}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (64). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (64). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:46,839] Trial 203 finished with value: 0.5906197639916257 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 64, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1590640941090098}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:47,437] Trial 204 finished with value: 0.5934985354800726 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 6, 'nb_type': 'categorical', 'discr_bins': 15, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1331771089738623}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (38) found smaller than n_clusters (53). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (53). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:48,315] Trial 205 finished with value: 0.628816297195579 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 11, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 53, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.0825924098163953}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (43) found smaller than n_clusters (54). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (13) found smaller than n_clusters (54). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:49,210] Trial 206 finished with value: 0.6066547318784455 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 12, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 7, 'nb_type': 'categorical', 'discr_bins': 54, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.08984735351247383}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (60). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:49,995] Trial 207 finished with value: 0.6288937787115503 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 17, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 7, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.06371060385693465}. Best is trial 199 with value: 0.6338700290018748.\n",
      "[I 2024-01-10 12:31:50,417] Trial 208 finished with value: 0.5861334988655897 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 11, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 17, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.00031939485234364594}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:51,162] Trial 209 finished with value: -1.0 and parameters: {'scaler': 'norm', 'lof': True, 'lof_neighs': 11, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 21, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 63, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.019712042612810038}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:51,676] Trial 210 finished with value: 0.5169284931397973 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 11, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 9, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'bernoulli', 'discr_bins': 71, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.05692731455975977}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (21) found smaller than n_clusters (50). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 9 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:52,270] Trial 211 finished with value: 0.5849257938986457 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 10, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 12, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 50, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.05640868655801489}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (68). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:53,010] Trial 212 finished with value: 0.5879506750053509 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 19, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 7, 'nb_type': 'categorical', 'discr_bins': 68, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.07260860209223088}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (37) found smaller than n_clusters (46). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (46). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:53,913] Trial 213 finished with value: 0.5972693223255864 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 6, 'nb_type': 'categorical', 'discr_bins': 46, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.23517688931487396}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (38) found smaller than n_clusters (65). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (65). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:54,908] Trial 214 finished with value: 0.6140310621182656 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 12, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 65, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.0846454932442224}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (61). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (61). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (61). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:55,674] Trial 215 finished with value: 0.408403022553966 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.10915649620705602}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (18). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:56,093] Trial 216 finished with value: 0.5823267469987328 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 18, 'discr_encoder': 'ordinal', 'discr_strat': 'kmeans', 'discrete_alpha': 0.21838212329729695}. Best is trial 199 with value: 0.6338700290018748.\n",
      "[I 2024-01-10 12:31:56,550] Trial 217 finished with value: 0.4315648324106971 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'top', 'top_k': 15, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.7080236336986733, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.34918852658572497}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (43) found smaller than n_clusters (58). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (13) found smaller than n_clusters (58). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:57,441] Trial 218 finished with value: 0.6005140943042353 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 7, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.03825894173020318}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (67). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (67). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:58,365] Trial 219 finished with value: 0.6052302272677865 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 67, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2893334182700552}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:58,919] Trial 220 finished with value: 0.6255403425723025 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.19013771762600548}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:31:59,702] Trial 221 finished with value: 0.6255403425723025 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1871965564482158}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (53). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (53). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:00,688] Trial 222 finished with value: 0.6189066980878819 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 53, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.19218543522911655}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (17). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:01,418] Trial 223 finished with value: 0.6255403425723025 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 17, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1840822882069498}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (51). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (51). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:02,294] Trial 224 finished with value: 0.6109173378136638 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 51, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.19881192610993967}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (56). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (56). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:03,317] Trial 225 finished with value: 0.6303163758755864 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.1731887109194662}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (52) found smaller than n_clusters (53). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (53). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:04,398] Trial 226 finished with value: 0.5983620546120546 and parameters: {'scaler': 'power', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 53, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.5200994902077438}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (56). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 8 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (56). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:05,048] Trial 227 finished with value: 0.53904736830128 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 30, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.6598843017443955, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.16932056007391746}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (57). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (57). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:05,936] Trial 228 finished with value: 0.6125220331047398 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.17651035960064476}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (53). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (53). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:06,974] Trial 229 finished with value: 0.6189066980878819 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 53, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.19244553292308822}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (53). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (53). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:08,028] Trial 230 finished with value: 0.6189066980878819 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 53, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.19167019055052698}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:09,092] Trial 231 finished with value: 0.6267304020737949 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 55, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.19991022668118785}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:09,976] Trial 232 finished with value: 0.6251094176941898 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 55, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.20943687667393118}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:10,928] Trial 233 finished with value: 0.6251094176941898 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 55, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.21404207312474186}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:12,013] Trial 234 finished with value: 0.6251095505183284 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 55, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.22530925970779048}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (56). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (56). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:12,999] Trial 235 finished with value: 0.6299785122417834 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.24344015118817058}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (55). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:13,935] Trial 236 finished with value: 0.6195555732926867 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 55, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.24582714907585246}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (24) found smaller than n_clusters (56). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/base.py:1152: ConvergenceWarning: Number of distinct clusters (17) found smaller than n_clusters (56). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:14,816] Trial 237 finished with value: 0.6299785122417834 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'kmeans', 'discrete_alpha': 0.2502508740581288}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:15,775] Trial 238 finished with value: 0.6269632452124552 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.23548225770703127}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:16,675] Trial 239 finished with value: 0.6269632452124552 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2600171245761979}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:17,544] Trial 240 finished with value: 0.6269632452124552 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2628660946338456}. Best is trial 199 with value: 0.6338700290018748.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:18,386] Trial 241 finished with value: 0.6363704046630876 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.259608694502218}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:19,247] Trial 242 finished with value: 0.5841970708580003 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.26447003585809625}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:20,186] Trial 243 finished with value: 0.6270395309685091 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.27346709792289686}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:21,018] Trial 244 finished with value: 0.6269632452124552 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2654513235558648}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:21,859] Trial 245 finished with value: 0.6238367719864161 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2724662631625641}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:22,893] Trial 246 finished with value: 0.6363704046630876 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.26329975683242807}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:23,838] Trial 247 finished with value: 0.6363704046630876 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.25586687082449394}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:24,731] Trial 248 finished with value: 0.6270395309685091 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.29608364167983975}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:25,701] Trial 249 finished with value: 0.6270395309685091 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3031335644577162}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:26,692] Trial 250 finished with value: 0.6270395309685091 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2988106036557482}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:27,630] Trial 251 finished with value: 0.6270395309685091 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2947292382166359}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:28,483] Trial 252 finished with value: 0.6270395309685091 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.30718890603286336}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:29,214] Trial 253 finished with value: -1.0 and parameters: {'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.30488784404911423}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:30,027] Trial 254 finished with value: 0.6270395309685091 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.31902979626253614}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:30,318] Trial 255 finished with value: 0.4669871673650928 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'complement', 'discr_bins': 59, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.32468661355145306}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:31,005] Trial 256 finished with value: -1.0 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.8850727642964795, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2939614575126677}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:31,646] Trial 257 finished with value: -1.0 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 4, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2821910664354879}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:32,526] Trial 258 finished with value: 0.6270395309685091 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3175519215119154}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:33,247] Trial 259 finished with value: 0.5359436916022224 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.590713222052444, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.31956030274944064}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:34,280] Trial 260 finished with value: -1.0 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.30450300717993445}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:35,002] Trial 261 finished with value: -1.0 and parameters: {'scaler': 'norm', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2689977366689177}. Best is trial 241 with value: 0.6363704046630876.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:35,874] Trial 262 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2809558704243822}. Best is trial 262 with value: 0.6418184346909495.\n",
      "[I 2024-01-10 12:32:36,163] Trial 263 finished with value: 0.5957872335997336 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0008232584987944588}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:37,127] Trial 264 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2897681140824891}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:38,067] Trial 265 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2872390761025639}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:38,955] Trial 266 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.330289107010187}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:39,792] Trial 267 finished with value: 0.6196441803738382 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3253923794218537}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:40,601] Trial 268 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2952304444601965}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:41,432] Trial 269 finished with value: 0.5895500547562404 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.29899314019820616}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:42,265] Trial 270 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3357998784300366}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:43,081] Trial 271 finished with value: 0.6040447056707219 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.34073126660567254}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:44,023] Trial 272 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.31580059591690307}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:44,967] Trial 273 finished with value: 0.5803404872053239 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.31535444375836086}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:45,906] Trial 274 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.29148128611412993}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:46,832] Trial 275 finished with value: 0.5841970708580003 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2888999201699236}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:47,187] Trial 276 finished with value: 0.5944941387337701 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 63, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.34571347243396316}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:47,903] Trial 277 finished with value: -1.0 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 5, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2898511727503325}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:48,392] Trial 278 finished with value: 0.4782872970266858 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.6557054641263643, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'complement', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.30345027396607516}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:49,231] Trial 279 finished with value: 0.6238367719864161 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.27892959517205634}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:49,830] Trial 280 finished with value: -1.0 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.6600484460132726, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.36714353661602406}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:50,665] Trial 281 finished with value: 0.6196441803738382 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.31969460661025273}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:51,504] Trial 282 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.33363928784821095}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:52,407] Trial 283 finished with value: 0.5928427450409381 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 64, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.28768030624219804}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:53,388] Trial 284 finished with value: 0.6286698959220031 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3323313710159718}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:54,227] Trial 285 finished with value: 0.6286698959220031 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.33624068751112896}. Best is trial 262 with value: 0.6418184346909495.\n",
      "[I 2024-01-10 12:32:54,497] Trial 286 finished with value: 0.35998319964641234 and parameters: {'scaler': 'norm', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.00011639364234322322}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:55,553] Trial 287 finished with value: -1.0 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.33777212548216073}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:56,558] Trial 288 finished with value: 0.6285991357252847 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.38167716743129504}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:57,481] Trial 289 finished with value: 0.6282291095404117 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3739798615493118}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:58,336] Trial 290 finished with value: 0.5878338269295715 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 64, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.37674018644767004}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:59,175] Trial 291 finished with value: 0.6282291095404117 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3277206874952723}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:32:59,856] Trial 292 finished with value: 0.5939123956538817 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 41, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3508065024905863}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:00,716] Trial 293 finished with value: 0.5911873940232526 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 63, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3631878840643116}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:01,479] Trial 294 finished with value: 0.5803404872053239 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3433387666798748}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:02,375] Trial 295 finished with value: 0.570059271351612 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 65, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.39402064481336835}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:03,267] Trial 296 finished with value: 0.6286698959220031 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.33071959431632564}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:04,259] Trial 297 finished with value: 0.6286698959220031 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3333614027630389}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:05,425] Trial 298 finished with value: 0.507746114378039 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.9464805211507811, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.3590065480407877}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:06,263] Trial 299 finished with value: -1.0 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.38023170411666596}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:07,229] Trial 300 finished with value: 0.6306513479210847 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.33846929673506526}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:07,946] Trial 301 finished with value: 0.6053510030786617 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.7587448740070102, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3405420607028863}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:08,803] Trial 302 finished with value: 0.6359567207423227 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.33201193849015836}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:09,627] Trial 303 finished with value: 0.6306513479210847 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.34567549727424457}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:10,089] Trial 304 finished with value: 0.530498115545516 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 14, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.254088038015946}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:10,958] Trial 305 finished with value: 0.6308943112005574 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.0032821886656885235}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:11,502] Trial 306 finished with value: 0.5063515046841605 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'complement', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.005504070981235593}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:12,331] Trial 307 finished with value: 0.5826575668743477 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.025299231898052034}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:13,221] Trial 308 finished with value: 0.6129948834383594 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.9754628669924558}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:14,176] Trial 309 finished with value: 0.592145637091914 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2752887804522466}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:14,979] Trial 310 finished with value: -1.0 and parameters: {'scaler': 'norm', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.35134754013210634}. Best is trial 262 with value: 0.6418184346909495.\n",
      "[I 2024-01-10 12:33:15,352] Trial 311 finished with value: 0.6013476654924024 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0003723294526756063}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:16,501] Trial 312 finished with value: -1.0 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 54, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2525352165935859}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:17,342] Trial 313 finished with value: 0.4905433787227266 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.0014473499314210457}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:17,856] Trial 314 finished with value: 0.5324702848848264 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 16, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 7, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.31553525421217765}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:18,778] Trial 315 finished with value: 0.6359567207423227 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3290992993296187}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:19,689] Trial 316 finished with value: 0.6180427145107973 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.040958541945991515}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:20,133] Trial 317 finished with value: 0.46415810067125857 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.5991778536008429, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 54, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.281665630314233}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:20,516] Trial 318 finished with value: 0.6250376301230789 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.3150445279926568}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:21,333] Trial 319 finished with value: 0.6097823345566773 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 41, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2532185788616815}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 20 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:22,183] Trial 320 finished with value: 0.3986519520992534 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.2817216378396136}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:22,801] Trial 321 finished with value: 0.5639312602861741 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.5215494841703318, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.35793700243317256}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:23,826] Trial 322 finished with value: 0.5904950512743234 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 7, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3048608656362905}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:24,774] Trial 323 finished with value: 0.5938896210172806 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 46, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.24623657186162767}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:25,669] Trial 324 finished with value: 0.6155604375010297 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 6, 'nb_type': 'categorical', 'discr_bins': 54, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3273232946763856}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:26,574] Trial 325 finished with value: 0.6302750262983292 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.26854350198631993}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:27,032] Trial 326 finished with value: 0.5395941055355908 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': True, 'feat_sel_type': 'perc', 'perc': 20, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2737423911365683}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:27,868] Trial 327 finished with value: 0.6371017921460147 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.26671028752424253}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:28,837] Trial 328 finished with value: 0.6362678100030641 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2605441975654612}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:29,699] Trial 329 finished with value: 0.6371017921460147 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.27053398938563633}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:30,151] Trial 330 finished with value: 0.5464410483457197 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'complement', 'discr_bins': 55, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2705995591330996}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:30,865] Trial 331 finished with value: -1.0 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.29179648378039047}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:31,728] Trial 332 finished with value: 0.6302750262983292 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2442139918834405}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:32,632] Trial 333 finished with value: 0.6302750262983292 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.26247152871087154}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:33,462] Trial 334 finished with value: 0.6302750262983292 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2858351164354147}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:34,224] Trial 335 finished with value: 0.5760755520189482 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3072763869660414}. Best is trial 262 with value: 0.6418184346909495.\n",
      "[I 2024-01-10 12:33:34,565] Trial 336 finished with value: 0.6019297850410927 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0008840415534028988}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:35,316] Trial 337 finished with value: -1.0 and parameters: {'scaler': 'norm', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 43, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2569204249273276}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:35,948] Trial 338 finished with value: -1.0 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.8469774774643372, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2745251992353273}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:36,975] Trial 339 finished with value: -1.0 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 73, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.23474218611403996}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:37,435] Trial 340 finished with value: 0.5591915120325865 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.5002500389211992, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.29675946011227017}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:38,300] Trial 341 finished with value: 0.6053446553446553 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 55, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3119891330360743}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:39,033] Trial 342 finished with value: -1.0 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 8, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.2838796397854613}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:40,027] Trial 343 finished with value: 0.596990886788016 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 63, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.26022388989347656}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:40,957] Trial 344 finished with value: 0.62258901981328 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 52, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.23541341205953153}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:41,918] Trial 345 finished with value: 0.6126445206858223 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 58, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.31679091339258725}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:42,842] Trial 346 finished with value: 0.624902913812729 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4105513137328552}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:43,428] Trial 347 finished with value: 0.62784062002812 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'bernoulli', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.27636613892513484}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:44,399] Trial 348 finished with value: 0.6306513479210847 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3458495942381968}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:45,371] Trial 349 finished with value: 0.5989377278690501 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 66, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.34010441989829615}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:46,296] Trial 350 finished with value: 0.5977576251829984 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 10, 'nb_type': 'categorical', 'discr_bins': 55, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.36746758688454106}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:47,335] Trial 351 finished with value: 0.5911873940232526 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 63, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.35463676909870884}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:48,301] Trial 352 finished with value: 0.6306513479210847 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 9, 'nb_type': 'categorical', 'discr_bins': 57, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3175714997376426}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:48,752] Trial 353 finished with value: 0.6090868792994844 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'complement', 'discr_bins': 56, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.32428868161646557}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:49,741] Trial 354 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3498978085288123}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:50,682] Trial 355 finished with value: 0.6418184346909495 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.35545509241843254}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:51,416] Trial 356 finished with value: -1.0 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 64, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.5705977623944682}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:51,849] Trial 357 finished with value: -1.0 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.5475195477605808, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.35596428491243537}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:52,755] Trial 358 finished with value: 0.6093607739978342 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.3743215181741253}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:53,776] Trial 359 finished with value: 0.6362542484093144 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.39472835192615724}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:54,386] Trial 360 finished with value: 0.5270684852319872 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.5976369361853001, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.42969446927647204}. Best is trial 262 with value: 0.6418184346909495.\n",
      "[I 2024-01-10 12:33:54,690] Trial 361 finished with value: 0.36347017663632086 and parameters: {'scaler': 'norm', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'gauss', 'gauss_var_smoothing': 0.0007033935400968937}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 20 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:55,034] Trial 362 finished with value: 0.39410773801017707 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 5, 'nb_type': 'categorical', 'discr_bins': 62, 'discr_encoder': 'ordinal', 'discr_strat': 'quantile', 'discrete_alpha': 0.39471739497709735}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:55,912] Trial 363 finished with value: 0.6362542484093144 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.39368649260123323}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:57,032] Trial 364 finished with value: -1.0 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 69, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.39285939809563053}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:57,941] Trial 365 finished with value: 0.6362542484093144 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.39838747999689694}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:58,963] Trial 366 finished with value: 0.6408124957616916 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4347247471355133}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:33:59,909] Trial 367 finished with value: 0.5712379530415156 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 65, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.39868241116243786}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:00,946] Trial 368 finished with value: 0.613120992350235 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 63, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4172736363121297}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:01,911] Trial 369 finished with value: 0.6082175897909552 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.47513460167801913}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:02,792] Trial 370 finished with value: 0.6408124957616916 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.44931870124843565}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:03,649] Trial 371 finished with value: 0.6408124957616916 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4471872890209259}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:04,479] Trial 372 finished with value: 0.6408124957616916 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.43107602427415426}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:05,307] Trial 373 finished with value: 0.6408124957616916 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'categorical', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.45402752571499355}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:05,815] Trial 374 finished with value: 0.6408124957616916 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4482636585966998}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:06,290] Trial 375 finished with value: 0.5888778506753056 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'bernoulli', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.46483301421476364}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:06,883] Trial 376 finished with value: 0.6408124957616916 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4258581059581408}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:07,519] Trial 377 finished with value: 0.6408124957616916 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.447495853149396}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:08,280] Trial 378 finished with value: 0.46088237010677674 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': True, 'pca_ratio': 0.8444898317225751, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4465266600071982}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:08,820] Trial 379 finished with value: 0.6049528165009992 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.443853773348543}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:09,364] Trial 380 finished with value: 0.6256923176608497 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4796655613599443}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:09,824] Trial 381 finished with value: 0.2899466063671461 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': True, 'corr_value': 0.6376739155234938, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 63, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.44150169352276364}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:10,331] Trial 382 finished with value: 0.5951261053456485 and parameters: {'scaler': 'std', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.42629839273493714}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:10,864] Trial 383 finished with value: 0.6082175897909552 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4927872076989691}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:11,336] Trial 384 finished with value: 0.40160916923628787 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'down', 'down_neighs': 6, 'nb_type': 'bernoulli', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.514425637757845}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:11,891] Trial 385 finished with value: 0.6093607739978342 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4604548503172262}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:12,465] Trial 386 finished with value: 0.6256923176608497 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4556093593480905}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:13,016] Trial 387 finished with value: 0.6408124957616916 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.42095518927388637}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:13,624] Trial 388 finished with value: 0.592227118809343 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 64, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4253929751174089}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:14,156] Trial 389 finished with value: 0.5007172178224809 and parameters: {'scaler': 'norm', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.43903133511249587}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:14,703] Trial 390 finished with value: 0.6034473211899034 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 62, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.46748957822907655}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:15,307] Trial 391 finished with value: 0.6180802303492409 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 4, 'nb_type': 'bernoulli', 'discr_bins': 61, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4951273704471291}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:15,937] Trial 392 finished with value: 0.5919982705528412 and parameters: {'scaler': 'power', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 60, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.42985951332723704}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 20 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 23 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 24 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 29 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:16,521] Trial 393 finished with value: 0.6024746335045245 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 59, 'discr_encoder': 'onehot-dense', 'discr_strat': 'quantile', 'discrete_alpha': 0.41325882479495474}. Best is trial 262 with value: 0.6418184346909495.\n",
      "/media/valentino/Irithyll1/repos/ClubFansIris/env/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n",
      "[I 2024-01-10 12:34:17,384] Trial 394 finished with value: 0.6073538160023144 and parameters: {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': True, 'kind': 'up', 'up_neighs': 3, 'nb_type': 'bernoulli', 'discr_bins': 63, 'discr_encoder': 'onehot-dense', 'discr_strat': 'uniform', 'discrete_alpha': 0.4517426245513831}. Best is trial 262 with value: 0.6418184346909495.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"tuning__{}\".format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")), storage=\"sqlite:///db.sqlite3\")\n",
    "\n",
    "study.optimize(BNTuning.objective_function, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': 'quan',\n",
       " 'lof': False,\n",
       " 'feature_selection': False,\n",
       " 'delete_correlated': False,\n",
       " 'pca': False,\n",
       " 'resample': False,\n",
       " 'nb_type': 'categorical',\n",
       " 'discr_bins': 33,\n",
       " 'discr_encoder': 'ordinal',\n",
       " 'discr_strat': 'uniform',\n",
       " 'discrete_alpha': 0.16637065913436855}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = study.best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=502, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 2, 32, 617513), datetime_complete=datetime.datetime(2024, 1, 10, 12, 2, 32, 800080), params={'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.16637065913436855}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=502, value=None),\n",
       " FrozenTrial(number=509, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 2, 34, 167897), datetime_complete=datetime.datetime(2024, 1, 10, 12, 2, 34, 350877), params={'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.13313117992514575}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=509, value=None),\n",
       " FrozenTrial(number=520, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 2, 36, 715902), datetime_complete=datetime.datetime(2024, 1, 10, 12, 2, 36, 927221), params={'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.15496247103756228}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=520, value=None),\n",
       " FrozenTrial(number=524, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 2, 37, 463262), datetime_complete=datetime.datetime(2024, 1, 10, 12, 2, 37, 670517), params={'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.11120847276917395}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=524, value=None),\n",
       " FrozenTrial(number=527, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 2, 38, 38428), datetime_complete=datetime.datetime(2024, 1, 10, 12, 2, 38, 211511), params={'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.1477756493880194}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=527, value=None),\n",
       " FrozenTrial(number=609, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 4, 573741), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 4, 789352), params={'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.10074170832177116}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=609, value=None),\n",
       " FrozenTrial(number=613, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 5, 704754), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 5, 889634), params={'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.10349623029936661}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=613, value=None),\n",
       " FrozenTrial(number=630, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 11, 196016), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 11, 379229), params={'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.1325402761697171}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=630, value=None),\n",
       " FrozenTrial(number=641, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 13, 865415), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 14, 81835), params={'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.16145893046850693}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=641, value=None),\n",
       " FrozenTrial(number=682, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 24, 18845), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 24, 282327), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.15960186925359876}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=682, value=None),\n",
       " FrozenTrial(number=695, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 27, 267618), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 27, 492712), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.1403244914998427}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=695, value=None),\n",
       " FrozenTrial(number=712, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 31, 883468), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 32, 87534), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.14534549410251607}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=712, value=None),\n",
       " FrozenTrial(number=729, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 36, 670127), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 36, 893812), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.09597232220342211}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=729, value=None),\n",
       " FrozenTrial(number=732, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 37, 425731), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 37, 665914), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.11553975472933624}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=732, value=None),\n",
       " FrozenTrial(number=739, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 39, 555322), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 39, 790951), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.14372099905726535}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=739, value=None),\n",
       " FrozenTrial(number=741, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 40, 55041), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 40, 281181), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.14555924405871817}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=741, value=None),\n",
       " FrozenTrial(number=793, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 3, 55, 181959), datetime_complete=datetime.datetime(2024, 1, 10, 12, 3, 55, 417761), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.14686705017153792}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=793, value=None),\n",
       " FrozenTrial(number=821, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 3, 636019), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 3, 870907), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.11081610520989177}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=821, value=None),\n",
       " FrozenTrial(number=822, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 3, 872414), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 4, 159497), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 24, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.0922478741118562}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=822, value=None),\n",
       " FrozenTrial(number=840, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 8, 824320), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 9, 59846), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 28, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.09363179937664405}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=840, value=None),\n",
       " FrozenTrial(number=895, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 24, 40333), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 24, 332404), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.14737129503540247}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=895, value=None),\n",
       " FrozenTrial(number=929, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 33, 646415), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 33, 933761), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 29, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.09441730123377413}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=929, value=None),\n",
       " FrozenTrial(number=953, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 39, 976666), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 40, 214462), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.1503571563253817}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=953, value=None),\n",
       " FrozenTrial(number=963, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 42, 720516), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 42, 970388), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.12614515021613512}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=963, value=None),\n",
       " FrozenTrial(number=970, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 44, 685739), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 44, 928803), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 25, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.16276064001972324}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=970, value=None),\n",
       " FrozenTrial(number=982, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 47, 934462), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 48, 184430), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 26, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.136483861274554}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=982, value=None),\n",
       " FrozenTrial(number=991, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 50, 264076), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 50, 522393), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 27, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.10462695977751535}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=991, value=None),\n",
       " FrozenTrial(number=999, state=TrialState.COMPLETE, values=[0.643702505462374], datetime_start=datetime.datetime(2024, 1, 10, 12, 4, 52, 415753), datetime_complete=datetime.datetime(2024, 1, 10, 12, 4, 52, 663903), params={'scaler': 'quan', 'lof': True, 'lof_neighs': 16, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.16012745732884495}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'scaler': CategoricalDistribution(choices=('std', 'norm', 'quan', 'power')), 'lof': CategoricalDistribution(choices=(True, False)), 'lof_neighs': IntDistribution(high=30, log=False, low=10, step=1), 'feature_selection': CategoricalDistribution(choices=(True, False)), 'delete_correlated': CategoricalDistribution(choices=(True, False)), 'pca': CategoricalDistribution(choices=(True, False)), 'resample': CategoricalDistribution(choices=(True, False)), 'nb_type': CategoricalDistribution(choices=('gauss', 'categorical', 'complement', 'bernoulli')), 'discr_bins': IntDistribution(high=75, log=False, low=10, step=1), 'discr_encoder': CategoricalDistribution(choices=('onehot-dense', 'ordinal')), 'discr_strat': CategoricalDistribution(choices=('uniform', 'quantile', 'kmeans')), 'discrete_alpha': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=999, value=None)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standarize': True,\n",
       " 'scaler': 'power',\n",
       " 'lof': True,\n",
       " 'lof_neighs': 10,\n",
       " 'feature_selection': True,\n",
       " 'feat_sel_type': 'top',\n",
       " 'top_k': 17,\n",
       " 'delete_correlated': False,\n",
       " 'pca': False,\n",
       " 'resample': False}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_trials = BNTuning.trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNTuning.trial = self_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant                         F1 Score    Train Acc    Test Acc  Parameters\n",
      "----------------------------  ----------  -----------  ----------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "tuning__20240110-120047__502      0.6391      82.8729     64.8352  {'scaler': 'quan', 'lof': False, 'feature_selection': False, 'delete_correlated': False, 'pca': False, 'resample': False, 'nb_type': 'categorical', 'discr_bins': 33, 'discr_encoder': 'ordinal', 'discr_strat': 'uniform', 'discrete_alpha': 0.16637065913436855}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = BNTuning.get_k_best_trials(study, k=1,save_kaggle=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standarize': True,\n",
       " 'scaler': 'power',\n",
       " 'lof': True,\n",
       " 'lof_neighs': 12,\n",
       " 'feature_selection': True,\n",
       " 'feat_sel_type': 'top',\n",
       " 'top_k': 24,\n",
       " 'delete_correlated': False,\n",
       " 'pca': False,\n",
       " 'resample': False}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"tuning__20240109-170403__378\"][\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = study.get_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': 'quan',\n",
       " 'lof': False,\n",
       " 'feature_selection': False,\n",
       " 'delete_correlated': False,\n",
       " 'pca': False,\n",
       " 'resample': False,\n",
       " 'nb_type': 'bernoulli',\n",
       " 'discr_bins': 33,\n",
       " 'discr_encoder': 'onehot-dense',\n",
       " 'discr_strat': 'uniform',\n",
       " 'discrete_alpha': 0.2076978780091387}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[544].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = trials.sort_values(by=[\"value\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_corr_value</th>\n",
       "      <th>params_delete_correlated</th>\n",
       "      <th>params_discr_bins</th>\n",
       "      <th>params_discr_encoder</th>\n",
       "      <th>params_discr_strat</th>\n",
       "      <th>...</th>\n",
       "      <th>params_nb_type</th>\n",
       "      <th>params_pca</th>\n",
       "      <th>params_pca_ratio</th>\n",
       "      <th>params_perc</th>\n",
       "      <th>params_resample</th>\n",
       "      <th>params_scaler</th>\n",
       "      <th>params_top_k</th>\n",
       "      <th>params_up_neighs</th>\n",
       "      <th>user_attrs_num_cols</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0.643703</td>\n",
       "      <td>2024-01-10 12:04:52.415753</td>\n",
       "      <td>2024-01-10 12:04:52.663903</td>\n",
       "      <td>0 days 00:00:00.248150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>quan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>630</td>\n",
       "      <td>0.643703</td>\n",
       "      <td>2024-01-10 12:03:11.196016</td>\n",
       "      <td>2024-01-10 12:03:11.379229</td>\n",
       "      <td>0 days 00:00:00.183213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>quan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>739</td>\n",
       "      <td>0.643703</td>\n",
       "      <td>2024-01-10 12:03:39.555322</td>\n",
       "      <td>2024-01-10 12:03:39.790951</td>\n",
       "      <td>0 days 00:00:00.235629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>quan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>793</td>\n",
       "      <td>0.643703</td>\n",
       "      <td>2024-01-10 12:03:55.181959</td>\n",
       "      <td>2024-01-10 12:03:55.417761</td>\n",
       "      <td>0 days 00:00:00.235802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>quan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>732</td>\n",
       "      <td>0.643703</td>\n",
       "      <td>2024-01-10 12:03:37.425731</td>\n",
       "      <td>2024-01-10 12:03:37.665914</td>\n",
       "      <td>0 days 00:00:00.240183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>quan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>576</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-01-10 12:02:56.117604</td>\n",
       "      <td>2024-01-10 12:02:56.455360</td>\n",
       "      <td>0 days 00:00:00.337756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>57.0</td>\n",
       "      <td>onehot-dense</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>True</td>\n",
       "      <td>0.612994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>quan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>633</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-01-10 12:03:11.804472</td>\n",
       "      <td>2024-01-10 12:03:12.303994</td>\n",
       "      <td>0 days 00:00:00.499522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>31.0</td>\n",
       "      <td>onehot-dense</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>power</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>639</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-01-10 12:03:13.353884</td>\n",
       "      <td>2024-01-10 12:03:13.712211</td>\n",
       "      <td>0 days 00:00:00.358327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>onehot-dense</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>quan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>471</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-01-10 12:02:24.684966</td>\n",
       "      <td>2024-01-10 12:02:24.856329</td>\n",
       "      <td>0 days 00:00:00.171363</td>\n",
       "      <td>0.769201</td>\n",
       "      <td>True</td>\n",
       "      <td>33.0</td>\n",
       "      <td>onehot-dense</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>norm</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>657</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-01-10 12:03:17.815252</td>\n",
       "      <td>2024-01-10 12:03:18.208533</td>\n",
       "      <td>0 days 00:00:00.393281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>31.0</td>\n",
       "      <td>onehot-dense</td>\n",
       "      <td>uniform</td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>True</td>\n",
       "      <td>0.811784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>quan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number     value             datetime_start          datetime_complete  \\\n",
       "999     999  0.643703 2024-01-10 12:04:52.415753 2024-01-10 12:04:52.663903   \n",
       "630     630  0.643703 2024-01-10 12:03:11.196016 2024-01-10 12:03:11.379229   \n",
       "739     739  0.643703 2024-01-10 12:03:39.555322 2024-01-10 12:03:39.790951   \n",
       "793     793  0.643703 2024-01-10 12:03:55.181959 2024-01-10 12:03:55.417761   \n",
       "732     732  0.643703 2024-01-10 12:03:37.425731 2024-01-10 12:03:37.665914   \n",
       "..      ...       ...                        ...                        ...   \n",
       "576     576 -1.000000 2024-01-10 12:02:56.117604 2024-01-10 12:02:56.455360   \n",
       "633     633 -1.000000 2024-01-10 12:03:11.804472 2024-01-10 12:03:12.303994   \n",
       "639     639 -1.000000 2024-01-10 12:03:13.353884 2024-01-10 12:03:13.712211   \n",
       "471     471 -1.000000 2024-01-10 12:02:24.684966 2024-01-10 12:02:24.856329   \n",
       "657     657 -1.000000 2024-01-10 12:03:17.815252 2024-01-10 12:03:18.208533   \n",
       "\n",
       "                  duration  params_corr_value  params_delete_correlated  \\\n",
       "999 0 days 00:00:00.248150                NaN                     False   \n",
       "630 0 days 00:00:00.183213                NaN                     False   \n",
       "739 0 days 00:00:00.235629                NaN                     False   \n",
       "793 0 days 00:00:00.235802                NaN                     False   \n",
       "732 0 days 00:00:00.240183                NaN                     False   \n",
       "..                     ...                ...                       ...   \n",
       "576 0 days 00:00:00.337756                NaN                     False   \n",
       "633 0 days 00:00:00.499522                NaN                     False   \n",
       "639 0 days 00:00:00.358327                NaN                     False   \n",
       "471 0 days 00:00:00.171363           0.769201                      True   \n",
       "657 0 days 00:00:00.393281                NaN                     False   \n",
       "\n",
       "     params_discr_bins params_discr_encoder params_discr_strat  ...  \\\n",
       "999               33.0              ordinal            uniform  ...   \n",
       "630               33.0              ordinal            uniform  ...   \n",
       "739               33.0              ordinal            uniform  ...   \n",
       "793               33.0              ordinal            uniform  ...   \n",
       "732               33.0              ordinal            uniform  ...   \n",
       "..                 ...                  ...                ...  ...   \n",
       "576               57.0         onehot-dense            uniform  ...   \n",
       "633               31.0         onehot-dense            uniform  ...   \n",
       "639               33.0         onehot-dense            uniform  ...   \n",
       "471               33.0         onehot-dense             kmeans  ...   \n",
       "657               31.0         onehot-dense            uniform  ...   \n",
       "\n",
       "     params_nb_type  params_pca params_pca_ratio  params_perc  \\\n",
       "999     categorical       False              NaN          NaN   \n",
       "630     categorical       False              NaN          NaN   \n",
       "739     categorical       False              NaN          NaN   \n",
       "793     categorical       False              NaN          NaN   \n",
       "732     categorical       False              NaN          NaN   \n",
       "..              ...         ...              ...          ...   \n",
       "576     categorical        True         0.612994          NaN   \n",
       "633     categorical       False              NaN          NaN   \n",
       "639     categorical       False              NaN          NaN   \n",
       "471     categorical       False              NaN          NaN   \n",
       "657     categorical        True         0.811784          NaN   \n",
       "\n",
       "     params_resample params_scaler  params_top_k  params_up_neighs  \\\n",
       "999            False          quan           NaN               NaN   \n",
       "630            False          quan           NaN               NaN   \n",
       "739            False          quan           NaN               NaN   \n",
       "793            False          quan           NaN               NaN   \n",
       "732            False          quan           NaN               NaN   \n",
       "..               ...           ...           ...               ...   \n",
       "576            False          quan           NaN               NaN   \n",
       "633            False         power           NaN               NaN   \n",
       "639             True          quan           NaN               NaN   \n",
       "471            False          norm          22.0               NaN   \n",
       "657            False          quan           NaN               NaN   \n",
       "\n",
       "    user_attrs_num_cols     state  \n",
       "999                 NaN  COMPLETE  \n",
       "630                 NaN  COMPLETE  \n",
       "739                 NaN  COMPLETE  \n",
       "793                 NaN  COMPLETE  \n",
       "732                 NaN  COMPLETE  \n",
       "..                  ...       ...  \n",
       "576                 NaN  COMPLETE  \n",
       "633                 NaN  COMPLETE  \n",
       "639                 NaN  COMPLETE  \n",
       "471                39.0  COMPLETE  \n",
       "657                 NaN  COMPLETE  \n",
       "\n",
       "[1000 rows x 28 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_np = trials[[\"number\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[350],\n",
       "       [444],\n",
       "       [580],\n",
       "       [540],\n",
       "       [181],\n",
       "       [174],\n",
       "       [173],\n",
       "       [731],\n",
       "       [172],\n",
       "       [171],\n",
       "       [167],\n",
       "       [166],\n",
       "       [629],\n",
       "       [918],\n",
       "       [347],\n",
       "       [949],\n",
       "       [524],\n",
       "       [352],\n",
       "       [354],\n",
       "       [719],\n",
       "       [361],\n",
       "       [642],\n",
       "       [373],\n",
       "       [649],\n",
       "       [761],\n",
       "       [560],\n",
       "       [558],\n",
       "       [396],\n",
       "       [790],\n",
       "       [688],\n",
       "       [744],\n",
       "       [784],\n",
       "       [767],\n",
       "       [992],\n",
       "       [593],\n",
       "       [612],\n",
       "       [812],\n",
       "       [834],\n",
       "       [905],\n",
       "       [490],\n",
       "       [983],\n",
       "       [597],\n",
       "       [608],\n",
       "       [463],\n",
       "       [896],\n",
       "       [436],\n",
       "       [379],\n",
       "       [376],\n",
       "       [264],\n",
       "       [292],\n",
       "       [256],\n",
       "       [335],\n",
       "       [319],\n",
       "       [298],\n",
       "       [246],\n",
       "       [182],\n",
       "       [175],\n",
       "       [176],\n",
       "       [177],\n",
       "       [305],\n",
       "       [704],\n",
       "       [244],\n",
       "       [241],\n",
       "       [253],\n",
       "       [240],\n",
       "       [239],\n",
       "       [238],\n",
       "       [234],\n",
       "       [233],\n",
       "       [232],\n",
       "       [231],\n",
       "       [227],\n",
       "       [279],\n",
       "       [226],\n",
       "       [934],\n",
       "       [225],\n",
       "       [224],\n",
       "       [223],\n",
       "       [218],\n",
       "       [299],\n",
       "       [301],\n",
       "       [277],\n",
       "       [382],\n",
       "       [892],\n",
       "       [498],\n",
       "       [805],\n",
       "       [193],\n",
       "       [222],\n",
       "       [211],\n",
       "       [192],\n",
       "       [195],\n",
       "       [203],\n",
       "       [201],\n",
       "       [191],\n",
       "       [190],\n",
       "       [976],\n",
       "       [197],\n",
       "       [186],\n",
       "       [188],\n",
       "       [184],\n",
       "       [185],\n",
       "       [990],\n",
       "       [194],\n",
       "       [943],\n",
       "       [254],\n",
       "       [510],\n",
       "       [ 96],\n",
       "       [370],\n",
       "       [603],\n",
       "       [159],\n",
       "       [844],\n",
       "       [437],\n",
       "       [938],\n",
       "       [151],\n",
       "       [138],\n",
       "       [130],\n",
       "       [465],\n",
       "       [137],\n",
       "       [859],\n",
       "       [141],\n",
       "       [152],\n",
       "       [132],\n",
       "       [131],\n",
       "       [123],\n",
       "       [216],\n",
       "       [212],\n",
       "       [768],\n",
       "       [144],\n",
       "       [786],\n",
       "       [748],\n",
       "       [296],\n",
       "       [318],\n",
       "       [245],\n",
       "       [626],\n",
       "       [321],\n",
       "       [205],\n",
       "       [716],\n",
       "       [538],\n",
       "       [162],\n",
       "       [154],\n",
       "       [721],\n",
       "       [155],\n",
       "       [243],\n",
       "       [259],\n",
       "       [282],\n",
       "       [340],\n",
       "       [250],\n",
       "       [302],\n",
       "       [324],\n",
       "       [304],\n",
       "       [164],\n",
       "       [700],\n",
       "       [497],\n",
       "       [712],\n",
       "       [472],\n",
       "       [837],\n",
       "       [467],\n",
       "       [322],\n",
       "       [429],\n",
       "       [925],\n",
       "       [426],\n",
       "       [868],\n",
       "       [214],\n",
       "       [389],\n",
       "       [331],\n",
       "       [280],\n",
       "       [957],\n",
       "       [765],\n",
       "       [627],\n",
       "       [469],\n",
       "       [909],\n",
       "       [855],\n",
       "       [698],\n",
       "       [737],\n",
       "       [841],\n",
       "       [169],\n",
       "       [875],\n",
       "       [371],\n",
       "       [562],\n",
       "       [395],\n",
       "       [577],\n",
       "       [920],\n",
       "       [550],\n",
       "       [650],\n",
       "       [450],\n",
       "       [421],\n",
       "       [323],\n",
       "       [821],\n",
       "       [ 94],\n",
       "       [338],\n",
       "       [446],\n",
       "       [330],\n",
       "       [281],\n",
       "       [275],\n",
       "       [273],\n",
       "       [337],\n",
       "       [265],\n",
       "       [754],\n",
       "       [278],\n",
       "       [745],\n",
       "       [401],\n",
       "       [865],\n",
       "       [417],\n",
       "       [913],\n",
       "       [366],\n",
       "       [125],\n",
       "       [989],\n",
       "       [527],\n",
       "       [161],\n",
       "       [514],\n",
       "       [466],\n",
       "       [156],\n",
       "       [835],\n",
       "       [160],\n",
       "       [822],\n",
       "       [901],\n",
       "       [827],\n",
       "       [675],\n",
       "       [711],\n",
       "       [789],\n",
       "       [609],\n",
       "       [598],\n",
       "       [648],\n",
       "       [491],\n",
       "       [456],\n",
       "       [374],\n",
       "       [725],\n",
       "       [741],\n",
       "       [534],\n",
       "       [618],\n",
       "       [948],\n",
       "       [802],\n",
       "       [525],\n",
       "       [575],\n",
       "       [407],\n",
       "       [846],\n",
       "       [662],\n",
       "       [344],\n",
       "       [204],\n",
       "       [215],\n",
       "       [183],\n",
       "       [578],\n",
       "       [915],\n",
       "       [555],\n",
       "       [547],\n",
       "       [533],\n",
       "       [945],\n",
       "       [684],\n",
       "       [271],\n",
       "       [274],\n",
       "       [881],\n",
       "       [530],\n",
       "       [258],\n",
       "       [287],\n",
       "       [628],\n",
       "       [727],\n",
       "       [749],\n",
       "       [895],\n",
       "       [442],\n",
       "       [814],\n",
       "       [588],\n",
       "       [502],\n",
       "       [415],\n",
       "       [770],\n",
       "       [832],\n",
       "       [362],\n",
       "       [552],\n",
       "       [796],\n",
       "       [398],\n",
       "       [355],\n",
       "       [671],\n",
       "       [703],\n",
       "       [932],\n",
       "       [571],\n",
       "       [964],\n",
       "       [228],\n",
       "       [255],\n",
       "       [333],\n",
       "       [316],\n",
       "       [666],\n",
       "       [252],\n",
       "       [237],\n",
       "       [229],\n",
       "       [261],\n",
       "       [730],\n",
       "       [236],\n",
       "       [797],\n",
       "       [210],\n",
       "       [114],\n",
       "       [599],\n",
       "       [984],\n",
       "       [381],\n",
       "       [430],\n",
       "       [787],\n",
       "       [953],\n",
       "       [196],\n",
       "       [206],\n",
       "       [213],\n",
       "       [392],\n",
       "       [343],\n",
       "       [879],\n",
       "       [955],\n",
       "       [402],\n",
       "       [519],\n",
       "       [889],\n",
       "       [739],\n",
       "       [517],\n",
       "       [505],\n",
       "       [978],\n",
       "       [492],\n",
       "       [810],\n",
       "       [652],\n",
       "       [541],\n",
       "       [405],\n",
       "       [199],\n",
       "       [807],\n",
       "       [387],\n",
       "       [935],\n",
       "       [664],\n",
       "       [963],\n",
       "       [574],\n",
       "       [400],\n",
       "       [474],\n",
       "       [129],\n",
       "       [907],\n",
       "       [644],\n",
       "       [723],\n",
       "       [611],\n",
       "       [734],\n",
       "       [673],\n",
       "       [750],\n",
       "       [933],\n",
       "       [565],\n",
       "       [460],\n",
       "       [602],\n",
       "       [595],\n",
       "       [871],\n",
       "       [726],\n",
       "       [418],\n",
       "       [694],\n",
       "       [842],\n",
       "       [987],\n",
       "       [434],\n",
       "       [944],\n",
       "       [590],\n",
       "       [617],\n",
       "       [774],\n",
       "       [494],\n",
       "       [702],\n",
       "       [546],\n",
       "       [553],\n",
       "       [440],\n",
       "       [861],\n",
       "       [917],\n",
       "       [714],\n",
       "       [481],\n",
       "       [363],\n",
       "       [317],\n",
       "       [986],\n",
       "       [142],\n",
       "       [473],\n",
       "       [996],\n",
       "       [928],\n",
       "       [145],\n",
       "       [150],\n",
       "       [828],\n",
       "       [133],\n",
       "       [134],\n",
       "       [135],\n",
       "       [136],\n",
       "       [511],\n",
       "       [377],\n",
       "       [365],\n",
       "       [523],\n",
       "       [823],\n",
       "       [785],\n",
       "       [615],\n",
       "       [327],\n",
       "       [300],\n",
       "       [297],\n",
       "       [341],\n",
       "       [157],\n",
       "       [646],\n",
       "       [384],\n",
       "       [622],\n",
       "       [569],\n",
       "       [561],\n",
       "       [911],\n",
       "       [411],\n",
       "       [941],\n",
       "       [916],\n",
       "       [548],\n",
       "       [692],\n",
       "       [817],\n",
       "       [584],\n",
       "       [425],\n",
       "       [679],\n",
       "       [862],\n",
       "       [803],\n",
       "       [988],\n",
       "       [724],\n",
       "       [616],\n",
       "       [778],\n",
       "       [890],\n",
       "       [946],\n",
       "       [591],\n",
       "       [764],\n",
       "       [610],\n",
       "       [459],\n",
       "       [876],\n",
       "       [961],\n",
       "       [903],\n",
       "       [651],\n",
       "       [839],\n",
       "       [669],\n",
       "       [375],\n",
       "       [647],\n",
       "       [870],\n",
       "       [967],\n",
       "       [493],\n",
       "       [348],\n",
       "       [856],\n",
       "       [639],\n",
       "       [573],\n",
       "       [554],\n",
       "       [403],\n",
       "       [695],\n",
       "       [499],\n",
       "       [974],\n",
       "       [209],\n",
       "       [513],\n",
       "       [532],\n",
       "       [294],\n",
       "       [667],\n",
       "       [168],\n",
       "       [431],\n",
       "       [586],\n",
       "       [394],\n",
       "       [486],\n",
       "       [453],\n",
       "       [439],\n",
       "       [342],\n",
       "       [811],\n",
       "       [858],\n",
       "       [798],\n",
       "       [968],\n",
       "       [972],\n",
       "       [470],\n",
       "       [360],\n",
       "       [781],\n",
       "       [353],\n",
       "       [518],\n",
       "       [886],\n",
       "       [655],\n",
       "       [819],\n",
       "       [623],\n",
       "       [991],\n",
       "       [763],\n",
       "       [594],\n",
       "       [495],\n",
       "       [894],\n",
       "       [566],\n",
       "       [356],\n",
       "       [682],\n",
       "       [931],\n",
       "       [412],\n",
       "       [528],\n",
       "       [771],\n",
       "       [866],\n",
       "       [677],\n",
       "       [833],\n",
       "       [549],\n",
       "       [665],\n",
       "       [235],\n",
       "       [284],\n",
       "       [641],\n",
       "       [543],\n",
       "       [583],\n",
       "       [202],\n",
       "       [315],\n",
       "       [643],\n",
       "       [979],\n",
       "       [729],\n",
       "       [257],\n",
       "       [475],\n",
       "       [635],\n",
       "       [314],\n",
       "       [399],\n",
       "       [691],\n",
       "       [897],\n",
       "       [500],\n",
       "       [630],\n",
       "       [127],\n",
       "       [930],\n",
       "       [659],\n",
       "       [971],\n",
       "       [674],\n",
       "       [124],\n",
       "       [508],\n",
       "       [759],\n",
       "       [847],\n",
       "       [995],\n",
       "       [488],\n",
       "       [143],\n",
       "       [380],\n",
       "       [891],\n",
       "       [592],\n",
       "       [477],\n",
       "       [568],\n",
       "       [521],\n",
       "       [198],\n",
       "       [187],\n",
       "       [221],\n",
       "       [118],\n",
       "       [378],\n",
       "       [480],\n",
       "       [937],\n",
       "       [452],\n",
       "       [529],\n",
       "       [308],\n",
       "       [416],\n",
       "       [654],\n",
       "       [848],\n",
       "       [ 49],\n",
       "       [ 63],\n",
       "       [709],\n",
       "       [110],\n",
       "       [111],\n",
       "       [105],\n",
       "       [775],\n",
       "       [448],\n",
       "       [ 52],\n",
       "       [ 95],\n",
       "       [313],\n",
       "       [443],\n",
       "       [653],\n",
       "       [113],\n",
       "       [115],\n",
       "       [857],\n",
       "       [249],\n",
       "       [288],\n",
       "       [276],\n",
       "       [103],\n",
       "       [102],\n",
       "       [153],\n",
       "       [ 78],\n",
       "       [824],\n",
       "       [104],\n",
       "       [479],\n",
       "       [921],\n",
       "       [606],\n",
       "       [912],\n",
       "       [544],\n",
       "       [165],\n",
       "       [751],\n",
       "       [ 77],\n",
       "       [ 51],\n",
       "       [121],\n",
       "       [570],\n",
       "       [874],\n",
       "       [625],\n",
       "       [668],\n",
       "       [ 74],\n",
       "       [ 46],\n",
       "       [793],\n",
       "       [283],\n",
       "       [339],\n",
       "       [758],\n",
       "       [268],\n",
       "       [504],\n",
       "       [843],\n",
       "       [ 72],\n",
       "       [139],\n",
       "       [708],\n",
       "       [908],\n",
       "       [883],\n",
       "       [672],\n",
       "       [958],\n",
       "       [117],\n",
       "       [826],\n",
       "       [788],\n",
       "       [956],\n",
       "       [478],\n",
       "       [ 91],\n",
       "       [146],\n",
       "       [ 79],\n",
       "       [589],\n",
       "       [747],\n",
       "       [816],\n",
       "       [954],\n",
       "       [424],\n",
       "       [686],\n",
       "       [773],\n",
       "       [742],\n",
       "       [818],\n",
       "       [ 56],\n",
       "       [303],\n",
       "       [576],\n",
       "       [120],\n",
       "       [293],\n",
       "       [853],\n",
       "       [ 98],\n",
       "       [307],\n",
       "       [251],\n",
       "       [638],\n",
       "       [328],\n",
       "       [458],\n",
       "       [746],\n",
       "       [ 92],\n",
       "       [ 81],\n",
       "       [269],\n",
       "       [736],\n",
       "       [567],\n",
       "       [966],\n",
       "       [454],\n",
       "       [977],\n",
       "       [501],\n",
       "       [799],\n",
       "       [449],\n",
       "       [419],\n",
       "       [660],\n",
       "       [851],\n",
       "       [689],\n",
       "       [ 83],\n",
       "       [869],\n",
       "       [762],\n",
       "       [423],\n",
       "       [551],\n",
       "       [ 66],\n",
       "       [ 71],\n",
       "       [ 67],\n",
       "       [122],\n",
       "       [109],\n",
       "       [898],\n",
       "       [357],\n",
       "       [993],\n",
       "       [631],\n",
       "       [ 54],\n",
       "       [163],\n",
       "       [ 61],\n",
       "       [769],\n",
       "       [678],\n",
       "       [420],\n",
       "       [ 85],\n",
       "       [893],\n",
       "       [783],\n",
       "       [312],\n",
       "       [884],\n",
       "       [433],\n",
       "       [633],\n",
       "       [619],\n",
       "       [368],\n",
       "       [624],\n",
       "       [794],\n",
       "       [489],\n",
       "       [ 73],\n",
       "       [910],\n",
       "       [722],\n",
       "       [969],\n",
       "       [208],\n",
       "       [332],\n",
       "       [428],\n",
       "       [272],\n",
       "       [942],\n",
       "       [756],\n",
       "       [ 82],\n",
       "       [468],\n",
       "       [965],\n",
       "       [927],\n",
       "       [506],\n",
       "       [325],\n",
       "       [885],\n",
       "       [484],\n",
       "       [939],\n",
       "       [ 69],\n",
       "       [657],\n",
       "       [705],\n",
       "       [445],\n",
       "       [795],\n",
       "       [696],\n",
       "       [849],\n",
       "       [605],\n",
       "       [409],\n",
       "       [882],\n",
       "       [291],\n",
       "       [ 60],\n",
       "       [391],\n",
       "       [ 70],\n",
       "       [390],\n",
       "       [ 55],\n",
       "       [564],\n",
       "       [777],\n",
       "       [108],\n",
       "       [676],\n",
       "       [217],\n",
       "       [867],\n",
       "       [998],\n",
       "       [872],\n",
       "       [ 76],\n",
       "       [367],\n",
       "       [112],\n",
       "       [306],\n",
       "       [713],\n",
       "       [690],\n",
       "       [902],\n",
       "       [888],\n",
       "       [404],\n",
       "       [482],\n",
       "       [922],\n",
       "       [663],\n",
       "       [929],\n",
       "       [830],\n",
       "       [438],\n",
       "       [ 93],\n",
       "       [451],\n",
       "       [687],\n",
       "       [864],\n",
       "       [369],\n",
       "       [242],\n",
       "       [262],\n",
       "       [ 57],\n",
       "       [601],\n",
       "       [515],\n",
       "       [697],\n",
       "       [179],\n",
       "       [ 44],\n",
       "       [107],\n",
       "       [ 84],\n",
       "       [715],\n",
       "       [526],\n",
       "       [699],\n",
       "       [637],\n",
       "       [982],\n",
       "       [267],\n",
       "       [ 26],\n",
       "       [326],\n",
       "       [ 34],\n",
       "       [981],\n",
       "       [406],\n",
       "       [ 62],\n",
       "       [522],\n",
       "       [349],\n",
       "       [542],\n",
       "       [718],\n",
       "       [503],\n",
       "       [604],\n",
       "       [106],\n",
       "       [ 40],\n",
       "       [ 41],\n",
       "       [388],\n",
       "       [ 37],\n",
       "       [809],\n",
       "       [ 43],\n",
       "       [952],\n",
       "       [ 33],\n",
       "       [ 42],\n",
       "       [738],\n",
       "       [845],\n",
       "       [906],\n",
       "       [563],\n",
       "       [ 27],\n",
       "       [999],\n",
       "       [ 39],\n",
       "       [753],\n",
       "       [791],\n",
       "       [539],\n",
       "       [757],\n",
       "       [636],\n",
       "       [878],\n",
       "       [ 35],\n",
       "       [ 47],\n",
       "       [383],\n",
       "       [728],\n",
       "       [ 23],\n",
       "       [735],\n",
       "       [ 88],\n",
       "       [ 32],\n",
       "       [ 28],\n",
       "       [ 87],\n",
       "       [836],\n",
       "       [ 22],\n",
       "       [512],\n",
       "       [813],\n",
       "       [149],\n",
       "       [951],\n",
       "       [346],\n",
       "       [ 36],\n",
       "       [364],\n",
       "       [386],\n",
       "       [ 24],\n",
       "       [189],\n",
       "       [ 31],\n",
       "       [772],\n",
       "       [854],\n",
       "       [680],\n",
       "       [904],\n",
       "       [334],\n",
       "       [260],\n",
       "       [309],\n",
       "       [ 45],\n",
       "       [  0],\n",
       "       [128],\n",
       "       [806],\n",
       "       [733],\n",
       "       [614],\n",
       "       [441],\n",
       "       [926],\n",
       "       [829],\n",
       "       [873],\n",
       "       [531],\n",
       "       [483],\n",
       "       [536],\n",
       "       [752],\n",
       "       [831],\n",
       "       [ 97],\n",
       "       [285],\n",
       "       [485],\n",
       "       [975],\n",
       "       [413],\n",
       "       [710],\n",
       "       [581],\n",
       "       [ 13],\n",
       "       [462],\n",
       "       [587],\n",
       "       [ 15],\n",
       "       [ 21],\n",
       "       [685],\n",
       "       [923],\n",
       "       [464],\n",
       "       [782],\n",
       "       [230],\n",
       "       [755],\n",
       "       [556],\n",
       "       [960],\n",
       "       [487],\n",
       "       [ 89],\n",
       "       [148],\n",
       "       [ 53],\n",
       "       [286],\n",
       "       [290],\n",
       "       [ 11],\n",
       "       [ 19],\n",
       "       [ 38],\n",
       "       [516],\n",
       "       [455],\n",
       "       [ 20],\n",
       "       [732],\n",
       "       [427],\n",
       "       [600],\n",
       "       [860],\n",
       "       [263],\n",
       "       [101],\n",
       "       [  5],\n",
       "       [ 12],\n",
       "       [289],\n",
       "       [393],\n",
       "       [432],\n",
       "       [760],\n",
       "       [ 25],\n",
       "       [ 14],\n",
       "       [959],\n",
       "       [720],\n",
       "       [701],\n",
       "       [ 48],\n",
       "       [559],\n",
       "       [681],\n",
       "       [579],\n",
       "       [351],\n",
       "       [ 86],\n",
       "       [247],\n",
       "       [852],\n",
       "       [919],\n",
       "       [557],\n",
       "       [266],\n",
       "       [178],\n",
       "       [207],\n",
       "       [820],\n",
       "       [613],\n",
       "       [780],\n",
       "       [476],\n",
       "       [147],\n",
       "       [620],\n",
       "       [640],\n",
       "       [329],\n",
       "       [410],\n",
       "       [414],\n",
       "       [880],\n",
       "       [940],\n",
       "       [310],\n",
       "       [840],\n",
       "       [537],\n",
       "       [ 18],\n",
       "       [ 58],\n",
       "       [435],\n",
       "       [980],\n",
       "       [808],\n",
       "       [ 65],\n",
       "       [  8],\n",
       "       [ 29],\n",
       "       [804],\n",
       "       [634],\n",
       "       [740],\n",
       "       [899],\n",
       "       [800],\n",
       "       [461],\n",
       "       [ 99],\n",
       "       [  6],\n",
       "       [119],\n",
       "       [825],\n",
       "       [994],\n",
       "       [170],\n",
       "       [219],\n",
       "       [ 64],\n",
       "       [776],\n",
       "       [140],\n",
       "       [507],\n",
       "       [  3],\n",
       "       [582],\n",
       "       [408],\n",
       "       [947],\n",
       "       [706],\n",
       "       [358],\n",
       "       [457],\n",
       "       [632],\n",
       "       [801],\n",
       "       [607],\n",
       "       [970],\n",
       "       [  1],\n",
       "       [ 75],\n",
       "       [997],\n",
       "       [116],\n",
       "       [779],\n",
       "       [924],\n",
       "       [973],\n",
       "       [707],\n",
       "       [359],\n",
       "       [877],\n",
       "       [509],\n",
       "       [585],\n",
       "       [950],\n",
       "       [683],\n",
       "       [385],\n",
       "       [900],\n",
       "       [180],\n",
       "       [220],\n",
       "       [535],\n",
       "       [658],\n",
       "       [661],\n",
       "       [ 50],\n",
       "       [656],\n",
       "       [ 90],\n",
       "       [  4],\n",
       "       [850],\n",
       "       [717],\n",
       "       [863],\n",
       "       [  2],\n",
       "       [ 17],\n",
       "       [ 16],\n",
       "       [838],\n",
       "       [422],\n",
       "       [  7],\n",
       "       [372],\n",
       "       [496],\n",
       "       [985],\n",
       "       [766],\n",
       "       [345],\n",
       "       [397],\n",
       "       [743],\n",
       "       [ 10],\n",
       "       [  9],\n",
       "       [471],\n",
       "       [100],\n",
       "       [ 30],\n",
       "       [336],\n",
       "       [572],\n",
       "       [596],\n",
       "       [936],\n",
       "       [621],\n",
       "       [815],\n",
       "       [158],\n",
       "       [ 80],\n",
       "       [914],\n",
       "       [ 68],\n",
       "       [200],\n",
       "       [ 59],\n",
       "       [248],\n",
       "       [270],\n",
       "       [520],\n",
       "       [545],\n",
       "       [295],\n",
       "       [645],\n",
       "       [792],\n",
       "       [962],\n",
       "       [670],\n",
       "       [311],\n",
       "       [126],\n",
       "       [320],\n",
       "       [887],\n",
       "       [693],\n",
       "       [447]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dict = trials.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([941, 973, 934, 971, 970, 933, 968, 967, 946, 965, 962, 957, 955, 954, 930, 929, 947, 928, 927, 948, 949, 952, 925, 950, 926, 972, 951, 978, 990, 979, 936, 942, 945, 938, 989, 988, 977, 943, 976, 991, 995, 986, 996, 998, 935, 981, 624, 686, 691, 696, 684, 700, 626, 681, 627, 628, 637, 683, 621, 922, 902, 892, 924, 906, 910, 914, 618, 919, 918, 909, 106, 736, 793, 794, 739, 818, 852, 787, 763, 758, 766, 884, 753, 767, 881, 751, 750, 772, 878, 773, 749, 774, 747, 779, 744, 743, 780, 862, 858, 724, 857, 783, 786, 865, 851, 762, 816, 837, 713, 834, 711, 805, 831, 705, 697, 703, 812, 809, 702, 730, 828, 731, 714, 825, 719, 799, 720, 844, 822, 118, 931, 953, 651, 647, 641, 657, 675, 676, 643, 661, 663, 578, 645, 656, 642, 672, 671, 669, 664, 652, 224, 459, 327, 326, 223, 325, 298, 222, 221, 333, 232, 336, 216, 342, 571, 213, 282, 211, 502, 345, 208, 207, 231, 241, 233, 235, 270, 303, 268, 616, 487, 274, 264, 263, 306, 474, 473, 470, 494, 254, 311, 295, 496, 313, 597, 289, 245, 317, 242, 319, 239, 281, 236, 506, 403, 204, 171, 169, 562, 449, 203, 364, 512, 369, 439, 555, 436, 548, 432, 382, 427, 383, 385, 423, 523, 418, 98, 546, 389, 543, 541, 398, 402, 527, 170, 194, 183, 453, 195, 191, 565, 196, 186, 185, 182, 198, 181, 407, 192, 176, 173, 174, 177, 201, 454, 200, 62, 164, 54, 162, 61, 53, 75, 56, 154, 43, 115, 114, 847, 823, 782, 842, 850, 838, 777, 873, 769, 804, 880, 855, 830, 806, 861, 811, 722, 735, 742, 725, 717, 761, 729, 738, 732, 704, 819, 757, 104, 695, 907, 625, 690, 622, 636, 893, 322, 215, 240, 172, 275, 290, 908, 678, 650, 133, 141, 63, 152, 161, 153, 64, 92, 91, 71, 72, 788, 728, 848, 868, 768, 829, 123, 689, 635, 304, 390, 308, 570, 248, 269, 372, 430, 103, 595, 888, 105, 111, 963, 911, 143, 278, 321, 301, 813, 592, 156, 82, 134, 867, 883, 814, 810, 841, 854, 807, 790, 833, 795, 116, 155, 52, 138, 27, 360, 404, 102, 832, 898, 332, 85, 708, 876, 752, 421, 370, 939, 920, 961, 673, 659, 653, 603, 122, 149, 994, 74, 426, 234, 422, 328, 228, 464, 604, 435, 461, 273, 244, 511, 446, 489, 262, 492, 504, 609, 475, 524, 284, 197, 549, 214, 547, 340, 199, 376, 391, 574, 567, 217, 371, 394, 529, 352, 189, 532, 363, 225, 94, 81, 142, 748, 65, 112, 119, 629, 692, 630, 634, 73, 148, 33, 411, 35, 45, 42, 579, 840, 341, 67, 827, 712, 846, 388, 518, 346, 20, 530, 561, 339, 229, 522, 890, 785, 792, 771, 869, 801, 450, 677, 151, 147, 901, 577, 999, 330, 654, 670, 631, 680, 863, 662, 166, 163, 144, 132, 167, 591, 974, 451, 413, 93, 32, 31, 145, 412, 121, 113, 165, 572, 28, 381, 853, 778, 721, 250, 611, 460, 992, 100, 824, 380, 796, 594, 396, 589, 765, 125, 477, 353, 569, 607, 280, 350, 384, 338, 334, 302, 307, 379, 600, 553, 300, 392, 456, 255, 267, 219, 447, 442, 497, 468, 175, 428, 180, 184, 193, 420, 261, 202, 344, 472, 226, 409, 237, 246, 535, 399, 361, 490, 598, 220, 179, 253, 482, 368, 463, 707, 335, 733, 800, 740, 709, 755, 845, 760, 455, 287, 513, 710, 288, 585, 356, 540, 408, 188, 256, 279, 260, 448, 395, 429, 375, 365, 503, 476, 355, 51, 568, 528, 101, 537, 491, 521, 84, 60, 904, 866, 12, 13, 10, 11, 791, 632, 128, 259, 887, 351, 440, 108, 126, 190, 135, 701, 294, 551, 90, 899, 21, 498, 120, 602, 495, 247, 552, 457, 286, 515, 324, 425, 688, 406, 897, 445, 331, 315, 484, 305, 560, 516, 401, 205, 639, 746, 727, 821, 292, 879, 212, 975, 70, 505, 644, 545, 923, 78, 593, 209, 88, 320, 243, 984, 960, 467, 969, 588, 966, 985, 471, 37, 770, 734, 789, 685, 265, 30, 520, 387, 310, 617, 400, 900, 679, 668, 157, 359, 452, 554, 586, 374, 944, 86, 613, 682, 438, 912, 660, 419, 815, 480, 110, 921, 39, 68, 87, 465, 0, 563, 993, 956, 932, 323, 895, 410, 885, 366, 655, 146, 983, 415, 285, 536, 26, 564, 584, 903, 556, 835, 797, 817, 872, 891, 741, 354, 808, 431, 499, 69, 531, 55, 486, 414, 258, 283, 299, 347, 466, 479, 373, 715, 856, 646, 47, 168, 444, 601, 610, 378, 573, 964, 987, 500, 619, 534, 251, 136, 836, 917, 276, 358, 15, 508, 612, 140, 417, 257, 958, 913, 160, 544, 97, 509, 839, 76, 99, 648, 737, 139, 238, 608, 227, 83, 362, 22, 875, 41, 620, 314, 433, 469, 230, 57, 277, 77, 130, 514, 293, 158, 982, 776, 377, 559, 357, 434, 802, 271, 266, 348, 581, 6, 23, 127, 58, 124, 50, 915, 129, 507, 538, 206, 483, 674, 34, 666, 443, 291, 877, 462, 14, 312, 580, 526, 481, 843, 318, 576, 316, 187, 437, 36, 605, 2, 615, 424, 16, 940, 5, 441, 386, 458, 249, 79, 252, 131, 19, 937, 519, 343, 210, 980, 218, 393, 349, 309, 784, 337, 397, 297, 329, 745, 488, 296, 997, 959, 596, 706, 694, 756, 178, 665, 687, 667, 894, 539, 859, 896, 557, 416, 3, 95, 525, 493, 107, 587, 405, 614, 640, 40, 638, 764, 726, 59, 24, 533, 905, 137, 89, 582, 649, 658, 1, 820, 542, 367, 501, 272, 550, 558, 803, 478, 575, 38, 8, 590, 117, 485, 606, 517, 510, 109, 623, 44, 566, 66, 49, 96, 17, 599, 159, 916, 693, 9, 46, 25, 29, 4, 150, 7, 633, 18, 716, 889, 699, 860, 781, 775, 798, 583, 826, 759, 849, 754, 718, 698, 864, 870, 871, 874, 882, 886, 80, 48, 723])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_dict[\"value\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': 'power',\n",
       " 'lof': False,\n",
       " 'feature_selection': False,\n",
       " 'delete_correlated': True,\n",
       " 'corr_value': 0.5657174886654177,\n",
       " 'pca': False,\n",
       " 'resample': True,\n",
       " 'kind': 'up',\n",
       " 'up_neighs': 3,\n",
       " 'nb_type': 'categorical',\n",
       " 'discr_bins': 13,\n",
       " 'discr_encoder': 'ordinal',\n",
       " 'discr_strat': 'kmeans',\n",
       " 'discrete_alpha': 0.9483197551692997}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[540].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_stats': {'A': {'precision': 0.8034682080924855,\n",
       "   'recall': 0.8996763754045307,\n",
       "   'f1-score': 0.848854961832061,\n",
       "   'support': 309.0},\n",
       "  'B': {'precision': 0.7024221453287197,\n",
       "   'recall': 0.656957928802589,\n",
       "   'f1-score': 0.6789297658862876,\n",
       "   'support': 309.0},\n",
       "  'C': {'precision': 0.6164383561643836,\n",
       "   'recall': 0.5825242718446602,\n",
       "   'f1-score': 0.5990016638935108,\n",
       "   'support': 309.0},\n",
       "  'D': {'precision': 0.7702265372168284,\n",
       "   'recall': 0.7702265372168284,\n",
       "   'f1-score': 0.7702265372168284,\n",
       "   'support': 309.0},\n",
       "  'accuracy': 0.7273462783171522,\n",
       "  'macro avg': {'precision': 0.7231388117006043,\n",
       "   'recall': 0.727346278317152,\n",
       "   'f1-score': 0.724253232207172,\n",
       "   'support': 1236.0},\n",
       "  'weighted avg': {'precision': 0.7231388117006043,\n",
       "   'recall': 0.7273462783171522,\n",
       "   'f1-score': 0.724253232207172,\n",
       "   'support': 1236.0}},\n",
       " 'val_stats': {'A': {'precision': 0.5909090909090909,\n",
       "   'recall': 0.8666666666666667,\n",
       "   'f1-score': 0.7027027027027029,\n",
       "   'support': 15.0},\n",
       "  'B': {'precision': 0.7941176470588235,\n",
       "   'recall': 0.7012987012987013,\n",
       "   'f1-score': 0.7448275862068966,\n",
       "   'support': 77.0},\n",
       "  'C': {'precision': 0.54,\n",
       "   'recall': 0.574468085106383,\n",
       "   'f1-score': 0.5567010309278351,\n",
       "   'support': 47.0},\n",
       "  'D': {'precision': 0.7142857142857143,\n",
       "   'recall': 0.6976744186046512,\n",
       "   'f1-score': 0.7058823529411765,\n",
       "   'support': 43.0},\n",
       "  'accuracy': 0.6813186813186813,\n",
       "  'macro avg': {'precision': 0.6598281130634072,\n",
       "   'recall': 0.7100269679191006,\n",
       "   'f1-score': 0.6775284181946528,\n",
       "   'support': 182.0},\n",
       "  'weighted avg': {'precision': 0.6928845104475356,\n",
       "   'recall': 0.6813186813186813,\n",
       "   'f1-score': 0.6835722764206067,\n",
       "   'support': 182.0}},\n",
       " 'val_conf': array([[13,  1,  1,  0],\n",
       "        [ 7, 54, 12,  4],\n",
       "        [ 2, 10, 27,  8],\n",
       "        [ 0,  3, 10, 30]]),\n",
       " 'train_pred': array(['D', 'D', 'B', ..., 'D', 'D', 'D'], dtype='<U1'),\n",
       " 'val_pred': array(['D', 'C', 'B', 'C', 'A', 'B', 'C', 'B', 'D', 'D', 'C', 'D', 'B',\n",
       "        'C', 'C', 'D', 'B', 'B', 'A', 'B', 'C', 'B', 'D', 'B', 'C', 'B',\n",
       "        'A', 'C', 'C', 'D', 'B', 'D', 'B', 'D', 'D', 'D', 'A', 'B', 'B',\n",
       "        'B', 'C', 'B', 'D', 'C', 'C', 'A', 'B', 'D', 'D', 'C', 'B', 'B',\n",
       "        'C', 'B', 'C', 'D', 'B', 'D', 'B', 'B', 'B', 'B', 'A', 'B', 'A',\n",
       "        'C', 'A', 'D', 'D', 'B', 'C', 'C', 'B', 'C', 'A', 'B', 'D', 'D',\n",
       "        'C', 'C', 'D', 'A', 'C', 'A', 'D', 'C', 'C', 'B', 'D', 'C', 'B',\n",
       "        'B', 'A', 'B', 'C', 'B', 'A', 'B', 'B', 'B', 'C', 'D', 'B', 'B',\n",
       "        'C', 'C', 'B', 'B', 'D', 'B', 'A', 'B', 'C', 'C', 'B', 'B', 'A',\n",
       "        'C', 'B', 'B', 'B', 'C', 'B', 'D', 'D', 'B', 'D', 'B', 'D', 'B',\n",
       "        'B', 'B', 'C', 'A', 'C', 'D', 'A', 'C', 'A', 'B', 'B', 'B', 'B',\n",
       "        'C', 'A', 'C', 'D', 'C', 'D', 'B', 'C', 'D', 'D', 'B', 'D', 'D',\n",
       "        'B', 'C', 'A', 'C', 'C', 'B', 'D', 'A', 'C', 'D', 'B', 'B', 'D',\n",
       "        'B', 'D', 'A', 'C', 'B', 'D', 'B', 'C', 'C', 'D', 'C', 'B', 'C'],\n",
       "       dtype='<U1'),\n",
       " 'test_pred': array(['B', 'B', 'D', 'D', 'A', 'D', 'D', 'C', 'B', 'D', 'C', 'C', 'D',\n",
       "        'D', 'C', 'C', 'C', 'C', 'B', 'C', 'C', 'D', 'A', 'D', 'C', 'C',\n",
       "        'C', 'B', 'B', 'A', 'C', 'B', 'C', 'A', 'B', 'B', 'C', 'B', 'C',\n",
       "        'B', 'C', 'D', 'C', 'D', 'A', 'D', 'D', 'C', 'B', 'C', 'D', 'B',\n",
       "        'D', 'C', 'C', 'B', 'B', 'C', 'A', 'C', 'C', 'B', 'B', 'C', 'C',\n",
       "        'D', 'D', 'D', 'C', 'B', 'D', 'B', 'B', 'D', 'D', 'D', 'C', 'B',\n",
       "        'D', 'D', 'C', 'B', 'C', 'C', 'B', 'B', 'C', 'B', 'A', 'A', 'B',\n",
       "        'D', 'C', 'A', 'D', 'C', 'C', 'B', 'C', 'B', 'D', 'A', 'D', 'B',\n",
       "        'D', 'A', 'A', 'C', 'B', 'B', 'C', 'C', 'D', 'C', 'D', 'C', 'D',\n",
       "        'D', 'C', 'C', 'A', 'B', 'C', 'B', 'B', 'B', 'A', 'C', 'D', 'A',\n",
       "        'B', 'B', 'A', 'A', 'B', 'B', 'B', 'A', 'B', 'D', 'D', 'A', 'C',\n",
       "        'B', 'B', 'B', 'D', 'B', 'D', 'C', 'B', 'C', 'D', 'C', 'A', 'B',\n",
       "        'A', 'C', 'B', 'C', 'C', 'D', 'B', 'C', 'C', 'A', 'A', 'C', 'B',\n",
       "        'C', 'B', 'D', 'C', 'B', 'C', 'C', 'B', 'C', 'C', 'B', 'B', 'C',\n",
       "        'B', 'B', 'D', 'C', 'B', 'A', 'C', 'D', 'A', 'B', 'D', 'B', 'B',\n",
       "        'D', 'C', 'C', 'D', 'B', 'A', 'B', 'B', 'B', 'B', 'C', 'B', 'B',\n",
       "        'D', 'B', 'C', 'B', 'D', 'B', 'D', 'B', 'D', 'B', 'B', 'B', 'B',\n",
       "        'D', 'B', 'D', 'B', 'C', 'C', 'B', 'B', 'D', 'C', 'B', 'D', 'D',\n",
       "        'C', 'D', 'A', 'B', 'B', 'D', 'D', 'C', 'B', 'C', 'C', 'B', 'D',\n",
       "        'B', 'D', 'B', 'C', 'B', 'C', 'D', 'B', 'D', 'C', 'B', 'B', 'C',\n",
       "        'C', 'A', 'D', 'C', 'C', 'B', 'D', 'A', 'C', 'B', 'C', 'B', 'C',\n",
       "        'B', 'D', 'C', 'C', 'C', 'C', 'A', 'C', 'D', 'B', 'C', 'B', 'D',\n",
       "        'B', 'D', 'D', 'C', 'B', 'D', 'C', 'A', 'D', 'B', 'A', 'B', 'C',\n",
       "        'A', 'B', 'B', 'B', 'D', 'C', 'D', 'B', 'D', 'D', 'B', 'C', 'B',\n",
       "        'B', 'D', 'A', 'A', 'C', 'B', 'D', 'B', 'A', 'D', 'B', 'C', 'D',\n",
       "        'C', 'C', 'A', 'D', 'C', 'B', 'C', 'C', 'D', 'A', 'A', 'A', 'C',\n",
       "        'B', 'D', 'B', 'D', 'C', 'B', 'A', 'D', 'C', 'D', 'C', 'D', 'C',\n",
       "        'A', 'C', 'B', 'B', 'B', 'B', 'A', 'B', 'D', 'B', 'C', 'A', 'B',\n",
       "        'B', 'C', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'D', 'A', 'C', 'C',\n",
       "        'C', 'B', 'A', 'A', 'B', 'A', 'A', 'B', 'D', 'D', 'A', 'A'],\n",
       "       dtype='<U1'),\n",
       " 'model': CategoricalNB(alpha=0.9319320115219788, force_alpha=True),\n",
       " 'fitness': 0.6794235497566671}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_trials[175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350]\n",
      "[444]\n",
      "[580]\n",
      "[540]\n",
      "[181]\n",
      "[174]\n",
      "[173]\n",
      "[731]\n",
      "[172]\n",
      "[171]\n",
      "[167]\n",
      "[166]\n",
      "[629]\n",
      "[918]\n",
      "[347]\n",
      "[949]\n",
      "[524]\n",
      "[352]\n",
      "[354]\n",
      "[719]\n",
      "[361]\n",
      "[642]\n",
      "[373]\n",
      "[649]\n",
      "[761]\n",
      "[560]\n",
      "[558]\n",
      "[396]\n",
      "[790]\n",
      "[688]\n",
      "[744]\n",
      "[784]\n",
      "[767]\n",
      "[992]\n",
      "[593]\n",
      "[612]\n",
      "[812]\n",
      "[834]\n",
      "[905]\n",
      "[490]\n",
      "[983]\n",
      "[597]\n",
      "[608]\n",
      "[463]\n",
      "[896]\n",
      "[436]\n",
      "[379]\n",
      "[376]\n",
      "[264]\n",
      "[292]\n",
      "[256]\n",
      "[335]\n",
      "[319]\n",
      "[298]\n",
      "[246]\n",
      "[182]\n",
      "[175]\n",
      "[176]\n",
      "[177]\n",
      "[305]\n",
      "[704]\n",
      "[244]\n",
      "[241]\n",
      "[253]\n",
      "[240]\n",
      "[239]\n",
      "[238]\n",
      "[234]\n",
      "[233]\n",
      "[232]\n",
      "[231]\n",
      "[227]\n",
      "[279]\n",
      "[226]\n",
      "[934]\n",
      "[225]\n",
      "[224]\n",
      "[223]\n",
      "[218]\n",
      "[299]\n",
      "[301]\n",
      "[277]\n",
      "[382]\n",
      "[892]\n",
      "[498]\n",
      "[805]\n",
      "[193]\n",
      "[222]\n",
      "[211]\n",
      "[192]\n",
      "[195]\n",
      "[203]\n",
      "[201]\n",
      "[191]\n",
      "[190]\n",
      "[976]\n",
      "[197]\n",
      "[186]\n",
      "[188]\n",
      "[184]\n",
      "[185]\n",
      "[990]\n",
      "[194]\n",
      "[943]\n",
      "[254]\n",
      "[510]\n",
      "[96]\n",
      "[370]\n",
      "[603]\n",
      "[159]\n",
      "[844]\n",
      "[437]\n",
      "[938]\n",
      "[151]\n",
      "[138]\n",
      "[130]\n",
      "[465]\n",
      "[137]\n",
      "[859]\n",
      "[141]\n",
      "[152]\n",
      "[132]\n",
      "[131]\n",
      "[123]\n",
      "[216]\n",
      "[212]\n",
      "[768]\n",
      "[144]\n",
      "[786]\n",
      "[748]\n",
      "[296]\n",
      "[318]\n",
      "[245]\n",
      "[626]\n",
      "[321]\n",
      "[205]\n",
      "[716]\n",
      "[538]\n",
      "[162]\n",
      "[154]\n",
      "[721]\n",
      "[155]\n",
      "[243]\n",
      "[259]\n",
      "[282]\n",
      "[340]\n",
      "[250]\n",
      "[302]\n",
      "[324]\n",
      "[304]\n",
      "[164]\n",
      "[700]\n",
      "[497]\n",
      "[712]\n",
      "[472]\n",
      "[837]\n",
      "[467]\n",
      "[322]\n",
      "[429]\n",
      "[925]\n",
      "[426]\n",
      "[868]\n",
      "[214]\n",
      "[389]\n",
      "[331]\n",
      "[280]\n",
      "[957]\n",
      "[765]\n",
      "[627]\n",
      "[469]\n",
      "[909]\n",
      "[855]\n",
      "[698]\n",
      "[737]\n",
      "[841]\n",
      "[169]\n",
      "[875]\n",
      "[371]\n",
      "[562]\n",
      "[395]\n",
      "[577]\n",
      "[920]\n",
      "[550]\n",
      "[650]\n",
      "[450]\n",
      "[421]\n",
      "[323]\n",
      "[821]\n",
      "[94]\n",
      "[338]\n",
      "[446]\n",
      "[330]\n",
      "[281]\n",
      "[275]\n",
      "[273]\n",
      "[337]\n",
      "[265]\n",
      "[754]\n",
      "[278]\n",
      "[745]\n",
      "[401]\n",
      "[865]\n",
      "[417]\n",
      "[913]\n",
      "[366]\n",
      "[125]\n",
      "[989]\n",
      "[527]\n",
      "[161]\n",
      "[514]\n",
      "[466]\n",
      "[156]\n",
      "[835]\n",
      "[160]\n",
      "[822]\n",
      "[901]\n",
      "[827]\n",
      "[675]\n",
      "[711]\n",
      "[789]\n",
      "[609]\n",
      "[598]\n",
      "[648]\n",
      "[491]\n",
      "[456]\n",
      "[374]\n",
      "[725]\n",
      "[741]\n",
      "[534]\n",
      "[618]\n",
      "[948]\n",
      "[802]\n",
      "[525]\n",
      "[575]\n",
      "[407]\n",
      "[846]\n",
      "[662]\n",
      "[344]\n",
      "[204]\n",
      "[215]\n",
      "[183]\n",
      "[578]\n",
      "[915]\n",
      "[555]\n",
      "[547]\n",
      "[533]\n",
      "[945]\n",
      "[684]\n",
      "[271]\n",
      "[274]\n",
      "[881]\n",
      "[530]\n",
      "[258]\n",
      "[287]\n",
      "[628]\n",
      "[727]\n",
      "[749]\n",
      "[895]\n",
      "[442]\n",
      "[814]\n",
      "[588]\n",
      "[502]\n",
      "[415]\n",
      "[770]\n",
      "[832]\n",
      "[362]\n",
      "[552]\n",
      "[796]\n",
      "[398]\n",
      "[355]\n",
      "[671]\n",
      "[703]\n",
      "[932]\n",
      "[571]\n",
      "[964]\n",
      "[228]\n",
      "[255]\n",
      "[333]\n",
      "[316]\n",
      "[666]\n",
      "[252]\n",
      "[237]\n",
      "[229]\n",
      "[261]\n",
      "[730]\n",
      "[236]\n",
      "[797]\n",
      "[210]\n",
      "[114]\n",
      "[599]\n",
      "[984]\n",
      "[381]\n",
      "[430]\n",
      "[787]\n",
      "[953]\n",
      "[196]\n",
      "[206]\n",
      "[213]\n",
      "[392]\n",
      "[343]\n",
      "[879]\n",
      "[955]\n",
      "[402]\n",
      "[519]\n",
      "[889]\n",
      "[739]\n",
      "[517]\n",
      "[505]\n",
      "[978]\n",
      "[492]\n",
      "[810]\n",
      "[652]\n",
      "[541]\n",
      "[405]\n",
      "[199]\n",
      "[807]\n",
      "[387]\n",
      "[935]\n",
      "[664]\n",
      "[963]\n",
      "[574]\n",
      "[400]\n",
      "[474]\n",
      "[129]\n",
      "[907]\n",
      "[644]\n",
      "[723]\n",
      "[611]\n",
      "[734]\n",
      "[673]\n",
      "[750]\n",
      "[933]\n",
      "[565]\n",
      "[460]\n",
      "[602]\n",
      "[595]\n",
      "[871]\n",
      "[726]\n",
      "[418]\n",
      "[694]\n",
      "[842]\n",
      "[987]\n",
      "[434]\n",
      "[944]\n",
      "[590]\n",
      "[617]\n",
      "[774]\n",
      "[494]\n",
      "[702]\n",
      "[546]\n",
      "[553]\n",
      "[440]\n",
      "[861]\n",
      "[917]\n",
      "[714]\n",
      "[481]\n",
      "[363]\n",
      "[317]\n",
      "[986]\n",
      "[142]\n",
      "[473]\n",
      "[996]\n",
      "[928]\n",
      "[145]\n",
      "[150]\n",
      "[828]\n",
      "[133]\n",
      "[134]\n",
      "[135]\n",
      "[136]\n",
      "[511]\n",
      "[377]\n",
      "[365]\n",
      "[523]\n",
      "[823]\n",
      "[785]\n",
      "[615]\n",
      "[327]\n",
      "[300]\n",
      "[297]\n",
      "[341]\n",
      "[157]\n",
      "[646]\n",
      "[384]\n",
      "[622]\n",
      "[569]\n",
      "[561]\n",
      "[911]\n",
      "[411]\n",
      "[941]\n",
      "[916]\n",
      "[548]\n",
      "[692]\n",
      "[817]\n",
      "[584]\n",
      "[425]\n",
      "[679]\n",
      "[862]\n",
      "[803]\n",
      "[988]\n",
      "[724]\n",
      "[616]\n",
      "[778]\n",
      "[890]\n",
      "[946]\n",
      "[591]\n",
      "[764]\n",
      "[610]\n",
      "[459]\n",
      "[876]\n",
      "[961]\n",
      "[903]\n",
      "[651]\n",
      "[839]\n",
      "[669]\n",
      "[375]\n",
      "[647]\n",
      "[870]\n",
      "[967]\n",
      "[493]\n",
      "[348]\n",
      "[856]\n",
      "[639]\n",
      "[573]\n",
      "[554]\n",
      "[403]\n",
      "[695]\n",
      "[499]\n",
      "[974]\n",
      "[209]\n",
      "[513]\n",
      "[532]\n",
      "[294]\n",
      "[667]\n",
      "[168]\n",
      "[431]\n",
      "[586]\n",
      "[394]\n",
      "[486]\n",
      "[453]\n",
      "[439]\n",
      "[342]\n",
      "[811]\n",
      "[858]\n",
      "[798]\n",
      "[968]\n",
      "[972]\n",
      "[470]\n",
      "[360]\n",
      "[781]\n",
      "[353]\n",
      "[518]\n",
      "[886]\n",
      "[655]\n",
      "[819]\n",
      "[623]\n",
      "[991]\n",
      "[763]\n",
      "[594]\n",
      "[495]\n",
      "[894]\n",
      "[566]\n",
      "[356]\n",
      "[682]\n",
      "[931]\n",
      "[412]\n",
      "[528]\n",
      "[771]\n",
      "[866]\n",
      "[677]\n",
      "[833]\n",
      "[549]\n",
      "[665]\n",
      "[235]\n",
      "[284]\n",
      "[641]\n",
      "[543]\n",
      "[583]\n",
      "[202]\n",
      "[315]\n",
      "[643]\n",
      "[979]\n",
      "[729]\n",
      "[257]\n",
      "[475]\n",
      "[635]\n",
      "[314]\n",
      "[399]\n",
      "[691]\n",
      "[897]\n",
      "[500]\n",
      "[630]\n",
      "[127]\n",
      "[930]\n",
      "[659]\n",
      "[971]\n",
      "[674]\n",
      "[124]\n",
      "[508]\n",
      "[759]\n",
      "[847]\n",
      "[995]\n",
      "[488]\n",
      "[143]\n",
      "[380]\n",
      "[891]\n",
      "[592]\n",
      "[477]\n",
      "[568]\n",
      "[521]\n",
      "[198]\n",
      "[187]\n",
      "[221]\n",
      "[118]\n",
      "[378]\n",
      "[480]\n",
      "[937]\n",
      "[452]\n",
      "[529]\n",
      "[308]\n",
      "[416]\n",
      "[654]\n",
      "[848]\n",
      "[49]\n",
      "[63]\n",
      "[709]\n",
      "[110]\n",
      "[111]\n",
      "[105]\n",
      "[775]\n",
      "[448]\n",
      "[52]\n",
      "[95]\n",
      "[313]\n",
      "[443]\n",
      "[653]\n",
      "[113]\n",
      "[115]\n",
      "[857]\n",
      "[249]\n",
      "[288]\n",
      "[276]\n",
      "[103]\n",
      "[102]\n",
      "[153]\n",
      "[78]\n",
      "[824]\n",
      "[104]\n",
      "[479]\n",
      "[921]\n",
      "[606]\n",
      "[912]\n",
      "[544]\n",
      "[165]\n",
      "[751]\n",
      "[77]\n",
      "[51]\n",
      "[121]\n",
      "[570]\n",
      "[874]\n",
      "[625]\n",
      "[668]\n",
      "[74]\n",
      "[46]\n",
      "[793]\n",
      "[283]\n",
      "[339]\n",
      "[758]\n",
      "[268]\n",
      "[504]\n",
      "[843]\n",
      "[72]\n",
      "[139]\n",
      "[708]\n",
      "[908]\n",
      "[883]\n",
      "[672]\n",
      "[958]\n",
      "[117]\n",
      "[826]\n",
      "[788]\n",
      "[956]\n",
      "[478]\n",
      "[91]\n",
      "[146]\n",
      "[79]\n",
      "[589]\n",
      "[747]\n",
      "[816]\n",
      "[954]\n",
      "[424]\n",
      "[686]\n",
      "[773]\n",
      "[742]\n",
      "[818]\n",
      "[56]\n",
      "[303]\n",
      "[576]\n",
      "[120]\n",
      "[293]\n",
      "[853]\n",
      "[98]\n",
      "[307]\n",
      "[251]\n",
      "[638]\n",
      "[328]\n",
      "[458]\n",
      "[746]\n",
      "[92]\n",
      "[81]\n",
      "[269]\n",
      "[736]\n",
      "[567]\n",
      "[966]\n",
      "[454]\n",
      "[977]\n",
      "[501]\n",
      "[799]\n",
      "[449]\n",
      "[419]\n",
      "[660]\n",
      "[851]\n",
      "[689]\n",
      "[83]\n",
      "[869]\n",
      "[762]\n",
      "[423]\n",
      "[551]\n",
      "[66]\n",
      "[71]\n",
      "[67]\n",
      "[122]\n",
      "[109]\n",
      "[898]\n",
      "[357]\n",
      "[993]\n",
      "[631]\n",
      "[54]\n",
      "[163]\n",
      "[61]\n",
      "[769]\n",
      "[678]\n",
      "[420]\n",
      "[85]\n",
      "[893]\n",
      "[783]\n",
      "[312]\n",
      "[884]\n",
      "[433]\n",
      "[633]\n",
      "[619]\n",
      "[368]\n",
      "[624]\n",
      "[794]\n",
      "[489]\n",
      "[73]\n",
      "[910]\n",
      "[722]\n",
      "[969]\n",
      "[208]\n",
      "[332]\n",
      "[428]\n",
      "[272]\n",
      "[942]\n",
      "[756]\n",
      "[82]\n",
      "[468]\n",
      "[965]\n",
      "[927]\n",
      "[506]\n",
      "[325]\n",
      "[885]\n",
      "[484]\n",
      "[939]\n",
      "[69]\n",
      "[657]\n",
      "[705]\n",
      "[445]\n",
      "[795]\n",
      "[696]\n",
      "[849]\n",
      "[605]\n",
      "[409]\n",
      "[882]\n",
      "[291]\n",
      "[60]\n",
      "[391]\n",
      "[70]\n",
      "[390]\n",
      "[55]\n",
      "[564]\n",
      "[777]\n",
      "[108]\n",
      "[676]\n",
      "[217]\n",
      "[867]\n",
      "[998]\n",
      "[872]\n",
      "[76]\n",
      "[367]\n",
      "[112]\n",
      "[306]\n",
      "[713]\n",
      "[690]\n",
      "[902]\n",
      "[888]\n",
      "[404]\n",
      "[482]\n",
      "[922]\n",
      "[663]\n",
      "[929]\n",
      "[830]\n",
      "[438]\n",
      "[93]\n",
      "[451]\n",
      "[687]\n",
      "[864]\n",
      "[369]\n",
      "[242]\n",
      "[262]\n",
      "[57]\n",
      "[601]\n",
      "[515]\n",
      "[697]\n",
      "[179]\n",
      "[44]\n",
      "[107]\n",
      "[84]\n",
      "[715]\n",
      "[526]\n",
      "[699]\n",
      "[637]\n",
      "[982]\n",
      "[267]\n",
      "[26]\n",
      "[326]\n",
      "[34]\n",
      "[981]\n",
      "[406]\n",
      "[62]\n",
      "[522]\n",
      "[349]\n",
      "[542]\n",
      "[718]\n",
      "[503]\n",
      "[604]\n",
      "[106]\n",
      "[40]\n",
      "[41]\n",
      "[388]\n",
      "[37]\n",
      "[809]\n",
      "[43]\n",
      "[952]\n",
      "[33]\n",
      "[42]\n",
      "[738]\n",
      "[845]\n",
      "[906]\n",
      "[563]\n",
      "[27]\n",
      "[999]\n",
      "[39]\n",
      "[753]\n",
      "[791]\n",
      "[539]\n",
      "[757]\n",
      "[636]\n",
      "[878]\n",
      "[35]\n",
      "[47]\n",
      "[383]\n",
      "[728]\n",
      "[23]\n",
      "[735]\n",
      "[88]\n",
      "[32]\n",
      "[28]\n",
      "[87]\n",
      "[836]\n",
      "[22]\n",
      "[512]\n",
      "[813]\n",
      "[149]\n",
      "[951]\n",
      "[346]\n",
      "[36]\n",
      "[364]\n",
      "[386]\n",
      "[24]\n",
      "[189]\n",
      "[31]\n",
      "[772]\n",
      "[854]\n",
      "[680]\n",
      "[904]\n",
      "[334]\n",
      "[260]\n",
      "[309]\n",
      "[45]\n",
      "[0]\n",
      "[128]\n",
      "[806]\n",
      "[733]\n",
      "[614]\n",
      "[441]\n",
      "[926]\n",
      "[829]\n",
      "[873]\n",
      "[531]\n",
      "[483]\n",
      "[536]\n",
      "[752]\n",
      "[831]\n",
      "[97]\n",
      "[285]\n",
      "[485]\n",
      "[975]\n",
      "[413]\n",
      "[710]\n",
      "[581]\n",
      "[13]\n",
      "[462]\n",
      "[587]\n",
      "[15]\n",
      "[21]\n",
      "[685]\n",
      "[923]\n",
      "[464]\n",
      "[782]\n",
      "[230]\n",
      "[755]\n",
      "[556]\n",
      "[960]\n",
      "[487]\n",
      "[89]\n",
      "[148]\n",
      "[53]\n",
      "[286]\n",
      "[290]\n",
      "[11]\n",
      "[19]\n",
      "[38]\n",
      "[516]\n",
      "[455]\n",
      "[20]\n",
      "[732]\n",
      "[427]\n",
      "[600]\n",
      "[860]\n",
      "[263]\n",
      "[101]\n",
      "[5]\n",
      "[12]\n",
      "[289]\n",
      "[393]\n",
      "[432]\n",
      "[760]\n",
      "[25]\n",
      "[14]\n",
      "[959]\n",
      "[720]\n",
      "[701]\n",
      "[48]\n",
      "[559]\n",
      "[681]\n",
      "[579]\n",
      "[351]\n",
      "[86]\n",
      "[247]\n",
      "[852]\n",
      "[919]\n",
      "[557]\n",
      "[266]\n",
      "[178]\n",
      "[207]\n",
      "[820]\n",
      "[613]\n",
      "[780]\n",
      "[476]\n",
      "[147]\n",
      "[620]\n",
      "[640]\n",
      "[329]\n",
      "[410]\n",
      "[414]\n",
      "[880]\n",
      "[940]\n",
      "[310]\n",
      "[840]\n",
      "[537]\n",
      "[18]\n",
      "[58]\n",
      "[435]\n",
      "[980]\n",
      "[808]\n",
      "[65]\n",
      "[8]\n",
      "[29]\n",
      "[804]\n",
      "[634]\n",
      "[740]\n",
      "[899]\n",
      "[800]\n",
      "[461]\n",
      "[99]\n",
      "[6]\n",
      "[119]\n",
      "[825]\n",
      "[994]\n",
      "[170]\n",
      "[219]\n",
      "[64]\n",
      "[776]\n",
      "[140]\n",
      "[507]\n",
      "[3]\n",
      "[582]\n",
      "[408]\n",
      "[947]\n",
      "[706]\n",
      "[358]\n",
      "[457]\n",
      "[632]\n",
      "[801]\n",
      "[607]\n",
      "[970]\n",
      "[1]\n",
      "[75]\n",
      "[997]\n",
      "[116]\n",
      "[779]\n",
      "[924]\n",
      "[973]\n",
      "[707]\n",
      "[359]\n",
      "[877]\n",
      "[509]\n",
      "[585]\n",
      "[950]\n",
      "[683]\n",
      "[385]\n",
      "[900]\n",
      "[180]\n",
      "[220]\n",
      "[535]\n",
      "[658]\n",
      "[661]\n",
      "[50]\n",
      "[656]\n",
      "[90]\n",
      "[4]\n",
      "[850]\n",
      "[717]\n",
      "[863]\n",
      "[2]\n",
      "[17]\n",
      "[16]\n",
      "[838]\n",
      "[422]\n",
      "[7]\n",
      "[372]\n",
      "[496]\n",
      "[985]\n",
      "[766]\n",
      "[345]\n",
      "[397]\n",
      "[743]\n",
      "[10]\n",
      "[9]\n",
      "[471]\n",
      "[100]\n",
      "[30]\n",
      "[336]\n",
      "[572]\n",
      "[596]\n",
      "[936]\n",
      "[621]\n",
      "[815]\n",
      "[158]\n",
      "[80]\n",
      "[914]\n",
      "[68]\n",
      "[200]\n",
      "[59]\n",
      "[248]\n",
      "[270]\n",
      "[520]\n",
      "[545]\n",
      "[295]\n",
      "[645]\n",
      "[792]\n",
      "[962]\n",
      "[670]\n",
      "[311]\n",
      "[126]\n",
      "[320]\n",
      "[887]\n",
      "[693]\n",
      "[447]\n"
     ]
    }
   ],
   "source": [
    "for i in trials_np:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
